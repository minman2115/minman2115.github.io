---
layout: post
title: "딥러닝의 도전과제"
tags: [딥러닝]
comments: true
---

.

Deep_Learning_Studynotes_(20190622)

study program : https://www.fastcampus.co.kr/data_camp_deeplearning

#### [학습목표]

딥러닝의 도전과제 이해

#### [학습기록]

- 딥러닝에서 첫번째 이슈는 어떤것을 분류를 하는데 그 전체적인 맥락을 이해하는 것이 아니기 때문에 전체적인 맥락까지 이해하기 위해서는 딥러닝이 더 발전해야 한다.


- 우리가 데이터를 수집해서 활용하는데 real-world의 데이터들은 항상 위에 브래드피트의 사진과 같지 않다. 흑백여자 사진처럼 햇빛에 얼굴이 일부 가려지는 이런 사진들은 딥러닝이 학습하는데 어려움을 준다. 로봇에게 처음부터 강화학습을 시키면 로봇은 학습을 시작하자마자 이상한 행동을 하면서 부셔질 것이다.


- 강화학습에서 Efficient Training에 대핸 이슈도 있다. 예를 들어서 어떤 단순한 컴퓨터 게임을 컴퓨터에게 학습시켜서 게임을 클리어 하도록 한다고 하면 사람은 두시간이면 클리어 할 수 있지만 컴퓨터에게 학습시키게 되면 한 900시간 정도해야 사람과 비슷해진다는 연구결과가 있다.


- 왜 사람은 그러면 더 잘하냐. 예전에 유사한 컴퓨터게임을 해봤던 경험도 있고, 내가 조종하는 캐릭터가 사다리에서 떨어지면 죽는다는 물리법칙을 이미 사전에 알고 있었고, 이런 여러가지 도메인지식을 갖고 있기 때문이다.


- 그래서 누가 재미있는 실험을 했는데 이런 사람의 도메인 지식을 방해를 하고, 컴퓨터와 비교를 하였다. 예를 들어서 사다리를 타면 죽게 한다던가, 보이지 않는 함정을 만든다던가, 방향키 셋팅을 바꿔서 한다던가 이렇게 했더니 컴퓨터와 큰 차이가 없었다는 실험결과가 있다.


- 강화학습의 또다른 도전과제는 Unintended Consequences이다. 예를 들어서 컴퓨터게임인데 보트경주를 하는 게임이 있다고 하자. 보트게임의 목적은 다른 경주자들보다 빨리 가면서 동시에, 중간에 있는 동전을 많이 먹어줘야 높은 점수를 획득한다. 사람이 플레이를 하면 남들보다 빠르게 완주하고자함은 물론이고 동전도 중간중간에 잘 먹어준다. 그런데 컴퓨터한테 학습을 시키니까 컴퓨터는 오직 점수만 높이는데 혈안이 되어서 계속 방황하면서 동전만 주구장창 먹기만한다. 왜냐하면 경주에서는 꼴지해도 동전을 겁나먹어서 점수를 높이면 최종 1등을 할 수 있기 때문이다. 딥러닝은 그래서 개발자가 의도하지 않았던 이상한 결과를 낼 수 있다는 것을 항상 염두해야 한다.


- Adversarial Attack이라는 것도 있다. 예를들어서 바나나 사진을 구분하는 딥러닝이라고 하면 바나나 사진에 노이즈를 줘도 예를 들어서 지우개를 두거나, 연필을 두거나해도 사람은 바나나라고 판별할 수 있지만 딥러닝 모델은 이런 작은 노이즈에도 엄청나게 반응을해서 분류결과까지 바뀌어 바리는 경우가 있다. 이런 경우는 자율주행 자동차에 엄청난 위협이 될 수 있다.


- Uncertainty 이슈도 있다. 예를들어서 cifar 10 이라는 열개의 클래스를 갖는 이미지 세트가 있는데 이거가지고 열심히 학습을 시킨다. 그 다음에 cifar 100라는 100개의 클래스를 갖는 데이터 세트가 있다. 이 cifer 100의 데이터를 cifar10으로 학습한 모델에 넣어본다. 그러면 클래스10개 중에 하나를 결과값으로 도출할텐데 cifar10에 없는 클래스인 이미지가 들어오게 되면 확률을 결과값으로 내줄때 모든클래스에 전부 10프로라고 결과값을 내주면 딥러닝 모델이 '아 나이거 잘 모르겠어' 라고 말하는 것과 같기 때문에 개발자는 그래서 " 아 이 cifar 100 데이터의 클래스는 cifar 10의 클래스에는 없는 데이터이기 때문에 결과값을 전부 10프로라고 해주겠지"라고 예상하겠지만 실제로는 사과를 넣었더니 90퍼센트 이상의 확률로 자동차라고 답하는 어의없는 상황이 연출된다.


- 무슨말이냐면 처음보는 데이터가 나와도 내가 지금까지 학습했던것 중에 하나라고 강력한 확신을 갖고 딥러닝 모델이 답하는 것이다. 즉, 내가 못본 데이터이기 때문에 불확실한 데이터라고 말하지 못하는 것이다.


- 마지막으로 Catastrophic Forgetting Problem 이라는 것도 있다. 사람과 마찬가지로 옛날에 학습했던 것을 까먹는 현상이다. 카이스트에서 재미있는 실험을 했다. 6만개의 데이터가 있는데 그거를 절반으로 뚝 잘라서 3만개 한 세트를 그룹1번, 3만개 다른 한개를 그룹2번으로해서 그룹1번으로 학습을 시키고 그룹2번으로 테스트를 했다. 그런다음에 이 학습이 된 상태로 추가로 그룹2번으로 학습을 시켜준다. 그리고 그룹1번을 테스트 셋으로해서 테스트를 해보니까 그룹1번에 대한 테스트 error-rate가 그룹2번으로 학습을 시킬수록 증가하는 경향이 발생했다. 


- 실제세계에서는 online learning이나 life long learning이라고 하는 케이스에서 자주 볼 수 있는 현상이다. 원래는 클래스가 10개였는데 상황에 따라서 클래스가 11개로 늘려야 하는 경우가 발생했다. 그때 11번째 클래스의 데이터가 학습이 되면서 나머지 10개의 클래스 데이터들에 대한 성능이 떨어지는 현상이 발생한다.


- 이밖에도 딥러닝 모델을 학습시키는데 학습을 위해서 꼭 필요한 도메인 지식을 어떻게 주입을 시켜야 하는것에 대한 고민등이 있다.
