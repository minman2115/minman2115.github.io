---
layout: post
title: "NASNet 기초개념"
tags: [딥러닝]
comments: true
---

.

Deep_Learning_TIL(20210301)

study program : https://www.fastcampus.co.kr/data_camp_deeplearning

패스트캠퍼스 "TensorFlow로 시작하는 딥러닝 입문 CAMP"를 공부하고 정리한 내용입니다.

** 참고자료 : https://github.com/jwlee-ml/TensorFlow_Training_13th

[학습내용]

- 개요

최근에 각광받는 Auto ML의 일종으로, NAS(Neural Architecture Search)라고 많이 부른다. NAS는 Auto ML에서 구글에서 하고 있는 것들을 부르기도 한다. 최근에 2018년 ~ 2019년 현재 Auto ML쪽 논문이 엄청 나오고 있다. NAS가 가장 기본적인 형태의 Auto ML이라고 이해하면 된다.

이 논문은 2017년 12월에 나온 논문인데 이전에 Neural Architecture Search Reinforcement learning 라는 논문이 있기는 했다. 

![1](https://user-images.githubusercontent.com/41605276/109437386-f4126b00-7a67-11eb-8541-72dd8c63b085.png)

- Neural Architecture Search

RNN과 강화학습을 사용한다. RNN은 컨트롤러다. RNN이 네트워크를 뽑아준다. 네트워크 첫번째 레이어부터 순차적으로 레이어별로 컨볼루션 필터의 가로사이즈 얼마, 세로 사이즈 얼마, 가로방향 스트라이드 얼마, 세로방향 스트라이드 얼마, 필더 갯수 몇개인지 그거를 RNN이 뽑아준다. 첫번째 레이어에 이작업을 하고, 두번째 레이어도 이 작업을 하고, 레이어 별로 이작업을 쭉 해준다. 그러면 레이어가 RNN으로부터 순차적으로 나오게 된다. 그거를 쭉 모아서 네트워크를 만든다. 그런 다음에 이미지넷 데이터를 가지고 열심히 학습을 해준다. 그러면 결과가 나오고 accuracy가 나온다. 이 결과값을 강화학습의 리워드로 준다. 결과값이 좋을수록 강화학습의 리워드가 높을 것이다. 그래서 RNN을 강화학습으로 학습을 하는 것이다.

![2](https://user-images.githubusercontent.com/41605276/109437408-12786680-7a68-11eb-9677-8a6766579b28.PNG)

- Motivation & Idea

1) NAS used 800 GPUs for 28days resulting in `22,400 GPU hours` --> too long (ImageNet dataset)

이 논문이 나온건 사실 2016년에 나온것이고, 2017년도에 발표가 된 것인데 처음에 나온 논문에서는 800개의 GPU로 28일 동안 돌려야 네트워크를 뽑을 수가 있었다. 너무 학습시간이 길다고 판단했다. 그래서 이거를 줄여야겠다라고 해서 나온게 NAS 이후에 ENAS(Efficient NAS, CPU 1개로 16시간만에 학습결과가 나온다.) 이런것들이 나오게 된다.

암튼 이 학습시간을 NAS에서 줄이기 위해서 처음에 어떤전략을 썼냐면 무식하게 첫번째 레이어부터 컨볼루션 필터 가로 몇 세로 몇 이렇게 바로 뽑지말자. 한땀한땀 찾아가는게 너무 오버헤드가 크니까 유저들이 이미지넷 대회에서 쌓은 knowledge를 활용해서 이를 줄여서 학습속도를 빠르게 해보자라는 것이다.   

2) Many state of the art models have `repeated modules`

그러면 지금까지 어떻게 해왔냐. 조그마한 모듈을 만들어서 그거를 계속 쌓았다. NAS에서도 그렇게 해보자. 전체 처음부터 끝까지 다찾지 말고, 조그만 모듈을 만들어서 그 안에서만 찾고, 그거를 쌓아버리자.

3) Searching for a good architecture on the far smaller CIFAR 10 dataset, and `automatically transfer the learned architecture` to ImageNet

그리고 이미지넷 데이터가 너무 크기 때문에 CIFAR 10 같은 데이터 크기로 줄여서 학습을 시킨다. 거기서 정확도를 계산하고 강화학습에 리워드를 주자. 조그만 모듈을 cell이라고 부르는데 cell의 구조가 가장 좋을것이냐도 CIFAR 10 데이터셋 가지고 결정을 하고, 그거를 레이어를 더 많이 쌓아서 이미지넷을 적용하자는 것이다. 다시말해서 이미지넷가지고 바로 정확도 계산하고 리워드로 주게되면 너무 학습하는데 시간이 오래걸린다는 것이다. 그래서 더 작은 데이터로해서 transfer를 하겠다는 것이다. 그래서 이 논문 제목이 Learning transferable Architectures for Scalable Image Recognition이다.

4) Achieving this transferability by designing a search space so that the complexity of `the architecture is independent of the depth of the network`

5) All convolutional networks in search space are composed of convolutional layers(or `"cells"` ) with identical structure but different weights

- Method

cell 종류는 Normal Cell, Reduction Cell 두가지다. CIFAR 10일때는 이미지가 들어오면 노멀 cell이라는 걸로 n 번 반복을 하고, Reduction Cell 한번 연산을 한다. Reduction Cell을 한번하면 가로세로가 절반으로 줄어든다. 

Overall architectures of the convolutional nets are manually predetermined

1) Normal Cell : convolutional cells that return a feature map of the same dimension

2) Reduction Cell : convolutional cells that return a feature map where the feature map height and width is reduced by a factor of two

Using common heuristic to double the number of filters in the output whenever the spatial activation size is reduced

- Scalable Architectures for Image Classification

아래 그림과 같이 CIFAR 10으로 학습을 하고 Normal Cell과 Reduction Cell로 어떤 구조의 cell이 좋은지를 찾은 다음에 이미지넷으로 옮기는 것이다. 3x3 컨볼루션 한번하고, 리덕션 두번해서 가로세로를 많이 줄인다음에 리덕션 한번, 노멀셀 n번,리덕션 한번, 노멀셀 n번 이런식으로 n을 조절하던지 해서 레이어를 깊게 쌓아서 하겠다는 것이다. 그래서 search는 아래그림의 좌측셀의 내부만 하겠다는 것이다.

![3](https://user-images.githubusercontent.com/41605276/109438688-5ec6a500-7a6e-11eb-9cf8-83353af312d8.PNG)

- Models and Algorithms

RNN으로 아웃풋이 나오면 이거를 입력값으로 다시 집어넣는 구조다. 하나의 엘리먼트는 아래 그림에서 빨간색 박스표시한 부분을 말한다. 두개의 연산을해서 하나로 합치는 구조다. 이 엘리먼트는 사람이 정한 구조다. 사람이 search space를 줄이기 위해서 이런구조로 가겠다고 정한 것이다. 이런 구조 안에서 제일 좋은 것을 찾겠다는 것이다.

파란색 표시그림의 가장 좌측셀은 입력을 어디서 가져올래를 뽑으라고 하는 것이다.

![4](https://user-images.githubusercontent.com/41605276/109439440-a864bf00-7a71-11eb-9a44-e3a764e07c62.PNG)

아래 그림이 결과로 뽑은 네트워크 예시인데 빨간색 박스표시한게 하나의 엘리먼트이고 이거를 5개를 모아서 하나의 블럭을 만든다는 것이다. 어디서 가져올래라고 한다면 hi+1가 hi 또는 hi-1에서 가져오게 된다. hi+1에서는 몇개의 선택지가 있는데 그중에서 고르는 것이다.

그런 다음에 위에 그림의 파란색 표시의 두번째 셀도 연산할때 입력을 또 어디서 가져와야 할지 모른다. 세번째 셀(노란색 박스)은 왼쪽에서 어떤 입력을 가져왔을때 어떤 연산을 할지 그런 다음에 그 다음 오른쪽 셀에서는 또 어떤 연산을 할지 그리고 마지막 오른쪽 셀은 왼쪽 두개의 셀에서 연산을 한것을 어떻게 합칠지를 의미한다. 어떻게 합칠지는 두개밖에 없다. add(더한다)와 concat 둘중하나를 고르게 되어있다. 


![5](https://user-images.githubusercontent.com/41605276/109439102-58392d00-7a70-11eb-9a2d-d4d7724993d0.PNG)

- Search Space in a Cell (위에 Models and Algorithms의 그림에서 Step 3 and 4)

노란색 셀에서 어떤 연산을 할지 고른다. classification을 한다. 몇개중에 하나를 고르는 거니까. 연산을 아래 그림의 13개중에 하나를 고르게 된다.

참고로 ENAS같은 경우에는 13개가 아니라 5개중에 하나를 고르는 걸로 했고, normal convolution은 전부다 빼버렸다. 학습속도를 높이는데 더 주력한 것이다. 아주 베스트한 것은 아니지만 베스트에 근접을 하는 성능을 내면서 그런 네트워크를 빨리 찾겠다는 것이다. 

![6](https://user-images.githubusercontent.com/41605276/109439684-bcf58700-7a72-11eb-9e47-10da9d0f2b0a.PNG)

그래서 뽑은게 예를 들어서 아래와 같이 NASNet-A 같은 것들이다. NASNet중 NASNet-A가 성능이 가장 좋다고 한다. 그래서 노멀셀을 5번을 먼저 뽑고, 다음 RNN으로 연결이 되는 것이다. 그 다음에 노멀셀을 다 뽑으면 그 결과를 쭉 가지고 가서 그 결과를 이어서 리덕션 셀을 또 뽑는 것이다.

![7](https://user-images.githubusercontent.com/41605276/109439947-bca9bb80-7a73-11eb-814d-91a0678b17e2.PNG)

- Results on ImageNet 

결과를 보면 사람이 한거보다 잘한다는게 결론이다. 단 사람보다 아주 약간 잘하는 수준이지 월등하게 잘하는 수준은 아니다.

![8](https://user-images.githubusercontent.com/41605276/109440082-53767800-7a74-11eb-89d8-a14143888919.PNG)


- 연산하는 순서가 search space를 줄이는데 도움을 주었다고  할 수 있다.

RNN의 특성상 엘리먼트 왼쪽에서 어떤 입력을 받을건지 뽑는 히든레이어 A가 있는데 이거를 통해서 어떤 입력을 받을지 뽑고, 그 다음에 그걸 받아서 어떤 연산을 할지 먼저 하지 않고, 엘리먼트 오른쪽에 입력을 먼저 결정을하면 이게 입력으로 다시 들어가기 때문에 다음 스텝에 영향을 준다. 두개의 입력이 서로 고려되어 어떤 연산을 할지 정하겠다는 것이다. 그리고 이것들을 전부 고려해서 또 다음연산을 하겠다는 것이다.

![10](https://user-images.githubusercontent.com/41605276/109440404-7ead9700-7a75-11eb-95c5-2b20af0785ad.PNG)

- 또 다른 버전의 NASNet : NASNet-B, C

NASNet-B에서는 concat이 보이지 않는다. 거의 다 덧셈을 한다. 그러면 덧셈을 하는거랑 concat을 하는거랑 무슨 차이냐. concat을 한다는 것은 concat을 하고 convolution 같은 연산을 하는데 덧셈은 자유도가 더 떨어진다. concat은 채널이 두배가 되는 것이고 add를 하게 되면 concat한거에 비해서 채널이 반이기 때문이다. concat을 하고 다음연산을 하게되면 다음 연산에 의해서 결과들이 합쳐질 것이다. add는 이 자체로 결과들이 합쳐지게 된다. 덧셈을 해도 그런데 대부분 학습이 잘된다. 노란색부분에서도 노멀 컨볼루션이 안보인다. depthwide- seperable convolution이 보인다. standard convolution이 하나도 안쓰이는게 특징이다.

![9](https://user-images.githubusercontent.com/41605276/109440161-920c3280-7a74-11eb-840c-19ea334d2c18.png)