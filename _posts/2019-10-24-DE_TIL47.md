---
layout: post
title: "Build a Serverless Real-Time Data Processing App By AWS services"
tags: [Data Engineering]
comments: true
---

.

Data_Engineering_TIL_(20190909)

#### [학습한 Contents]

- AWS 튜토리얼

1) 주제 : Build a Serverless Real-Time Data Processing App

2) URL : https://aws.amazon.com/ko/getting-started/projects/build-serverless-real-time-data-processing-app-lambda-kinesis-s3-dynamodb-cognito-athena/


#### [학습목표]


- AWS 서비스를 이용한 실시간 데이터처리


#### [구현목표 아키텍처]

![0](https://user-images.githubusercontent.com/41605276/67453233-0a810900-f661-11e9-9617-05d4f7e9c85f.jpg)

#### [실습내용 요약]

#### step 1) Intro


- Set up your AWS Cloud9 IDE


- Set up the Command Line Clients


#### step 2) Build a data stream


- Create an Amazon Kinesis stream


- Produce messages into the stream


- Read messages from the stream


- Create an identity pool for the unicorn dashboard


- Grant the unauthenticated role access to the stream


- View unicorn status on the dashboard


- Experiment with the producer

#### step 3) Aggregate data


- Create an Amazon Kinesis stream


- Create an Amazon Kinesis Data Analytics application


- Read messages from the stream


- Experiment with the producer

#### step 4) Process streaming data


- Create an Amazon DynamoDB tables


- Create an IAM role for your Lambda function


- Create a Lambda function to process the stream


- Monitor the Lambda function


- Query the DynamoDB table

#### step 5) Store & query Data


- Create an Amazon S3 bucket


- Create an Amazon Kinesis Data Firehose delivery stream


- Create an Amazon Athena table


- Explore the batched data files


- Query the data files

#### [실습 상세내용]

#### step 1) Intro

step 1-1) Set up your AWS Cloud9 IDE

클라우드9 콘솔 접속 및 create environment 클릭

아래 그림과 같이 설정 후 생성

![1](https://user-images.githubusercontent.com/41605276/67453241-0fde5380-f661-11e9-85cf-2de43a86bf87.jpg)

![2](https://user-images.githubusercontent.com/41605276/67453249-17056180-f661-11e9-841c-69a73bf7b880.jpg)

![3](https://user-images.githubusercontent.com/41605276/67453253-1ff63300-f661-11e9-8c8f-c22661766f71.jpg)

다음을 누르면 최종검토 화면 전시, 생성한 내용이 맞는지 확인 후 최종생성

![4](https://user-images.githubusercontent.com/41605276/67453260-25ec1400-f661-11e9-9c3c-82eaa34f4fe3.jpg)

생성 클릭하면 아래와 같이 로딩되면서 클라우드9이 생성됨

![5](https://user-images.githubusercontent.com/41605276/67453264-2be1f500-f661-11e9-9ac3-f251552ed148.jpg)

생성이 완료되면 하단의 CLI 창에 aws sts get-caller-identity 명령어를 입력하여 계정관련 정보를 확인

![6](https://user-images.githubusercontent.com/41605276/67453272-313f3f80-f661-11e9-9233-a07c5935485f.jpg)

step 1-2) Set up the Command Line Clients

https://aws.amazon.com/ko/getting-started/projects/build-serverless-real-time-data-processing-app-lambda-kinesis-s3-dynamodb-cognito-athena/ 의 아래와 같은 화면에서 produce.go와 consumer.go를 다운로드

![7](https://user-images.githubusercontent.com/41605276/67453291-38fee400-f661-11e9-9f42-8ec4e6f1e2d7.jpg)

cloud9 cli 창으로 돌아와서 `curl -s https://dataprocessing.wildrydes.com/client/client.tar | tar -xv` 명령어를 실행하면 아래 그림과 같이 컨슈머와 프로듀서 파일이 좌측 상단화면에 생성되는 것을 확인할 수 있다.

![8](https://user-images.githubusercontent.com/41605276/67453299-3e5c2e80-f661-11e9-99dd-5dcdf9820c36.jpg)

주의사항 : cloud9 화면은 실습 간 계속 사용할 예정으로 항상 띄워놓고 있어야 한다.
 
#### step 2) Build a data stream

step 2) 에서 구현하고자 하는 아키텍처 부분

![9](https://user-images.githubusercontent.com/41605276/67453303-461bd300-f661-11e9-909a-bb0ac8b69775.jpg)

step 2-1) Create an Amazon Kinesis stream

키네시스 콘솔 접속 -> create data streams 클릭

아래 화면과 같은 설정으로 생성해준다.

![10](https://user-images.githubusercontent.com/41605276/67453311-4d42e100-f661-11e9-9400-4655dae764da.jpg)

생성된 결과는 아래 그림과 같다.

![11](https://user-images.githubusercontent.com/41605276/67453318-52a02b80-f661-11e9-83b1-ae7868b2d31e.jpg)

step 2-2) Produce messages into the stream

다시 cloud9 콘솔로 넘어가서 콘솔에서 ./producer 명령어를 실행한다.

그러면 아래 그림과 같이 producer가 작동하는 것을 확인할 수 있다.

![12](https://user-images.githubusercontent.com/41605276/67453323-5764df80-f661-11e9-8126-6b19f1ab7f35.jpg)

step 2-3) Read messages from the stream

그리고 콘솔창을 하나 더 열어서 ./consumer 명령어를 실행하면 아래 그림과 같이 제이슨 형식의 데이터를 초단위로 수집하게 된다.

![13](https://user-images.githubusercontent.com/41605276/67453330-60ee4780-f661-11e9-8eb9-7beffb17f1a5.jpg)

step 2-4) Create an identity pool for the unicorn dashboard

AWS 콘솔에서 Cognito 로 접속해서 ‘자격증명 폴 관리’를 클릭한다.

아래 그림과 같이 pool name을 부여하고 create pool을 클릭한다.

![14](https://user-images.githubusercontent.com/41605276/67453341-69df1900-f661-11e9-80ee-8c5357da749b.jpg)

다음과 같은 화면이 전시될것인데 그러면 allow를 클릭한다.

![15](https://user-images.githubusercontent.com/41605276/67453350-706d9080-f661-11e9-8a6d-e1b1edf84aa9.jpg)

그러면 pool이 생성되는데 우측상단에 edit identity pool을 클릭한다.

![16](https://user-images.githubusercontent.com/41605276/67453354-75cadb00-f661-11e9-9993-eb225695099e.jpg)

아래 그림과 같이 pool name을 부여하고 저장한다.

identity pool id는 메모장에 잘 적어둔다.

![17](https://user-images.githubusercontent.com/41605276/67453361-7bc0bc00-f661-11e9-93b3-0a844c752037.jpg)

step 2-5) Grant the unauthenticated role access to the stream

IAM 서비스 콘솔로 이동해서 

좌측 메뉴에서 roles클릭 -> 아래와 같이 검색하여 해당 롤을 클릭

![18](https://user-images.githubusercontent.com/41605276/67453379-824f3380-f661-11e9-8d89-6dc4c7a48e10.jpg)

클릭해서 아래 그림과 같은 화면이 전시되면 add inline policy를 클릭한다.

![19](https://user-images.githubusercontent.com/41605276/67453392-88451480-f661-11e9-9fb9-e3823f79fc0e.jpg)

아래 그림과 같은 화면이 전시되면 service는 kinesis로 선택, actions에서는 list와 read 선택한다.

![20](https://user-images.githubusercontent.com/41605276/67453410-8e3af580-f661-11e9-9f6b-740b58fb944f.jpg)

그리고 resources로 넘어가서 stream 옆에 add arn 클릭,

지역, 어카운트넘버, stream name을 아래 그림과 같이 입력해주고 add 클릭

![21](https://user-images.githubusercontent.com/41605276/67453420-93984000-f661-11e9-845f-c4f98764a5ad.jpg)

위의 내용들을 설정하면 아래 그림과 같이 setting이 된것을 확인할 수 있다.

![22](https://user-images.githubusercontent.com/41605276/67453431-998e2100-f661-11e9-91f8-1273a1c76432.jpg)

그리고 좌측하단에 review policy를 클릭하면 아래 그림과 같은 화면이 전시되는데 Name을 아래 그림과 같이 부여해주고 create policy를 클릭한다.

![23](https://user-images.githubusercontent.com/41605276/67453442-a01c9880-f661-11e9-88ce-df72c3563c20.jpg)

생성하면 아래 그림처럼 role이 셋팅된 것을 확인할 수 있다.

![24](https://user-images.githubusercontent.com/41605276/67453454-a6ab1000-f661-11e9-8e36-56cccd7dbb27.jpg)

step 2-6) View unicorn status on the dashboard

브라우저에서 https://dataprocessing.wildrydes.com/dashboard.html 로 접속하면 아래 그림과 같은 하면이 전시가 되면서 identity pool ID를 입력하라고 나오는데 아까 메모해 두었던 identity pool ID를 넣어주고 start를 클릭한다.

![25](https://user-images.githubusercontent.com/41605276/67453462-ad398780-f661-11e9-87ee-52e26ab749f6.jpg)

그러면 아래 그림과 같이 유니콘이 실시간으로 이동하는 화면이 전시가 될 것이다.

![26](https://user-images.githubusercontent.com/41605276/67453471-b296d200-f661-11e9-89d5-6c049d792c82.jpg)

step 2-7) Experiment with the producer

cloud9 콘솔로 돌아와서 컨트롤 + c 명령어로 producer를 중단했다가 다시 실행했을때 정상적으로 유니콘이 사라졌다 다시 움직이는지 확인한다.

![27](https://user-images.githubusercontent.com/41605276/67453481-b9254980-f661-11e9-984e-fd052aac626c.jpg)

그리고 아래 그림과 같이 터미널을 하나 더 띄워서 ./producer -name Bucephalus 명령어를 실행해서 시각화 대시보드에 다른 유니콘 하나를 더 띄워본다.

![28](https://user-images.githubusercontent.com/41605276/67453487-bf1b2a80-f661-11e9-951a-9bd8f28af641.jpg)

![29](https://user-images.githubusercontent.com/41605276/67453491-c3dfde80-f661-11e9-9cc7-b6e5af3efa32.jpg)

#### step 3) Aggregate data

step 3) 에서 구현하고자 하는 아키텍처 부분

![30](https://user-images.githubusercontent.com/41605276/67453498-c93d2900-f661-11e9-9d71-42950192d61b.jpg)

step 3-1) Create an Amazon Kinesis stream

키네시스 콘솔로 이동해서 create data streams 클릭, 아래 그림과 같이 세팅 후 생성

![31](https://user-images.githubusercontent.com/41605276/67453503-cf330a00-f661-11e9-91eb-9373da99fc67.jpg)

아래 그림과 같이 생성결과를 확인할 수 있다.

![32](https://user-images.githubusercontent.com/41605276/67453510-d5c18180-f661-11e9-8a56-fa9ffbfa94ea.jpg)

step 3-2) Create an Amazon Kinesis Data Analytics application

대시보드로 이동해서 create analytics를 클릭한다.

그리고 아래 그림과 같이 세팅 후 create application을 클릭한다.

![33](https://user-images.githubusercontent.com/41605276/67453514-dce88f80-f661-11e9-9a6e-e7b1c1d7460b.jpg)

그리고 아래 그림과 같은 화면이 나오면 connect streaming data를 클릭한다.

![34](https://user-images.githubusercontent.com/41605276/67453524-e2de7080-f661-11e9-90ce-ee80c960277f.jpg)

그리고 아래 그림과 같이 셋팅해준다.

![35](https://user-images.githubusercontent.com/41605276/67453534-ed006f00-f661-11e9-8088-6a9874d93102.jpg)

이 셋팅화면 하단에 discover schema를 클릭해서 아래 그림과 같이 전시가 되는지 확인한다.

![36](https://user-images.githubusercontent.com/41605276/67453542-f4277d00-f661-11e9-8bd8-4fd51341ee0a.jpg)

그리고 하단에 save and continue를 클릭한다.

![37](https://user-images.githubusercontent.com/41605276/67453555-fa1d5e00-f661-11e9-9323-cc47da416f1f.jpg)

세이브 엔 컨티뉴를 누르면 아래 그림과 같은 화면이 전시되는데 여기서 go to SQL editor를 클릭한다.

![38](https://user-images.githubusercontent.com/41605276/67453565-02759900-f662-11e9-9aa9-b2e3fedc4bb6.jpg)

아래 그림과 같은 화면이 전시되면 yes, start application 클릭

![39](https://user-images.githubusercontent.com/41605276/67453571-07d2e380-f662-11e9-943c-7456a84ef52d.jpg)

그리고 아래 그림과 같이 쿼리 화면에 다음과 같은 내용을 복붙한다.


```python
CREATE OR REPLACE STREAM "DESTINATION_SQL_STREAM" (
  "Name"                VARCHAR(16),
  "StatusTime"          TIMESTAMP,
  "Distance"            SMALLINT,
  "MinMagicPoints"      SMALLINT,
  "MaxMagicPoints"      SMALLINT,
  "MinHealthPoints"     SMALLINT,
  "MaxHealthPoints"     SMALLINT
);

CREATE OR REPLACE PUMP "STREAM_PUMP" AS
  INSERT INTO "DESTINATION_SQL_STREAM"
    SELECT STREAM "Name", "ROWTIME", SUM("Distance"), MIN("MagicPoints"),
                  MAX("MagicPoints"), MIN("HealthPoints"), MAX("HealthPoints")
    FROM "SOURCE_SQL_STREAM_001"
    GROUP BY FLOOR("SOURCE_SQL_STREAM_001"."ROWTIME" TO MINUTE), "Name";
```

그리고 save and run SQL을 클릭한다.

![40](https://user-images.githubusercontent.com/41605276/67453584-0ef9f180-f662-11e9-84cc-48cb6028e331.jpg)

그러면 아래 그림과 같이 집계된 결과가 전시된다.

![41](https://user-images.githubusercontent.com/41605276/67453592-14573c00-f662-11e9-852d-b824f15736d0.jpg)

화면 상단에 wildrydes를 클릭해서 아래 그림과 같은 콘솔화면으로 빠져나온다.

그런 다음에 connect to a destination을 클릭한다.

![43](https://user-images.githubusercontent.com/41605276/67453608-29cc6600-f662-11e9-89a7-c303be15178b.jpg)

아래 그림과 같이 설정 셋팅을 해준다.

![42](https://user-images.githubusercontent.com/41605276/67453603-220cc180-f662-11e9-949e-d975623eea92.jpg)

step 3-3) Read messages from the stream

cloud9 콘솔로 돌아가서 아래 그림과 같이 ./consumer -stream wildrydes-summary 명령어를 실행해서 데이터가 잘 전시되는지 확인한다.

![44](https://user-images.githubusercontent.com/41605276/67453627-32bd3780-f662-11e9-9ee9-7deb29355d9f.jpg)

step 3-4) Experiment with the producer

새로운 콘솔 터미널을 열어서 아래 그림과 같이 ./producer -name Bucephalus 명령어를 실행한다.

![45](https://user-images.githubusercontent.com/41605276/67453633-38b31880-f662-11e9-8a30-dc321cb00afc.jpg)

#### step 4) Process streaming data

step 4) 에서 구현하고자 하는 아키텍처

![46](https://user-images.githubusercontent.com/41605276/67453640-3e106300-f662-11e9-913e-c374f89e7299.jpg)

step 4-1) Create an Amazon DynamoDB tables

DynamoDB 서비스 콘솔로 접속 -> create table 클릭 -> 아래 그림과 같이 셋팅 및 생성

![47](https://user-images.githubusercontent.com/41605276/67453650-45d00780-f662-11e9-8b88-c89293126aa0.jpg)

생성후 overview 메뉴에서 하단에 ARN 주소 확인, 메모장에 임시기록

![48](https://user-images.githubusercontent.com/41605276/67453655-4bc5e880-f662-11e9-84f9-1829fdfb5bca.jpg)

step 4-2) Create an IAM role for your Lambda function

IAM 서비스 콘솔에 접속 -> 좌측 메뉴에서 policies 클릭 -> create policy 클릭

![49](https://user-images.githubusercontent.com/41605276/67453666-554f5080-f662-11e9-96fa-d80f837b388e.jpg)

아래 그림과 같이 서비스는 다이나모 디비로 설정, actions는 BatchWriteItem를 검색하여 설정, 그리고 리소스에서 table에 add arn 클릭

![50](https://user-images.githubusercontent.com/41605276/67453670-5bddc800-f662-11e9-877e-285b4e47b583.jpg)

아래 그림과 같은 화면에서 지역, 아이디고유번호,테이블이름 기입(메모장에 기록해둔 다이나모디비 arn 주소 참고할 것) 그리고 add 클릭

![51](https://user-images.githubusercontent.com/41605276/67453679-6304d600-f662-11e9-94c5-041dd7c31ead.jpg)

add를 클릭하면 아래 그림과 같은 화면이 전시되는데 우측하단에 review policy 클릭

![52](https://user-images.githubusercontent.com/41605276/67453684-69934d80-f662-11e9-8441-06e654431b2d.jpg)

그러면 아래 그림과 같은 화면이 전시되는데 Name에 WildRydesStreamProcessorRole 기입 후 create policy 클릭

![53](https://user-images.githubusercontent.com/41605276/67453690-7021c500-f662-11e9-96cc-3f5ce8746885.jpg)

IAM 콘솔의 좌측메뉴에서 roles 클릭 -> create role 클릭 -> 아래 그림과 같이 설정 -> 우측하단에 next : permission 클릭

![54](https://user-images.githubusercontent.com/41605276/67453706-80d23b00-f662-11e9-9403-c97c16113c68.jpg)

그러면 아래 그림과 같은 화면이 전시되는데 filter policies창에 AWSLambdaKinesisExecutionRole 을 검색하여 나온 결과의 체크박스 체크

![55](https://user-images.githubusercontent.com/41605276/67453715-862f8580-f662-11e9-9b3e-abb5d0660087.jpg)

 filter policies창에 AWSLambdaKinesisExecutionRole를 지우고 다시 WildRydesDynamoDBWritePolicy 를 입력하여 마찬가지로 검색결과로 나온 것의 체크박스 체크 그리고 next : tags 클릭

![56](https://user-images.githubusercontent.com/41605276/67453726-8cbdfd00-f662-11e9-8c34-d834f5af1001.jpg)

그러면 아래 그림과 같은 화면이 전시되는데 우측하단에 create role 클릭

![57](https://user-images.githubusercontent.com/41605276/67453737-98a9bf00-f662-11e9-87fe-34372ec511e3.jpg)

step 4-3) Create a Lambda function to process the stream

AWS 람다 콘솔로 접속 -> create function 클릭 -> 아래 그림과 같이 설정

![58](https://user-images.githubusercontent.com/41605276/67453844-fa6a2900-f662-11e9-9604-e0a1e608c3e0.jpg)

아래 그림과 같이 하단 코드에디터에 다음 코드들을 입력

![59](https://user-images.githubusercontent.com/41605276/67453850-00600a00-f663-11e9-8762-c73faa95e76f.jpg)


```python
'use strict';

const AWS = require('aws-sdk');
const dynamoDB = new AWS.DynamoDB.DocumentClient();
const tableName = process.env.TABLE_NAME;

exports.handler = function(event, context, callback) {
  const requestItems = buildRequestItems(event.Records);
  const requests = buildRequests(requestItems);

  Promise.all(requests)
    .then(() => callback(null, `Delivered ${event.Records.length} records`))
    .catch(callback);
};

function buildRequestItems(records) {
  return records.map((record) => {
    const json = Buffer.from(record.kinesis.data, 'base64').toString('ascii');
    const item = JSON.parse(json);

    return {
      PutRequest: {
        Item: item,
      },
    };
  });
}

function buildRequests(requestItems) {
  const requests = [];

  while (requestItems.length > 0) {
    const request = batchWrite(requestItems.splice(0, 25));

    requests.push(request);
  }

  return requests;
}

function batchWrite(requestItems, attempt = 0) {
  const params = {
    RequestItems: {
      [tableName]: requestItems,
    },
  };

  let delay = 0;

  if (attempt > 0) {
    delay = 50 * Math.pow(2, attempt);
  }

  return new Promise(function(resolve, reject) {
    setTimeout(function() {
      dynamoDB.batchWrite(params).promise()
        .then(function(data) {
          if (data.UnprocessedItems.hasOwnProperty(tableName)) {
            return batchWrite(data.UnprocessedItems[tableName], attempt + 1);
          }
        })
        .then(resolve)
        .catch(reject);
    }, delay);
  });
}
```

그리고 더 하단으로 스크롤을 내려서 아래 그림과 같이 설정

![60](https://user-images.githubusercontent.com/41605276/67453855-081fae80-f663-11e9-9116-47751e11e777.jpg)

다시 가장 상단으로 스크롤을 올리면 아래 그림과 같은 화면에서 add trigger 클릭

![61](https://user-images.githubusercontent.com/41605276/67453871-0e158f80-f663-11e9-9fcd-79db4934da1d.jpg)

아래 그림과 같이 설정 후 add 클릭 후 빠져나온 화면에서 우측 상단에 save 클릭

![62](https://user-images.githubusercontent.com/41605276/67453876-14a40700-f663-11e9-9b96-c07665a0fd1e.jpg)

step 4-4) Monitor the Lambda function

다시 클라우드9 콘솔로 돌아와서 터미널을 하나 새로 열고 ./producer -name Rocinante 명령어를 실행해서 잘 작동하는지 확인한다.


![63](https://user-images.githubusercontent.com/41605276/67453887-1cfc4200-f663-11e9-9d9d-73bd2faae6b2.jpg)

step 4-5) Query the DynamoDB table

다이나모디비 서비스 콘솔로 접속 -> 왼쪽에서 Tables 클릭 -> UnicornSensorData 선택 -> items 클릭하면 아래 그림과 같이 결과가 나오는지 확인한다.

![64](https://user-images.githubusercontent.com/41605276/67453897-24bbe680-f663-11e9-95e2-64d41153a8bf.jpg)

#### step 5) Store & query Data

step 5) 에서 구현하고자 하는 아키텍처 부분


![65](https://user-images.githubusercontent.com/41605276/67453903-2d142180-f663-11e9-8342-e56766ac1726.jpg)

step 5-1)  Create an Amazon S3 bucket

s3 콘솔로 접속해서 아래 그림과 같이 s3 버킷 하나를 생성해준다.

![66](https://user-images.githubusercontent.com/41605276/67453913-33a29900-f663-11e9-9ac0-327c752f4032.jpg)

step 5-2) Create an Amazon Kinesis Data Firehose delivery stream

키네시스 콘솔로 접속 후 create delivery stream 클릭, 아래 그림과 같이 설정 후 next 클릭

![67](https://user-images.githubusercontent.com/41605276/67453917-38ffe380-f663-11e9-8f8f-1a1c0165e9e1.jpg)

아래 그림과 같이 설정 후 next 클릭

![68](https://user-images.githubusercontent.com/41605276/67453924-3e5d2e00-f663-11e9-88c0-995d94f5073b.jpg)

아래 그림과 같이 설정 후 next

![69](https://user-images.githubusercontent.com/41605276/67453929-44eba580-f663-11e9-8cc9-807bb1ee94dc.jpg)

아래 그림과 같이 설정 후 create new or choose 클릭

![70](https://user-images.githubusercontent.com/41605276/67453936-4b7a1d00-f663-11e9-9ff1-caa12696d060.jpg)

![71](https://user-images.githubusercontent.com/41605276/67453944-50d76780-f663-11e9-972a-4cc444911726.jpg)

아래 그림과 같은 화면이 나오면 allow 클릭

![72](https://user-images.githubusercontent.com/41605276/67453950-56cd4880-f663-11e9-99d7-3cf993df54b3.jpg)

그러면 아래 그림과 같은 화면이 전시가 되는것을 확인하고 next 클릭

![73](https://user-images.githubusercontent.com/41605276/67453958-5c2a9300-f663-11e9-9330-7a3b3e4e4bb7.jpg)

아래 그림과 같이 delivery streams가 생성된 것을 확인

![74](https://user-images.githubusercontent.com/41605276/67453964-62b90a80-f663-11e9-92af-7d24d0401821.jpg)

step 5-3) Create an Amazon Athena table

아테나 콘솔로 접속후 아래 그림과 같이 다음 쿼리를 돌려본다.

![75](https://user-images.githubusercontent.com/41605276/67453970-69478200-f663-11e9-81f6-311d85248296.jpg)


```python
CREATE EXTERNAL TABLE IF NOT EXISTS wildrydes (
       Name string,
       StatusTime timestamp,
       Latitude float,
       Longitude float,
       Distance float,
       HealthPoints int,
       MagicPoints int
     )
     ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe'
     LOCATION 's3://YOUR_BUCKET_NAME_HERE/';
```

step 5-4) Explore the batched data files

아래 그림과 같이 아까 생성한 s3 버킷으로 이동해서 배치 데이터별로 잘 데이터가 생성되었는지 확인한다.

![76](https://user-images.githubusercontent.com/41605276/67453982-6fd5f980-f663-11e9-98bf-b3fe9bfa0cd8.jpg)

step 5-5) Query the data files

아래 그림과 같이 다시 아테나 콘솔로 돌아와서 다음과 같은 쿼리를 날려서 결과를 확인해본다.

`SELECT * FROM wildrydes`

![77](https://user-images.githubusercontent.com/41605276/67453986-75334400-f663-11e9-8d92-e75049fa18d9.jpg)

step 5-6) 실습이 종료되면 사용했던 자원들에 대해 모두 terminate한다.
