---
layout: post
title: "Spark RDD 데이터 출력하기"
tags: [Data Engineering]
comments: true
---

.

Data_Engineering_TIL(20210827)

[학습시 참고자료]

"[Spark] RDD의 내용을 출력하는 방법" 블로그글

https://wooono.tistory.com/127?category=914839

[학습내용]

Local mode(single machine)가 아닌 Cluster mode에서는 RDD를 생성하면 RDD가 각각 노드에 분할 되어 executor에 할당된다.

이때, executor에 할당 된 모든 RDD의 내용을 출력하기 위해서는 collect() 함수가 사용된다.

```java

myrdd.collect().foreach(println)

```

그러나 collect 함수를 사용하면 모든 executor의 rdd를 drvier node로 취합하기 때문에 드라이버 노드의 사양에 따라서 out of memory가 발생할 수 있다.

그래서 이를 해결하기 위해 take 함수가 사용된다.

take 함수는 RDD의 일부 내용만을 출력할 때 사용되며 아래는 100개의 element 만을 print 하는 예이다.

```java

myrdd.take(100).foreach(println)
  
``` 

RDD에 collect함수가 불가능한 경우는 데이터가 너무 크기 때문이며, 대부분의 경우 saveAsTextFile 함수 등을 사용하여 HDFS나 S3와 같은 분산 파일 시스템에 데이터를 write한다.
