---
layout: post
title: "워크로드 특성에 따른 S3 운영방안"
tags: [Data Engineering]
comments: true
---

.

Data_Engineering_TIL(20230123)

### Youtube "워크로드 특성에 따른 안전하고 효율적인 Data Lake 운영 방안 - 박성훈, Account Growth Lead, AWS" 자료를 공부하고 정리한 내용입니다.

** URL : https://youtu.be/-Gc_Jc8ymbQ

## [목차]

1 ) Data Lake 구축의 어려움

2 ) 확장 가능한 S3 key space 설계

3 ) 예기치 못한 사고로부터 데이터 보호

4 ) 비용 최적화

## [공부한 내용]

### 1 ) Data Lake 구축의 어려움

<img width="891" alt="1" src="https://user-images.githubusercontent.com/41605276/213968150-41b9fc53-c581-4e76-bc80-bc46e4ad140b.png">

서비스를 운영하면서 발생하는 데이터의 양이 점점 증가하고 있다. 새로운 소스, 새로운 데이터 format 등 데이터의 특성도 점점 다양해지고 있다. 그리고 수집되고 저장된 데이터는 분석가, 사이언티스트 등 다양한 사용자와 응용프로그램이 안전하게 액세스하고 분석할 수 있어야 한다. 또한 데이터를 사용하는 사용자는 self-service를 통해서 해당 데이터를 직접 사용하기를 원하는 추세이다.

<img width="920" alt="2" src="https://user-images.githubusercontent.com/41605276/213968209-b1782c51-bbbd-4724-95c8-5ccfe4937b19.png">

최신 데이터 처리 전략은 위와 같은 아키텍처로 구성한다고 할 수 있다.

<img width="983" alt="3" src="https://user-images.githubusercontent.com/41605276/213968390-f1c1ed23-959f-4d64-a1ad-530f1409397d.png">

Data Lake를 구축한다는 것은 위와 같은 장점을 취할 수 있다는 것이다. 정형 및 비정형 데이터 등 모든 데이터를 비용 효율적으로 저장할 수 있다. 또한 데이터를 오픈형식으로 저장하면 스토리지와 컴퓨팅을 분리할 수 있다는 이점을 취할 수 있다. 따라서 데이터를 분석할때 가장 적합한 처리방법을 자유롭게 채택해서 데이터를 처리할 수 있다는 장점이 있다.

<img width="941" alt="4" src="https://user-images.githubusercontent.com/41605276/213968770-da44768c-1fb3-4386-84dc-d21a3743615c.png">

하지만 데이터 레이크를 구축하는 것은 쉬운게 아니다. 일반적으로 데이터 레이크를 구축하면서 겪는 어려운 점은 아래와 같다.

challenge #1 Data Ingestion : 신뢰할 수 있는 데이터 파이프라인을 구축하는 것은 복잡하다.

challenge #2 Data Management : S3에 데이터를 저장하고 최적화하는데 시간이 많이 걸린다.

challenge #3 Security & Governance : 세분화된 권한을 관리하는 것이 어렵고 오류가 발생하기 쉽다.

challenge #4 Integrations : 선택한 서비스나 어플리케이션을 통합하는 것이 어렵다.

challenge #5 Data Sharing : 계정 및 조직간에 공유하는 것은 복잡하다.

#### 이번 세미나에서는 "challenge #2 Data Management : S3에 데이터를 저장하고 최적화하는데 시간이 많이 걸린다." 에 대해 알아볼 것이다.

### 2 ) 확장 가능한 S3 key space 설계

<img width="787" alt="5" src="https://user-images.githubusercontent.com/41605276/213969845-52dc7473-022f-42d6-af9f-bafbf1784944.png">

S3는 index partition 당 GET/HEAD 요청의 경우 초당 5500건의 요청을 처리할 수 있고, PUT/POST/DELETE의 경우 초당 3500건의 요청을 처리할 수 있다. 한개의 S3 bucket에 최대로 저장할 수 있는 접두사 및 객체의 수는 제한이 없다. 그리고 하둡이나 스팍 워크로드의 경우 S3에 객체를 저장하고 사용하는 중에 503 Slow Down 에러가 발생하기도 하는데 접두사 하위에 많은 객체에 동시에 많은 요청이 발생할 수 있기 때문에 현재 구성에서 처리가 가능한 요청수를 초과하게 되면 발생할 수 있다. S3 503 Slow Down 에러는 S3로 들어오는 요청이 지원할 수 있는 처리량을 초과했다는 것을 의미한다. S3-A나 EMRFS를 사용하는 경우에도 재시도 횟수를 조정하여 S3 503 Slow Down 에러로 인해 작업이 실패하는 것을 완화할 수 있다.

<img width="907" alt="6" src="https://user-images.githubusercontent.com/41605276/213970846-63242758-00ba-403c-b48e-fdc5ae91cd32.png">

그러면 PUT/GET 요청이 동시에 들어온다면 하나의 인덱스 파티션에서 처리할 수 있는 처리량은 얼마나 될까. 특정 인덱스 파티션으로 들어오는 전체 요청의 50%가 PUT 요청이고 나머지 50%가 GET 요청이라고 가정하면 초당 4500건의 요청을 처리할 수 있다. 두번째 예로 특정 인덱스 파티션으로 들어오는 전체 요청의 30%가 PUT 요청이고 나머지 70%가 GET 요청이라고 가정하면 초당 4900건의 요청을 처리할 수 있다. S3 bucket으로 들어오는 요청이 항상 동일한 요청으로 들어오는 경우는 없으므로 하나의 인덱스 파티션에서 처리할 수 있는 워크로드의 I/O 패턴에 따라 달라지게 된다.

그렇다면 초당 처리량을 늘리기 위해서는 어떻게 해야할까.

<img width="653" alt="7" src="https://user-images.githubusercontent.com/41605276/213971462-bc675cab-b455-4942-8c98-f1876cfdae01.png">

요청을 더 많은 인덱스 파티션으로 분할하여 초당 처리량을 늘릴 수 있다. 요청을 분산하기 위해 필요한 추가 파티션을 만드는 방법은 두가지가 있다.

방법 1. Auto partitioning

사용자의 개입없이 S3에서 자동으로 수행하는 방법임

시간이 지남에 따라 S3 워크로드가 점차 증가할때 S3는 워크로드를 분석하고, 필요하다면 추가 인덱스 파티션을 생성하게 된다. 이를 위해서는 S3가 워크로드에 적합한 파티션을 생성할 수 있도록 워크로드의 I/O 패턴을 고려한 확장 가능한 key space를 설계하는 것이 중요하다.

방법 2. Pre-partition request

AWS Case open을 통해 index partition 생성을 요청하는 방법임

S3 워크로드가 빠르게 증가할때 선호

<img width="839" alt="8" src="https://user-images.githubusercontent.com/41605276/213972213-f7ddd98e-a737-42d4-a3ab-8d73a184114d.png">

위의 그림은 S3 auto partitioning이 동작하는 방식을 잘 보여주는 그림이다. 그래프의 x축은 시간, y축은 put 요청과 에러수를 의미한다. 그래프 상단의 주황색선은 put 요청수를, 초록색 선은 OXX 에러수를 의미한다. 여기서 OXX 에러는 S3 500과 503 에러를 의미한다. 이 그래프는 S3의 클라우드워치 메트릭으로 확인이 가능하다. 그래프를 보면 지속적으로 동일한 양의 put 요청을 S3로 보냈을때 최초에는 27만개의 OXX 에러가 발생하지만, 점차적으로 에러수가 줄어드는 것을 알 수 있다. 이는 S3가 워크로드를 분석한후 인덱스 파티션을 생성하여 분산한다는 것을 알 수 있다.

<img width="939" alt="9" src="https://user-images.githubusercontent.com/41605276/213972835-820f1da5-ed01-4ef4-855b-f950a3d5e46a.png">

구체적인 사례를 알아보자. 18년 7월 이전에는 S3가 요청을 여러 인덱스 파티션에다가 분산하는데 용이하도록 접두사에 해시값을 추가하는 것을 AWS에서 권고를 했었다. S3는 해시가 추가된 접두사를 사용해서 필요할시 인덱스 파티션을 생성했다.

<img width="952" alt="10" src="https://user-images.githubusercontent.com/41605276/213973143-0e9bdacc-ce4f-4a10-bd1f-cf81b1579e8a.png">

하지만 18년 7월부터 GET/HEAD 요청은 초당 5500건, PUT/POST/DELETE의 경우 초당 3500건을 처리하는 성능을 제공하고 있다. 그래서 대부분의 경우 key space 설계시 무의미한 해시값을 접두사로 사용하지 않다도 무방해졌다. 초당 처리할 수 있는 요청건수는 증가했지만 요청이 여러 인덱스 파티션으로 분산될 수 있도록 key space를 설계해야하는 것은 여전히 고려대상이다. 이를 위해 카디날리티가 높은, 즉 중복도가 낮은 접두사를 사용하는 것이 중요하다.

- Example: Autonomous vehicles

첨단 운전자 보조시스템 ADAS를 통해 데이터를 수집하는 사례이다. 데이터를 수집하는 자동차들은 매일 아침 차고지를 출발해 거리로 나가서 데이터를 수집한 후, 거의 동시에 차고지로 돌아와 수집한 데이터를 S3 데이터 레이크레 업로드를 한다. S3에 업로드된 데이터는 전처리 과정을 거쳐 종류에 따라 분류된 후 ADAS 칩 트레이닝을 위해 사용된다. 

1 ) 많은 계측 자동차가 중앙에 위치하고 있습니다.

2 ) 매일 그 자동차들은 운전을하고 많은 데이터를 수집합니다. 

3 ) 거의 동시에 차고지로 돌아와서 수집한 데이터를 데이터레이크에 업로드합니다.

이번세션에서는 수집된 데이터를 S3 데이터 레이크로 업로드하는 부분만 살펴볼 것이다.

<img width="875" alt="11" src="https://user-images.githubusercontent.com/41605276/213974210-b4418a28-6b23-4f06-a4be-b5f31b90a7df.png">

먼저 S3 request rate에 대한 이해를 위해 key space 구조에 대해 알아보자. S3 key space는 먼저 버킷이름과 객체 key 이름으로 구성이 된다. 객체 key는 또 접두사와 객체 이름으로 분류할 수 있다.

<img width="913" alt="12" src="https://user-images.githubusercontent.com/41605276/213974517-fbf84bdf-cf02-4a8a-8c7f-0e6d274c402a.png">

이 사례의 요구사항은 수집한 데이터를 각 자동차에서 S3로 초당 3000건의 PUT 요청을 실행할 수 있어야 한다는 것이다. 이는 총 다섯대의 자동차가 업로드하는 초당 15000건의 PUT 요청을 처리할 수 있어야 한다는 것을 의미한다. 앞서 얘기한것처럼 PUT 요청만 발생했을때 하나의 인덱스 파티션에서 처리할 수 있는 PUT 요청건수는 초당 3500건이다.

<img width="751" alt="13" src="https://user-images.githubusercontent.com/41605276/213975385-f12935b5-9c61-4d46-a87b-beb6de6d2b95.png">

위에 그래프를 보게 되면 각 자동차에서 S3로 초당 3000건의 PUT 요청을 했을때 처음부분에는 전체 15000건의 요청중 3500건의 PUT 요청만 처리되는 것을 알 수 있다. 이때 각 자동차에서는 503 slow down 에러가 발생하게 된다. 업로드하는 어플리케이션은 AWS SDK 사용하여 개발되었기 때문에 설정에 따라 재시도를 수행할 것이다. 시간이 지남에 따라 초당 15000건이 처리되는 것을 확인할 수 있다. 이는 S3가 워크로드를 분석하고 워크로드의 요청을 수용하기 위해 필요한 추가 인덱스 파티션을 생성했기 때문이다. 또한 이 그래프를 통해 한가지 더 확인할 수 있는 것은 초당 15000건이 처리되기 전에도 처리량이 조금씩 증가 했다는 것이다. 이를 통해서 S3가 인덱스 파티션을 한방에 생성하는 것이 아니라 워크로드를 분석하여 점진적으로 생성한다는 것을 알 수 있다.

<img width="927" alt="14" src="https://user-images.githubusercontent.com/41605276/213975710-81c1dab0-9ae0-4a39-8ed1-306f11c0e0cd.png">

동시에 S3로 들어오는 요청을 충분히 처리할 수 있는 인덱스 파티션이 만들어질때까지 쓰로틀이 발생하고, 이때 S3는 503 slow down 에러를 어플리케이션에 반환한다. 이번 사례의 key space를 고려할때 자동차 이름 앞의 버킷이름/샤딩일자 까지는 접두사가 모두 동일한 것을 알 수 있다.

<img width="664" alt="15" src="https://user-images.githubusercontent.com/41605276/213975992-8af9a807-b6d0-447d-9023-9b58e922dbdf.png">

따라서 S3는 각 자동차 이름의 접두사로 인덱스 파티션을 만들게 된다. 그러면 5개의 인덱스 파티션이 만들어지게 된다. 그래서 20220710에 다섯대의 자동차가 보내는 초당 15000건의 PUT 요청은 잘 처리될 것이다.

<img width="927" alt="16" src="https://user-images.githubusercontent.com/41605276/213976227-b06b76c2-0dc9-47fb-a14c-195b43408fe2.png">

그러면 그 다음 날에도 다섯대의 차량은 다시 거리로 나가 데이터를 수집하고 저녁에 차고지로 돌아와서 전날과 동일하게 초당 15000건의 PUT 요청을 만들게 될 것이다. 전날 생성한 인덱스 파티션이 있기 때문에 쓰로틀링 없이 요청을 모두 잘 처리할 수 있을까. 그 전날 S3는 20220710과 {자동차이름}으로 다섯개의 인덱스 파티션을 생성했다. 하지만 20220711에 업로드되는 객체의 key space에서 사용된 날짜는 전날과 다른 20220711이기 때문에 전날 생성된 인덱스 파티션을 사용할 수 없다. 따라서 각 자동차는 전날과 동일하게 S3가 충분한 인덱스 파티션을 생성할때까지 어제와 동일한 현상의 S3 503 Slow Down 에러가 발생할 것이다.

그러면 어떻게 하면 이 현상을 해결할 수 있을까.

<img width="674" alt="17" src="https://user-images.githubusercontent.com/41605276/213976859-92f62bce-c0d8-4a07-918d-34547841c32b.png">

날짜 접두사와 자동차 이름 접두사 위치를 바꿔서 해결할 수 있다.

<img width="647" alt="18" src="https://user-images.githubusercontent.com/41605276/213976993-8f260e21-7bd3-4577-83ea-000603e95714.png">

새로운 S3 key space에서는 날짜 접두사 앞에 자동차이름 접두사를 가지고 인덱스 파티션을 만들것이다. 따라서 20220711에 다섯개의 접두사가 만들어지고, 초당 15000건의 PUT 요청을 처리할 수 있다.

<img width="640" alt="19" src="https://user-images.githubusercontent.com/41605276/213977196-3a016ccf-e96f-4daf-9ecd-774e252f6a97.png">

그리고 다음날인 20220712에 즉, 날짜 접두사가 변경되었더라도, 자동차이름 접두사에서 이미 5개의 파티션이 만들어져 있기 때문에 2022년 7월 12일에 수집한 데이터를 S3에 업로드할때 전날 생성된 인덱스 파티션을 사용하게 된다. 따라서 S3는 초당 15000건의 PUT 요청을 쓰로틀링 없이 처리할 수 있게 된다.

<img width="793" alt="20" src="https://user-images.githubusercontent.com/41605276/213977548-993f1037-402d-4956-8b6e-b87fd7f92815.png">

일반적으로 클라이언트에서 S3로 접근하는 방식을 알아보자. 하나의 클라이언트에서 mybucket에 flight_info라는 접두사를 가진 모든 객체를 가져온다고 가정하자. 클라이언트는 해당 접두사 아래에 있는 모든 객체를 순차적으로 가져오게 된다. 따라서 GET 요청의 제한값인 1초의 5500건을 넘을 가능성은 거의 없다고 할 수 있다.

<img width="814" alt="21" src="https://user-images.githubusercontent.com/41605276/213978022-1db85e97-e8f9-4e1f-b6a2-d8293aa77f00.png">

그러면 EMR 클러스터에서 S3에 요청을 보내는 방식을 알아보자. 하둡에서는 하나의 job을 작은 단위의 task로 분할하여 여러 컨테이너에서 동시에 작업을 실행하게 된다. 따라서 flight_info라는 접두사 아래에 모든 객체를 가져오는 작업을 한다고 하면 각각의 컨테이너에서 접두사 아래에 있는 객체들을 나누어서 병렬로 가져오게 된다. 일반적으로 S3에서는 성능향상을 위해 위해 병렬로 처리하는 것을 권장한다. 하지만 EMR 클러스터의 크기에 따라 많은 컨테이너에서 동시에 flight_info라는 접두사 아래에 객체들에 GET 요청을 보내게 되면 하나의 접두사에서 처리할수 있는 요청수를 초과할 수 있다.

<img width="831" alt="22" src="https://user-images.githubusercontent.com/41605276/213978600-392e30af-84f7-4015-88c6-e210e57e716d.png">

그런데 만약에 위에 그림과 같이 병렬 처리하는 컨테이너 들의 요청을 하나의 접두사에서 처리하는 것이 아니라 두개의 접두사로 나누어서 처리하게 되면 각 접두사별로 인덱스 파티션이 만들어져 있는 경우 요청은 두개의 인덱스 파티션으로 분산되고 S3가 동시에 처리할 수 있는 요청도 두배가 된다. 따라서 워크로드의 I/O 패턴을 고려한 S3 Key space 설계는 빅데이터를 처리하는 환경에서는 테이블 파티셔닝과 함께 필수적으로 고려해야하는 사항이라고 할 수 있다.

<img width="814" alt="23" src="https://user-images.githubusercontent.com/41605276/213979058-e09bc190-eab1-479e-bc39-f98d8bf17406.png">

버킷이 생성되면 버킷의 모든객체는 동일 인덱스 파티션을 공유하게 된다. 하나의 인덱스 파티션에서 처리할 수 있는 요청보다 더 많은 요청이 flight_info 접두사 아래에 있는 객체들로 들어오면 S3는 워크로드를 분석하고 flight_info에 대한 인덱스 파티션을 생성한다.

<img width="800" alt="24" src="https://user-images.githubusercontent.com/41605276/213979377-aed84635-9b63-46c4-8a16-efd11ad6714d.png">

이 작업이 완료되면 위에 그림과 같이 두개의 파티션에서 기존대비 두배의 요청을 처리할 수 있게 된다. 

<img width="956" alt="25" src="https://user-images.githubusercontent.com/41605276/213979703-8919265a-fd60-45f2-9102-ca7c92560ca0.png">

인덱스 파티션을 만든 이후에도 flight_info 접두사로 들어온 요청이 지속적으로 하나의 인덱스 파티션에서 처리할 수 있는 요청수를 초과하게 되면 S3는 그 요청을 모두 수용할수 있을때까지 모든 접두사들에 대한 인덱스 파티션을 만들게 된다. 하지만 S3에서 인덱스 파티션을 만드는 것은 필요한 인덱스 파티션을 한번에 모두 만드는게 아니라 워크로드를 분석하여 점진적으로 만들게 된다. 따라서 초기 S3 데이터 레이크 구축을 준비할때 pre partitioning을 통해서 인덱스 파티션을 미리 확보하는 것을 고려할 필요가 있다. 이를 위해서는 워크로드에 대한 충분한 이해를 바탕으로 설계된 key space가 중요하다.

### 3 ) 예기치 못한 사고로부터 데이터 보호

IAM과 S3 버킷 정책을 활용해서 접근제어를 하더라도 악의적인 데이터 삭제나 권한이 있는 사용자의 실수로 인해 사고가 발생할 수 있으므로 사고가 발생했을때 복구할 수 있는 방안을 알고 있어야 한다. 데이터 유실위험으로부터 데이터를 보호하기 위해 S3에서 제공하는 기능들과 AWS backup에 대해서 알아보자.

<img width="926" alt="26" src="https://user-images.githubusercontent.com/41605276/213980488-b1cb0fd4-1b69-4915-ba68-e4214e8451b0.png">

S3 versioning이라는 기능이 있는데 이 기능을 enable하면 실수로 객체를 덮어쓰거나 삭제하였을때 복구가 가능하다. S3 versioning을 사용하면 동일이름의 객체를 PUT하더라도 기존객체는 덮어쓰지 않고 유지하게 된다. 따라서 복구가 필요하면 새로 업로드 된 객체를 삭제하거나 기존객체를 복사해서 복구할 수 있다.

<img width="384" alt="27" src="https://user-images.githubusercontent.com/41605276/213980801-70be26c4-35e6-4a00-ac3b-19f76d619dae.png">

그리고 실수로 객체를 삭제하더라도 애플리케이션 입장에서는 객체가 삭제된 것으로 보이지만 기존객체는 삭제되지 않고 delete marker가 생성된 것이기 때문에 delete marker를 삭제하거나 삭제한 해당 객체를 복사해서 복구가 가능하다.

<img width="939" alt="28" src="https://user-images.githubusercontent.com/41605276/213981051-a7c95bdc-b65a-4cb1-a318-6a06afd9fee4.png">

버저닝 기능이 켜져있는 S3 bucket에 객체를 업로드하게 되면 각 객체마다 버전 아이디가 생성된다. 그리고 동일한 이름을 갖은 객체를 구별할때 객체 이름과 함께 버전 아이디를 사용한다. 위에 그림을 보면 versioning-test.pdf라는 이름의 객체가 3개가 있고 1개의 delete marker가 있다. 그리고 모든객체와 delete marker는 각각 다른 버전 아이디를 가지고 있다. 각 객체의 last modified column을 보면 맨 마지막줄에 있는 객체가 가장 먼저 업로드 된 객체이고, 맨 위에 있는 객체가 가장 최근에 업로드된 객체임을 알 수 있다. 그리고 동일한 이름을 가진 객체가 업로드 되면 버저닝이 켜져있기 때문에 덮어쓰지 않고 버전 아이디로 각 객체를 구분해서 저장하는 것을 알 수 있다. 이 상태에서 해당 객체에 대해서 GET 요청을 하게되면 S3는 최신버전의 객체를 반환하게 된다. 그리고 delete marker 객체는 실제 객체가 아니다. 이는 아래에서 두번째 객체가 최신버전일때 delete 요청이 있었다는 것을 짐작할 수 있다. 그리고 객체에 대한 delete 요청이 발생해도 해당객체를 실제로 삭제하지 않는 것을 알 수 있다. 그리고 당연한 얘기겠지만 객체가 delete marker가 최신버전일때 GET 요청이 오게되면 S3는 404 에러를 반환하게 된다.

<img width="933" alt="29" src="https://user-images.githubusercontent.com/41605276/213982249-77861e08-528a-46f4-b57c-7524f1f5f744.png">

그리고 S3 replication이라는 기능도 있다. 이 기능은 S3 bucket간에 데이터를 복제하는 탄력적이고 저렴한 완전관리형 기능이다. 복제할 위치와 방법을 제공한다. 복제 규칙이 정해지면 S3가 원본 버킷의 객체와 메타데이터를 자동으로 복제하게 된다.

<img width="904" alt="30" src="https://user-images.githubusercontent.com/41605276/213982804-34885fac-f326-4fce-bc34-3fca0bca13fd.png">

S3 replication은 다양한 복제방법을 제공한다. S3 replication이 복제한 데이터를 사용하여 삭제된 데이터를 복구할수 있다. 다른 계정간 복제의 경우 객체에 대한 접근권한을 완전히 분리할 수 있기 때문에 악의적인 사고로 인한 데이터 유실상황에서도 데이터를 안전하게 보호하고 복구할 수 있다. 여기서 악의적인 사고로 인한 데이터 유실상황은 버저닝이 켜져있는 버킷에 객체인 경우에도 객체의 버전아이디를 확인하여 삭제하게 되면 특정 객체의 삭제가 가능하다. 따라서 이를 방지하기 위해 서로 다른 AWS 계정간 복제를 통해 접근권한을 완전히 분리할 필요가 있다.

<img width="955" alt="31" src="https://user-images.githubusercontent.com/41605276/213983374-a88bb059-1fdb-455a-b76b-84ca250661d1.png">

AWS backup은 정책을 기반으로 대규모 데이터를 간편하고 비용효율적으로 실행할 수 있는 완전관리형 서비스이다. 데이터 유실 발생시 S3 bucket 및 객체를 신규 또는 기존 s3 bucket으로 복원할 수 있다.

<img width="921" alt="32" src="https://user-images.githubusercontent.com/41605276/213983668-bb9094e1-e7d2-40d0-9313-50dd077848f2.png">

RPO : 특정일, 하루전, 일주일전, 한달전 등으로 복원시점을 정할 수 있다.

RTO : 복구에 걸리는 시간을 의미한다.

참고로 연속백업은 최대 35일간까지 저장이 가능하다.

또한 AWS backup은 교차리전, 교차계정 백업도 가능하다.

S3 replication 및 AWS backup은 기본적으로 S3 versioning이 셋팅이 되어야 사용이 가능한 기능이다.

참고로 S3 versioning을 켜게 되면 객체 아이디가 엄청나게 많아질 여지가 있고 이는 S3 list API 성능에 악영향을 주고 불필요한 비용을 발생시킬 수 있으니 주의해야 한다. 따라서 불필요한 버전 아이디 객체를 주기적으로 삭제해주는 작업이 필요하다.

<img width="907" alt="33" src="https://user-images.githubusercontent.com/41605276/213984661-a52d27e7-fde9-4e58-8df1-4118ab58806d.png">

<img width="857" alt="34" src="https://user-images.githubusercontent.com/41605276/213984826-d9112a10-f8cf-4f7e-9486-0c880abef2d2.png">

S3 lifecycle이라는 기능이 있는데 이것을 사용하면 위와 같은 문제를 해결 할 수 있다. 더 이상 보존할 필요가 없는 데이터 세트의 자동삭제 설정을 제공한다.

<img width="950" alt="35" src="https://user-images.githubusercontent.com/41605276/213985100-eaca9227-c9a1-4b47-8acd-4f434620ab18.png">

또한 S3는 데이터의 보호를 위해 S3 Obiect Lock 라는 기능도 제공한다.

ObiectLock은 고정된 시간동안 또는 무기한으로 객체의 삭제 또는 덮어쓰기를 방지하는데 도움이될수 있지만 데이터 레이크 데이터 스토어로 사용되는 S3 버킷에 적용하는 것은 아주 신중히 고려해야 한다. 또한 ACID transaction을 지원하는 apache iceburg나 hudi 그리고 AWS lakeformation의 경우 사용하는 ACID transaction의 프레임 워크에 따라 작은 file들을 merge하기 위해 compaction을 수행하기도 한다. 이경우에 S3 Obiect Lock이 켜져있다면 compaction 작업후 기존객체가 삭제되지 않고 그대로 존재하게 된다. 따라서 AWS object Lock이 고정된 시간 동안 또는 무기한으로 객체의 삭제 및 덮어쓰기를 방지하는데 도움이 될수는 있겠지만 데이터 레이크 스토어로 사용하는 환경에서라면 S3 Obiect Lock의 사용을 매우 신중하게 고려해야 한다.

### 4 ) 비용 최적화

intelligent-tiering 기능을 사용하면 비용 최적화에 도움이 되지만 아래와 같이 고려해야 하는 사항도 있으니 주의해야 한다.

<img width="957" alt="36" src="https://user-images.githubusercontent.com/41605276/213986923-f3cd7ea3-5209-476f-a237-4ea3187d249c.png">

S3 Storage Lens 기능도 사용하면 좋다.

<img width="936" alt="37" src="https://user-images.githubusercontent.com/41605276/213987263-953bf3cc-c998-4f00-b302-e670d0f3269c.png">

<img width="876" alt="38" src="https://user-images.githubusercontent.com/41605276/213987513-9e47903d-1e65-413d-924e-6658543dce1b.png">

추가로 아래에 페이지 내용도 참고할 것

https://minman2115.github.io/DE_TIL74