---
layout: post
title: "AWS EKS 위에서 Jupyter Hub 분석 환경 구현하기"
tags: [Data Engineering]
comments: true
---

.

Data_Engineering_TIL_(20191026)

study program : https://www.meetup.com/awskrug

### [학습시 참고자료]

1) AWS EKS 위에서 Jupyter Hub 분석 환경 제공하기 / '19.10.26.(토) AWSKRUG Hands-on 세미나

URL : bit.ly/2IMGeVZ


2) 핸즈온 가이드

URL : bit.ly/31PUfst


### [세미나 필기노트]

1) AWS resource 생성 및 관리를 위한 `Terraform`

- 코드로 인프라 관리가 가능하기 때문에 인프라 재사용이나 이력관리가 매우 용이


- 이미 존재하는 레거시 리소스도 Import 가능


- Template 기능 존재


2) Terraform을 사용하는 이유

- 인프라를 코드로 관리하기 때문에 어떤 변화가 잇을지, 왜 변화하였는지 명확한 이력관리가 가능


- 이런 용이함은 보안과 관련된 AWS Security Group, IAM 등의 히스토리 및 변화관리에 매우 좋다.


- 복잡한 인프라 구성을 코드로 관리하기 때문에 재활용이 매우 쉽다.


- 어플리케이션의 라이브러리처럼 테마폼 모듈을 만들어 재활용이 쉽다.


- 복잡한 설정을 가진 AWS 리소스의 경우도 쉽게 재생성할 수 있다.


- Template (설정 파일 생성) + Bootstrap Action (EC2 시작시 초기화 스크립트) 기능이 가능하다.


- AWS UI에서는 설정이 보이지 않거나, 번잡한 옵션도 한번에 / 한곳에서 설정이 가능하다.


3) Terraform Remote State, Lock

- 생성된 EC2 머신의 Private IP Address 등 Terraform 실행 결과는 State 가 되어 기본적으로는 Local에 저장


- 현재 프로젝트의 Terraform State 를 다른 프로젝트 / 혹은 다른 사람과 공유하기 위해 Local 이 아닌 외부 저장소에 관리 가능: Remote State 


- AWS 위에서는 S3 를 Remote State Backend 로 사용 가능


- Terraform 을 이용해 한 작업자가, AWS 리소스를 변경하는 동안 다른 변경을 막기 위해 Terraform Lock 을 이용


- AWS 위에서는 Dynamo DB 를 사용해 Lock 관리 가능


4) Storage 어플리케이션 설치 및 운영을 위한 `Ansible`

- 파이썬으로 구현된 오픈소스 IT 자동화 도구


- 서버 설정, 미들웨어 설치, 소프트웨어 배포, 복수의 호스트를 자동화 구성 관리 도구


- 어플리케이션 설치 및 설정관리, 업그레이드 가능


- 기타 필요한 모니터링 Agent 등등 설치


- 이미 존재하는 Playbook 활용 가능


5) Terrfor과 Ansible 활용양상

![000](https://user-images.githubusercontent.com/41605276/67650799-c86a0700-f981-11e9-9ad7-a37180592b9f.png)

6) 어플리케이션 클러스터링을 위한 `Kubernetes`

- High Availability, (Auto) Scaling, Load Balancing 등을 제공하는 Container Cluster


- Helm을 이용하여 설치가 복잡한 Application Set 를 묶어 Package 로 쉽게 설치 가능하도록 제공


- AWS 등 각 클라우드 밴드와 잘 연동되어 Scaling, Spot Instance 등 제공


- 유연한 리소스 관리 (저사양 Pod 은 저사양 Node = EC2 에 할당)


- Pod 마다 리소스 제한 (CPU, Memory 등)


- 사용자별로 독립적인 환경 (Pod) 제공 가능


- Cloud Vendor 레이어 추상화 (Kubernetes Volumne = AWS EBS, …)


** Node = EC2, Pod = 사용자 Jupyter


7) AWS Managed Kubernetes `AWS EKS`


- AWS 가 관리해주는 Kubernetes (Master 노드)


- 기존 Kops 등 도구에 에 비해 Kubernetes Cluster 설치가 아주 편리


- AWS VPC CNI, Cluster Log 수집, Cluster 업그레이드 등 AWS 가이드 또는 지원


8) 멀티 유저의 Jupyter Notebook 사용을 위한 `Jupyter Hub`

- 본래 Jupyter 는 개인 노트북에서 실행되는 개인별 노트북


- JupyterHub 는 다수의 사용자에게 Jupyter 할당 할 수 있도록 만들어짐


- Google Auth, LDAP 등 인증 및 사용자관리


- Cluster 리소스를 나누어 사용가능


- 접속한지 오래된 노트북은 자동으로 Shutdown (Culling) 

9) Jupyter Hub 를 Kubernetes 위에 설치한다면

- Kubernetes 의 리소스 관리 기능 활용


- Helm Package 로 쉽게 설치


- Dockerfile을 이용하여 Jupyter Container 이미지는 쉽게 확장 


10) Jupyter Hub - Jupyter Docker Image

![000-2](https://user-images.githubusercontent.com/41605276/67650813-cf911500-f981-11e9-9d23-e184b564cc75.png)

11) Jupyter Hub - Multiple Hub Charts

- Jupyter Hub 는 사용자마다 Container Image 에 대한 접근제어 불가능


- 등록된 사용자는 모든 등록된 Jupyter Container Image 사용하기 때문에 고사양 / 또는 용도에 따라 Jupyter Hub를 여러개 설치해 운영 가능


- 예를들어서 Ad-hoc 한 분석용 고사양 Jupyter Hub, 스케쥴링용 저 / 중간사양 Jupyter Hub, S3 (Parquet w/ Hive Meta) 접근이 가능한 Jupyter Hub 등


- 하나의 EKS 클러스터에 Namespace 만 나누어 여러개의 Jupyter Hub 설치하기 때문에 리소스를 나누어 사용하므로 별도의 비용 X


### [핸즈온 개요]

#### 1) 목표

Terraform, AWS EKS 등을 이용하여 Jupyter Hub 분석환경 구현

#### 2) 목차

STEP 1) 핸즈온 준비하기

- 실습 클라이언트(EC2) 구동, 패키지툴 최신화, 깃설치


- AWS IAM 사용자 Administrator 생성, 권한부여 및 AWS Access Key 생성, 설정


- aws-iam-authenticator 설치


- Docker 설치


- Terraform 설치


- Kubectl (Kubernetes Client) 설치


- EC2 클라이언트를 위한 SSH 키 생성


- 실습 코드 Clone 받기


- Terraform State 를 위한 S3, Dynamo 생성


STEP 2) Github 에서 받은 소스 코드 내 S3 경로 수정


STEP 3) Terraform 으로 AWS IAM 생성


STEP 4) Terraform 으로 AWS VPC생성


STEP 5) Terraform 으로 AWS EKS 생성


STEP 6) Kubernetes 내 JupyterHub 설치


STEP 7) (선택) Custom Docker Image 빌드


### [핸즈온 상세내용]

### STEP 1) 핸즈온 준비하기

STEP 1-1) 실습 클라이언트(EC2) 구동, 패키지툴 최신화, 깃설치

아래 그림과 같이 핸즈온간 사용할 EC2를 구동하고, 패키지 툴을 최신화시켜준다.

마지막으로 `sudo yum install git`을 실행하여 git을 설치해준다.

![00](https://user-images.githubusercontent.com/41605276/67650824-d750b980-f981-11e9-8b52-5ed41ab0c83c.png)

STEP 1-2) AWS IAM 사용자 Administrator 생성, 권한부여 및 AWS Access Key 생성, 설정

![1](https://user-images.githubusercontent.com/41605276/67650829-dc156d80-f981-11e9-9a6b-e20cd2c04f21.png)

STEP 1-3) aws-iam-authenticator 설치

아래 그림과 같이 EC2에서 명령어들을 실행하여 설치한다.

참고 URL : https://docs.aws.amazon.com/ko_kr/eks/latest/userguide/install-aws-iam-authenticator.html

![7](https://user-images.githubusercontent.com/41605276/67650842-e3d51200-f981-11e9-8f86-03e859217d56.png)

STEP 1-4) Docker 설치

아래 그림과 같이 EC2에서 명령어를 실행하여 설치한다.

![8](https://user-images.githubusercontent.com/41605276/67650847-ea638980-f981-11e9-9d5d-35ba0601e39a.png)

STEP 1-5) Terraform 설치

아래 그림과 같이 명령어들을 실행하여 설치한다.

참고 URL : https://learn.hashicorp.com/terraform/getting-started/install.html

![9](https://user-images.githubusercontent.com/41605276/67650853-f0f20100-f981-11e9-8ba1-65782cac05f2.png)

STEP 1-6) Kubernetes 설치

아래 그림과 같이 명령어들을 실행하여 설치한다.

참고 URL : https://kubernetes.io/docs/tasks/tools/install-kubectl/

![12](https://user-images.githubusercontent.com/41605276/67650857-f7807880-f981-11e9-97f2-014f2a173c25.png)

STEP 1-7) EC2 클라이언트를 위한 SSH 키 생성

아래 그림과 같은 명령어들을 실행하여 SSH키를 생성해준다.

![13](https://user-images.githubusercontent.com/41605276/67650865-fcddc300-f981-11e9-88e6-8f9599582302.png)

STEP 1-8) 실습코드 Clone 받기

EC2에서 아래 그림과 같은 명령어를 이용하여 실습코드를 다운받는다.

![15](https://user-images.githubusercontent.com/41605276/67650872-036c3a80-f982-11e9-90f5-635955e61f49.png)

STEP 1-9) Terraform State 를 위한 S3, Dynamo 생성

- Terraform 의 Remote State 저장을 위해  AWS S3 (State) 와 Dynamo DB (Lock) 이 필요하다.


- Seoul Region (ap-northeast-2) 에 S3 Bucket 을 생성


- 이름은 terraform-{something} 하되 S3 이름은 공유되어 다른 사람과 중복 생성이 불가능하므로 {something} 을 자신이 원하는 이름으로 변경하여 기억하기 쉽게 만든다.


- Seoul Region (ap-northeast-2) 에 DynamoDB 테이블을 생성


- 테이블 이름은 terraform-resource-lock (그대로 사용)


- Primary Key 는 String 타입, 이름은 LockID


![16](https://user-images.githubusercontent.com/41605276/67650883-09621b80-f982-11e9-996f-f6bd0e60ef30.png)

#### STEP 1)을 통해서 아래와 같은 내역들이 준비 되었는지 확인 후 실습 단계로 넘어간다.

- AWS 계정 내 `Administrator` IAM 사용자 생성


- AWS 계정 내 `Administrator` IAM 사용자에게 `AdministratorAccess` 권한 부여


- AWS 계정 내 `Administrator` IAM 사용자에게 Access Key 발급 후 CSV 다운로드


- AWS CLI 설치 후 `aws configure` 명령어로 AWS Credential 로컬에 세팅


- aws-iam-authenticator 설치


- Docker CE 19.03+ 설치


- Terraform 0.12+ 설치


- Kubectl 1.15.0 설치


- SSH 키 생성 및 AWS 에 생성된 SSH Public Key 등록


- 실습 코드 Github 에서 Clone 또는 Download 받아 준비하기


- Terraform State 를 위한 S3, Dynamo 생성

### STEP 2) Github 에서 받은 소스 코드 내 S3 경로 수정

아래 그림과 같이 테라폼 파일들을 수정해준다. 

위에서 만든 S3 Bucket 이름을 적용하기 위해 Github 에서 받은 소스 코드 내 아래의 파일들 내용을 수정

terraform-root-iam/terraform.tf

terraform-root-eks/terraform.tf

terraform-root-vpc/terraform.tf

terraform-root-eks/data.tf    ←- bucket 2곳

![19](https://user-images.githubusercontent.com/41605276/67650898-1121c000-f982-11e9-91e6-31fa12dcd440.png)

### STEP 3) Terraform 으로 AWS IAM 생성

`terraform-root-iam`폴더로 이동해서 아래 그림과 같이 명령어들을 실행해준다.

![23](https://user-images.githubusercontent.com/41605276/67650907-17b03780-f982-11e9-89e0-ec416fdf9038.png)

### STEP 4) Terraform 으로 AWS VPC 생성

`terraform-root-vpc`폴더로 이동해서 아래 그림과 같이 명령어들을 실행해준다.

![28](https://user-images.githubusercontent.com/41605276/67650914-1da61880-f982-11e9-90b4-8ad2e1c5a190.png)

### STEP 5) Terraform 으로 AWS EKS 생성

`terraform-root-eks`폴더로 이동해서 아래 그림과 같이 명령어들을 실행해준다.

![33](https://user-images.githubusercontent.com/41605276/67650921-24cd2680-f982-11e9-9684-1d65bd98c550.png)

### STEP 6) Kubernetes 내 JupyterHub 설치

설치한 AWS EKS Cluster analysis-production 을 kubectl (Kubernetes 클라이언트) 에 세팅하는 스텝이다.

아래의 커맨드를 실행한다.

`aws eks update-kubeconfig --name analysis-production`

kubectl 이 세팅이 되면 아래 커맨드로 확인할 수 있다.

`kubectl get nodes`

![37-2](https://user-images.githubusercontent.com/41605276/67650928-2b5b9e00-f982-11e9-8cad-273f5fed5ed4.png)

아래 그림과 같이 Jupyter Hub 패키지 설치에 필요한 Helm Client 와 Server (Kubernetes 내 Agent) 설치한다.

먼저 Helm을 설치한다.

그리고 아래의 코드를 실행해준다.

`kubectl --namespace kube-system create serviceaccount tiller`


`kubectl create clusterrolebinding tiller --clusterrole cluster-admin --serviceaccount=kube-system:tiller`


`helm init --service-account tiller --wait`


`kubectl patch deployment tiller-deploy --namespace=kube-system --type=json --patch='[{"op": "add", "path": "/spec/template/spec/containers/0/command", "value": ["/tiller", "--listen=localhost:44134"]}]'`


그런다음에 아래의 URL의 내용과 같이 k8s-jupyter-hub/jupyter.helm-config.yaml 파일의 기존 내용에서 아래 커밋을 따라 똑같이 주석 처리

 https://github.com/1ambda/terraform-aws-eks-jupyterhub/commit/7d43994cafdaf10b54febdf24ba998e0ebbf6f3b

![38](https://user-images.githubusercontent.com/41605276/67650934-31ea1580-f982-11e9-86ef-af86e15c251f.png)

AWS Disk 관련된 설정을 위해  k8s-jupyter-hub 디렉토리 아래에서 다음 명령을 실행한다.
`kubectl apply -f ./k8s.ebs-storage-class.yaml`


Git Clone 받은 폴더 내 k8s-jupyter-hub 디렉토리로 이동하셔서 아래의 명령어 실행한다.
`./jupyter.helm-install.sh`


모니터링을 위해 아래 커맨드를 사용할 수 있다.

`kubectl get namespaces`


`kubectl get -n jupyter-production pods`


`kubectl get -n jupyter-production pods -w`


아래 커맨드를 이용해서 kubernetes service = AWS ELB 주소 확인할 수 있다.


`kubectl --namespace=jupyter-production get svc proxy-public`


혹은 AWS EC2 메뉴 내에 Load Balancer 메뉴에서 확인할 수 있습니다


http://{loadbalancer-url} 을 통해 Jupyter 에 접근


Jupyter Container 이미지를 추가하고 싶을 시 k8s-jupyter-hub 디렉토리 내의 jupyter.helm-config.yaml 을 변경하고 jupyter.helm-update.sh 를 실행하면 된다.


추가적인 설정은 Zero To Kubernetes (Kubernetes Helm Chart) 에서 확인할 수 있다.

관련URL : https://zero-to-jupyterhub.readthedocs.io/en/latest/authentication.html


GPU 관련된 설정은 jupyter.helm-config.yaml 내 아래처럼 추가할 수 있다.


관련URL : https://zero-to-jupyterhub.readthedocs.io/en/latest/user-resources.html#set-user-gpu-guarantees-limits

![40](https://user-images.githubusercontent.com/41605276/67650949-3b737d80-f982-11e9-94d7-8030b7eee977.png)

그래서 위에서 언급한 내용들을 아래 그림과 같이 명령어들을 실행해주면 된다.

![41](https://user-images.githubusercontent.com/41605276/67651514-c3f31d80-f984-11e9-9be8-435a89deb5dc.png)

### STEP 7) (선택) Custom Docker Image 빌드

Custom Jupyter Container 를 이용하기 위해 AWS ECR (Docker Image Repository) 생성 합니다

![45](https://user-images.githubusercontent.com/41605276/67650973-52b26b00-f982-11e9-840b-77972fa91fe7.png)

그런 다음에 jupyter/docker-stacks 내의 minimal-notebook 을 확장하는 Dockerfile 을 생성한다.


관련URL : https://gist.github.com/1ambda/fd2138ca92b160a485408b14b9a9f3b3


Local 에서 해당 Dockerfile 을 빌드한다.


관련URL : https://subicura.com/2017/02/10/docker-guide-for-beginners-create-image-and-deploy.html


ECR 에 빌드한 이미지를 푸시한다.


관련URL :https://docs.aws.amazon.com/ko_kr/AmazonECR/latest/userguide/docker-push-ecr-image.html


권한 문제가 있을 경우 다음의 커맨드를 실행해본다. (Docker ECR 로그인 커맨드)
$(aws ecr get-login --region ap-northeast-2 --no-include-email)

### 핸즈온 시 사용한 리소스 삭제하기

핸즈온 정리 단계 1 - Kubernetes 리소스 삭제하기

`k8s-jupyter-hub/jupyter.helm-delete.sh` 를 실행한다.

올바르게 제거되었는지 확인하기 위해 아래 커맨드를 이용할 수 있다. 

모든 Pod 과 Service 가 제거되어야 한다.

`kubectl -n analysis-production get pods`


`kubectl -n analysis-production get services`

핸즈온 정리 단계 2 - Terraform 리소스 삭제하기

아래 문서를 따라서 다음 내용들을 삭제합니다.

(Terraform) EKS

terrfaorm-root-eks > terraform destroy

(Terraform) VPC

terrfaorm-root-vpc > terraform destroy

(Terraform) IAM

terrfaorm-root-iam > terraform destroy

(AWS Console) S3

(AWS Console Dynamo DB

(AWS Console) EC2 -> EBS

(AWS Console) AWS Access Key 를 삭제

(AWS Console) AWS 사용자 (Administrator) 삭제 

