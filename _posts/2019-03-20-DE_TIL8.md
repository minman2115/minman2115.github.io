---
layout: post
title: "AWS Data flow infrastructure 기초개념"
tags: [Data Engineering]
comments: true
---

Data Engineering TIL (20190319)


#### [학습목표]

- EMR 와 Glue 을 활용해 데이터 처리에 대한 흐름을 이해 한다.


#### [학습기록]

![1](https://user-images.githubusercontent.com/41605276/54688269-a9d89d80-4b60-11e9-95c1-582bec7b81d0.png)

- EMR을 띄우면 spark가 클러스터링을 자동으로 구성해준다. 그 안에 HDFS가 포함이 되어있다. 또한 EMR이 큰 데이터를 핸들링하다보니까 이 시스템이 정상적으로 작동하고 있는지 모니터링도 해야한다. 너무 큰 데이터를 작은 리소스로 돌리게 되면 상당히 부하가 크고 오래걸릴 수 있기 때문에 이 부분을 어떻게 모니터링 할것인가도 중요하다.


- 스파크 클러스터링을 보면 위와같이 마스터노드와 워커노드로 구분이되어 구성되어있다. EMR에서는 마스터노드, 코어노드, 테스크노드 세개로 구성되어있다. 마스터노드는 일을 시키는 노드이고 일을하는 노드가 일을 잘 하고 있는지 모니터링하고 있다가 뭔가 문제가 있으면 다시일을 시키는 기능을 가지고 있다. 또한 특정파일을 선택해서 분석하고자할때 그 파일 숫자에 따라서 노드숫자에 맞게 일을 배분해주는 역할도 한다.


- 코어노드는 그림에서 볼 수 있듯이 HDFS가 붙어있다. 테스크노드에는 HDFS가 없다. 그러면 코어노드에는 왜 HDFS가 붙어있는가. 우리가 어플리케이션을 돌리면 보통 TEMP폴더가 있는데 스파크를 돌릴때 임시로 저장했다 읽어오는 경우가 있다. 예를들어 캐시를 만들어서 적용하는 경우가 있는데 이때 임시로 저장하는 용도로 많이 사용한다. 또는 어떤 연산을 조금 더 빠르게 처리해야 할때 필요하다.


- 스파크는 항상 마스터노드와 워커노드가 쌍으로 있어야만 구동한다. 왜냐하면 그게 클러스터 단위이기 때문이다. 그래서 마스터노드와 코어노드 중에 하나라도 없으면 이 전체클러스터가 다운되어 버린다. 그래서 구성할때 마스터노드와 코어노드는 쌍으로 꼭 필요하다.


- 테스크노드는 HDFS가 없고 이 노드는 단지 마스터노드가 일을시키면 컴퓨팅자원만 사용하여 테스크를 수행한다.


- HDFS로 S3를 사용했을때 장점

1) 클러스터를 종료하고 다시 클러스터를 구성해도 기존데이터를 읽을 수 있다. 

1-1) 보통 하둡같은 경우에는 서버를 항상 켜둬야하는 문제점이 있다. 서버를 껐다가 다시키면 데이터를 다시 마운트해야 하기 때문에 데이터를 가져오는데 매우 번거롭다. 반면에 S3같은 경우는 EMR을 꺼버리면 코어노드에 붙어있는 HDFS에 temp로 데이터를 저장한것은 날아가버리지만 S3에 저장할경우 항상 남아있다. 통상 그래서 데이터를 다 처리한 후에 S3에 저장을 한다. 참고로 속도때문에 데이터 처리하는 중간과정 중에 코어노드의 HDFS에 데이터를 저장하는 경우가 있다.

또한 glue에서는 카테고리를 저장할 수 있는 기능이 있기 때문에 그걸 참조를 하면 EMR 몇대를 구동해도 퍼포먼스의 영향없이 똑같은 데이터를 가져와서 활용할 수 있다. 그래서 통상 데이터는 전부 S3에 저장하고 여러 AWS툴에서 접근할수 있다. 다시말해서 EMR에서 참조할 수 있게 구성도 가능하다는 뜻이다.

2) HDFS의 확장에 대해서 신경을 쓰지 않아도 된다.


3) 용량에 대한 체크가 가능하다.


4) AWS의 강력한 저장 내구성 보장


5) Both in IOPs and data storage 가능


6) Build elastic clusters 가능

6-1) Add nodes to read from Amazon S3 가능

6-2) Remove nodes with data safe on Amazon S3 가능


7) 여러개의 클러스터 서비스에서 데이터를 읽을 수 있다. 운영 EMR과 분석용 EMR에서 다 사용 가능하다.

통상 S3 버켓에 전처리한 데이터를 저장해 놓거나 로우데이터를 저장해놓고 여러개의 EMR을 띄워서 다 똑같은 데이터를 바라보고 가져와서 활용할 수 있다. 또한 EMR을 이용해 데이터를 활용한 다음에 꺼버려도 데이터는 항상 S3 버켓에 있기 때문에 나중에 다시 EMR을 띄워서 데이터를 그대로 다시 가져와서 활용할수도 있고, 아테나를 이용해서 S3의 데이터를 조회할 수 있다.

- EMR은 하둡, 스파크, 텐서플로우 등 많은 툴을 제공해준다.


- 프레스토는 쉽게 얘기해서 SQL 분산처리 시스템이라고 할 수 있다. 페이스북에서 만든 오픈소스이고 쿼리를 날리면 빨리 결과를 얻을 수 있는것이 장점이다. 예를들어서 S3에 쌓은 데이터를 조회할때 EMR 내 프레스토를 활용해서 조회하면 이기종 데이터를 끌어다가 분석할 수 있다. 넷플릭스 같은 큰 기업들이 잘 활용하고 있다.


- 스파크는 데이터 전처리나 로직을 집어넣어서 처리를 하고 저장하거나 데이터 간에 비교하고 분석할때 많이 활용하는 툴이라고 하면 프레스토는 데이터 시각화 툴에 데이터를 연결해줄때 처리가 다 된 저장된 데이터를 처리해줄때 많이 활용하는 툴이다.


- sqoop은 rds에 있는 데이터를 내릴때 클러스터링을 이용해서 db에 있는 데이터를 하둡에 내릴때 쓰는 용도로 만들어진 오픈소스이다.


- ganglia는 EMR이 돌고 있는것을 모니터링 할 수 있는 툴이다. EMR의 프로세스 숫자, 각 서버들의 상태(서버리소스 부하가 올 경우 빨간색으로 표시해준다) 등 관리가능


- 주키퍼는 클러스터간에 모니터링할때 쓰는 툴이다.


- 우지는 ETL job은 선행작업이 있고 후행작업이 있는데 이런 작업을 실행할 수 있는 툴이다.

- EMR 생성 시 글루 데이터 카탈로그 세팅 옵션의 의미

![2](https://user-images.githubusercontent.com/41605276/54688280-b0ffab80-4b60-11e9-8d48-be4e8a568796.png)

S3의 데이터를 처리를 해서 무언가 정리된 데이터를 저장을 하면 이 저장된 데이터를 데이터 카탈로그 또는 메타스토어라고도 한다. 거기에는 테이블 정보(= 메타데이터)가 있는데 S3의 특정 버켓에 저장되어있는 테이블에 대한 이 정보(=메타데이터)를 glue라는 툴이 가지고 있다. EMR을 구동할때 이 메타데이터를 참고할지 선택하는 옵션을 말한다.

- 데이터 분석 시 아래와 같이 spot instance를 쓰게 되면 저렴하게 할 수 있으므로 EMR에서도 리소스 옵션 선택 시 master노드 같은 경우 spot instance로 하는 것을 권장한다. 반면에 core노드에서 spot instance를 선택하면 중간에 온디멘드 옵션으로 한 유저들에게 리소스를 뺏기는 현상이 발생할 수 있기 때문에 실질적으로 일을하는 core 노드는 온디멘드로 하는 것이 좋다. 왜냐하면 중간에 리소스를 뺏겨서 다운이 되어버리면 클러스터 전체가 문제가 생기기 때문이다. master노드는 일을 많이 안하기 때문에 spot을 해도 상관없다.

![3](https://user-images.githubusercontent.com/41605276/54688295-b9f07d00-4b60-11e9-9406-f9058a4c81df.png)

- 참고로 코어를 한번 생성하면 가능하면 코어의 숫자를 변경하지 않는것이 좋다. 왜냐하면 코어안에 HDFS temp에 분석한 데이터들이 저장되어 있기 때문에 갑자기 코어 수를 줄여버리면 느려질 수 있다. 예를 들어 core가 두대 있는데 한대가 필요없는거 같아 core를 한대로 줄이려고 하면 한대로 줄이는 작업이 안끝날수도 있다. 스캐일 인중에 상태값을 보면 스케일을 줄이려고 계속 시도하는데 디스크가 모자라서 안끝난다. 이렇게 되면 리소스만 계속 소비하게 되고 리사이징은 안되는 현상이 발생한다. 이부분은 조심해야한다.

- task노드는 리소스에 대한 그룹인데 아래와 같이 몇개를 추가해도 상관없다. 이 instance groups의 각각의 ID는 서버그룹을 말하는 것이다. 아래 보는것처럼 현재는 instance count가 task는 0개로 되어 있는데 프로그래밍으로 이것을 데이터의 크기에 따라 임의로 늘릴 수 있다는 말이다. 0개로 해도 이 그룹은 살아있다. 반면에 코어 그룹은 이런 조절이 어렵다.

![4](https://user-images.githubusercontent.com/41605276/54688309-c07ef480-4b60-11e9-8247-33c2b252d6ed.png)

- EMR을 활용한 데이터 처리 아키텍처(하단그림)

![5](https://user-images.githubusercontent.com/41605276/54688337-c8d72f80-4b60-11e9-92ed-53f29aa2f107.png)

- 위의 그림에서 키네시스는 큐라고 생각하면된다. firehose는 데이터를 받아서 데이터를 S3에 저장해주는 툴이다. 처음에는 로우데이터로 되어 있을텐데 이것을 한꺼번에 처리를 하게되면 코스트가 매우 커지게 된다. 이 로우데이터에서 필요한 특정데이터만 뽑아서 정기적으로 transformed data 버켓에 저장한다. 이렇게 로우버킷에서 데이터를 정제해서 transformed data 버킷으로 쌓아두는 것을 EMR이 해준다. 

- EMR 스파크 SQL을 이용한 데이터 처리 양상 (하단그림)

![6](https://user-images.githubusercontent.com/41605276/54688355-cffe3d80-4b60-11e9-84ca-7b9b140b7496.png)

- 위의 그림에서 볼 수 있듯이 통상 write할때는 parquet data로 저장하는 것이 좋다 왜냐하면 호환성이 좋기 때문에

- Zeppelin Notebook이란

1) Brower에서 Python, Scala, R 등의 다양한 언어를 섞어가며 분석코드를 표현 할 수 있고 바로 실행하여 결과를 바로 볼 수 있을뿐만 아니라 생성된 데이터를 Graph로 시각화하여 볼 수 있다.

2) 소스코드를 표현하고 실행하고 수정하고 분석하고 시각화를 쉽게 할 수 있다.

3) 유사한 툴로는 주피터 노트북이 있다.

- AWS Glue : ETL 워크플로우를 정의하고 관리할 수 있는 서비스


1) Data Catalog: AWS Glue 데이터 Catalog은 영구적 Meta Data Store


2) AWS Glue Crawlers 및 Classification

리포지토리에서 데이터를 스캔하고 분류, 스키마 정보를 추출 및 AWS Glue Data Catalog에서 자동적으로 Metadata를 저장하는 Crawlers를 설정가능


3) AWS GlueETL 연산

AWS Glue Jobs System, Trigger 기능


- AWS Glue Data Catalog : Data Store

![7](https://user-images.githubusercontent.com/41605276/54688370-d8ef0f00-4b60-11e9-9d26-2128fe8a2cad.png)

![8](https://user-images.githubusercontent.com/41605276/54688389-df7d8680-4b60-11e9-99ac-8acedff709c9.png)

- AWS glue 크롤러는 csv나 텍스트 파일을 올려놓고 빠르게 분석을 하고 싶을때 이 크롤러를 돌리면 특정형태에 맞게 데이터를 구성하고 SQL 쿼리로 조회할 수 있도록 임시로 만들어주는 툴이다.


- AWS REDSHIFT 스펙트럼 : RDS를 띄우면서 얘도 마스터 노드와 슬레이브 노드가 있는데 슬레이브 노드 밑에 S3를 읽을 수 있는 커널이 있고 이 커널을 통해 S3와 연결이 되면 S3의 파일을 조회할 수 있다.

![9](https://user-images.githubusercontent.com/41605276/54688394-e60bfe00-4b60-11e9-99e9-cd88aa42101a.png)

- 데이터 엔지니어링 시 어떤 데이터를 어떻게 제공할 것인가에 따라 툴들을 정하는 것이지 툴을 먼저 정하는 것은 아니다
