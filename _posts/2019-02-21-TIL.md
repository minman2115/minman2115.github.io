---
layout: post
title: "Data Engineering TIL (20190221)"
tags: [Data Engineering]
comments: true
---

Cloud_AWS STEP 1)


- 실제 서버와 클라우드의 차이점을 알아야한다. 그리고 클라우드 상에서 네트워크 구조를 이해하기 위해 VPC를 실제 구성할 줄 알아야한다.


- 데이터를 수집해서 분석하는 것이기 때문에 네트워크 구조를 이해해야 데이터 분석 시 데이터 수집에 관련된 경로를 설정할때 도움이 된다. 그러기 위해 먼저 클라우드 관련 용어를 이해해야한다. 


- 데이터 엔지니어로 어떤 것을 할것인가에 대해 먼저 이해하고 있어야한다. 사물인터넷이나 여러가지 어플리케이션 또는 집에서 쓰는 애코 등에서 나오는 데이터들을 통상 인터넷을 통해 수집을 하게 되는데 그런 데이터들을 분석가 들이 잘 분석할 수 있도록 잘 정리해서 제공해주는 것이 데이터 엔지니어링이다.

- 클래스 매니저님 코멘트 "넷플릭스 데이터팀 소개 영상을 추천드립니다. 대규모 서비스의 분석에서의 데이터 인프라 구조(7분 대)와 개인적으로 마지막의 데이터 팀의 철학 3가지는 꼭 추천드립니다(https://www.youtube.com/watch?v=nMyuCdqzpZc)"


- 현실적으로는 이 용어 정의에 대한 실질적인 구분이 모호하다. 요즘에는 엔지니어링도 하는 동시에 머신러닝도 하고 있다. 클라우드 상에서 쉽게 머신러닝을 할 수 있는 환경이 구축되어 있기 때문이다.


- 클래스 매니저님 코멘트 "개인적으로 느끼기로는 해당 분야의 발전이 진행되면서 전문화 되어 가는 것 같습니다(비록 서비스가 발전해서 모든 것을 다하기 쉽다고 할지라도). 사내에서도 '데이터 인프라'라는 팀이 이번에 '데이터 인프라' 및 '데이터 서비스'로 나뉘게 되는데요(데이터 사이언스에서 머신러닝을 담당합니다). 위의 넷플릭스 영상에서도 구조를 참고하신다면 각 구조 요소별 직무의 특징이 예상되리라 생각됩니다."


- 또한 최근에 AWS에서 '세이즈 메이커'라는 것을 엔지니어들이 잘 다룰 줄 알아야한다. 우리가 앱같은 경우에는 구글에 올려서 판매를 통상하게 되는데 AWS에서는 로직을 짜서 세이즈 메이커라는 곳에 라이브러리에 올려서 판매할 수 있는 스토어가 생겼다. 중요한 포인트는 데이터를 잘 정재해야 한다는 것이다. 왜냐하면 데이터가 엄청나게 크기 때문에 잘 정제하고 논리적으로 잘 축적해야한다.
	

- 온프라미스는 자체적으로 서버를 구축하는 것이다. 대략적으로 클라우드 컴퓨팅에 반대되는 개념이다. 


- 메타데이터는 테이블에 대한 정의를 관리해준다. 테이블 구조이기 때문에 빅데이터를 예를 들어 어떤위치에 데이터가 쌓여있다고 치면, 그 데이터가 쌓여있는 위치정보까지 합친 개념에 대한 용어이다. 메타데이터는 중요한 개념이다. 우리가 데이터를 접근할 때 어떤 데이터를 조회한다고 치면 그 데이터가 어떤 구조로 되어져있는지 그런 부분을 알아야한다. 대부분의 큰 회사들은 메타데이터를 관리한다. 


- 클래스 매니저님 코멘트 "엄청나게 쏟아지는 데이터를 구조화하여 잘 저장하는 것에 더해서, 서비스 변화에 따라 변동되는 구조 및 추가되는 구조도 타부서나, 팀내에서 찾아 접근할 수 있도록 잘 기록하는 부분도 매우 중요합니다(우버 데이터북: https://eng.uber.com/databook/)"


- ETL은 보통 쌓여있는 로우데이터를 다시 추출해서 거기에 특정한 로직이 있다면 적용하고 우리가 그 데이터들을 사용자 또는 아이템 , 거래 등 특정한 주제영역별로 변환을 해서 다시 적재하는 개념등을 말한다. 보통 데이터 transformation을 할때는 대부분 ETL툴을 사용하게 된다. 최근에 SPARK이라는 툴이 두드러지게 많이 사용하게 되는데 보통 ETL 개념을 적용할때는 이 SPARK를 많이 쓰는 편이다. 


- 클래스 매니저님 코멘트 "백엔드 등의 real-time이 중요시 되는 것과 데이터쪽이 특징적으로 차이가 나는 부분인데요. 일부 특수 목적을 제외하면 아직까지 실시간 데이터가 분석에 필요한 케이스가 (퍼센티지가) 높지 않은 것으로 알고 있습니다. 리소스가 많은 새벽(3 ~ 5시)에 시작해 전날까지의 데이터를 프로덕션 서버에서 분석쪽으로 넘기며 transform하는 것이 보통의 케이스입니다."


- Producer와 Consumer는 데이터 엔지니어링에서 다음과 같이 이해한다. producer는 예를들어 사물인터넷 하드웨어처럼 하루에 수많은 데이터들을 생성해내는 것을 말한다. 그래서 producer에서 발생한 데이터를 consumer queue에 담게 된다. queue는 데이터를 담는 그릇이라고 생각하면 된다. 그 그릇(queue)은 한번 데이터를 거기서 꺼내가면 데이터가 없어지는 경우도 있고, 어떤 그릇은 강물이 흐르듯이 없어질때까지 활용할 수 있기도 한다. queue를 사용할때 카프카라는 것을 많이 쓴다. 온프라미스에서는 카프카를 많이 쓰고 AWS에서는 키네시스라는 것을 쓴다. consumer는 queue안에 있는 데이터를 활용해서 뭔가 에코를 하고 정재해서 특정위치에 쌓거나 실시간으로 모니터링 할 수 있는 그런 툴이 있으면 연결해주는 그런 개념이다.


- 우리가 데이터 분석을 할때 spark라는 것을 활용할 것인데 spark의 기본 베이스는 하둡이라는 툴이다. 하둡환경은 클러스터 환경이다. 기존에는 서버 한대한대를 별도로 운영했는데 클러스터는 논리적으로는 하나의 서버로 보이지만 여러개의 컴퓨터들이 연결되어 있는 집합이다.


- 클래스 매니저님 코멘트 "앞으로 진행할 대다수의 패키지가 하둡과 그 개념을 기반해 있습니다. 하둡을 이해하면 다른 파생적인? 패키지를 이해하는 큰 도움이 되니 하둡에 많은 시간을 투자하길 권장드립니다."


- scale up은 우리가 운영하고 있는 서버의 리소스(CPU, 메모리, SDD 등)를 더 좋은 것으로 교체하거나 추가하는 것이고 scale out은 서버대수를 늘리는 것이다.


- Data Lake는 모든 데이터를 쌓아놓는 공간을 말한다. 그래서 정형데이터, 비정형데이터 다 들어가 있다. 이 내에서 데이터들을 잘 정형화시키는 것이 관건이다.


- 클라우드의 장점
1) 선투자금이 없으므로 고정비용이 아닌 가변비용이다.
2) 서버가 많이 필요할때와 적게 필요할때 탄력적으로 활용할 수 있다(TCO 절감). 과거에는 서버를 내가 더 필요할때 일일히 실제로 주문을해서 구매했지만, 클라우드에서는 코딩으로 내가 컨트롤 할 수 있다. 모든 서버대수나 스케일이나 API로 컨트롤이 가능하다. 그런점에서 비용을 클라우드에서 아낄 수 있다.  그래서 빅데이터 분석은 결국에 클라우드 컴퓨팅으로 할 수 밖에 없다.


- AWS에서 EC2는 클라우드에서 확장식 컴퓨팅을 말한다. AMI는 가상 인터넷에 윈도우, 리눅스 등 os가 깔린 이미지를 말한다.


- EC2 생성시 instance Tag : 인스턴스를 구분하기 위해 이름을 부여하는 것


- EC2 생성시 security group : 보안관리를 위해 서버에 접속할 수 있는 포트를 관리하는 툴. 그래서  서버에 접속이 안되는 현상이 식별되면 시큐리티 그룹에서 포트가 안열린게 있나 확인하는 것도 해결방법 중 하나이다. ssh는 터미널에서 접속하는 프로토콜을 말한다. 웹서버를 띄울때는 80포트를 개방해야한다. 보안그룹에서 0.0.0.0이라는 것은 어디에서든 접속이 가능하다는 의미이다. 


- 윈도우즈 운영체제에서 putty로 AWS 접속하기

STEP1) PuTTYgen 실행

STEP2) Load 클릭 -> All Filles 옵션선택

STEP3) 인스턴스 생성시 만든 키페어(.pem) 파일 선택 -> Save private key 클릭 -> 경고표시 Yes

STEP4) .pem 형식을 .ppk 파일형식으로 변환하는 과정으로, 이름을 임의로 설정하고 저장을 누르면 .ppk가 생성된다.

STEP5) PuTTY 실행

STEP6) 좌측탭에 SSH에서 Auth 클릭 -> 우측에 Browse 클릭 후 생성한 .ppk 선택

STEP7) Session클릭 -> Host Name에 AWS에서 인스턴스 실행 클릭 시 나오는 하단에 Example에서 ec2부터 쭉 복사 및 붙어넣기

STEP8) open 클릭


- private IP : 클라우드 내에서 쓰는 아이피, public IP : 외부에서 접속할 수 있는 아이피


- IAM 권한관리 : AWS 리소스에 대한 액세스를 안전하게 제어할 수 있는 웹 서비스이다. 리소스를 사용하도록 로그인 및 권한 대상을 제어한다. 회사에서는 보안팀이라는 조직에서 AWS 권한을 분배해준다.


- 클래스 매니저님 코멘트 "IAM 권한관리는 내부적으로 JSON 덩어리입니다(https://www.youtube.com/watch?v=YQsK4MtsELU)"


- VPC는 Region이 빌딩부지라고 생각하면 되는 것이고, VPC는 한층한층 빌딩을 올린다고 생각하면 된다. 거기에 방을 서브넷이라고 생각하면 된다. VPC은 사용자가 정의한 가상 네트워크다.


- 사이더 방식 : 기존의 아이피 주소 할방방식이었던 네트워크 클래스를 대체함. A.B.C.D/N 예를 들어 10.0.1.234/32 이런 형식을 쉽게 볼 수 있도록 해준다. /32는 아이피 대역을 하나만 쓸 수 있다. /24를 쓰면 C클래스라고 해서 256개의 호스트를 쓸 수 있다. 정확히 말하면 255개로 1개는 라우터가 디폴트로 쓴다. /16은 B클래스라고 해서 약 6만 개를 쓸 수 있다. 


- VPC 생성법

STEP1) VPC 서비스 클릭 -> VPC 마법사 시작 클릭

STEP2) IPv4 CIDR 블록에 12.0.0.0/16 입력, 네임테그에 내 아이디 입력 및 생성

STEP3) VPC 대시보드에서 서브넷 클릭 -> 서브넷 생성 클릭 및 생성

STEP4) 인터넷 게이트웨이 생성 및 'ATTACH to VPC' 클릭하여 VPC에 아이피 할당

STEP5) 라우팅 테이블 생성(네임테그 : 내 아이디, VPC는 내가 만든 VPC 선택), Edit routes에 route를 추가하여 destination에 0.0.0.0/0 추가, target은 내가 만든 VPC 선택 -> save routes -> edit subnet associations에서 public subnet 선택 및 save

STEP6) 인스턴스 생성(생성 시 3.configure instance에서 내가 만든 VPC 선택)


- 인스턴스를 생성하고 네트워크를 특정 VPC로 지정하게 되면 이 인스턴스들은 특정 VPC 바운더리 내에 있는 것이다. 