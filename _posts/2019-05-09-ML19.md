---
layout: post
title: "xgboost 기초개념"
tags: [Classification]
comments: true
---

.

#### 그림, 실습코드 등 학습자료 출처 : https://brunch.co.kr/@snobberys/137

#### 1. xgboost 개념이해를 위한 Boosting algorithm 기본원리

![1](https://user-images.githubusercontent.com/41605276/57428183-28e57a80-7262-11e9-92b7-f2b1aaa3c9a5.jpg)

#### 2. xgboost 기본원리

![2](https://user-images.githubusercontent.com/41605276/57428195-3438a600-7262-11e9-9c70-03fbe36f63f0.jpg)

#### 3. 기본원리를 수식으로 표현

![3](https://user-images.githubusercontent.com/41605276/57428199-3ef33b00-7262-11e9-83f3-2f13845a22ea.jpg)

![4](https://user-images.githubusercontent.com/41605276/57428213-4adefd00-7262-11e9-9116-f5d924d9bdb4.jpg)

![5](https://user-images.githubusercontent.com/41605276/57428220-53cfce80-7262-11e9-8be5-ebb8a0dac3ce.jpg)

![6](https://user-images.githubusercontent.com/41605276/57428230-5cc0a000-7262-11e9-9ffa-d7a08871355a.jpg)

#### 4. Parameter

xgboost의 파라미터는 크게 3가지 종류가 있다.

1) 도구의 모양을 결정하는 'general parameters'

1-1) booster : 어떤 부스터 구조를 쓸지 결정한다. gbtree, gblinear, dart가 있다.

1-2) nthread : 몇개의 쓰레드를 동시에 처리하도록 할지 결정한다. 디폴트 옵션은 "최대한 많이"다

1-3) num_feature : 피쳐 차원의 숫자를 정해야 하는 경우 이 옵션을 세팅한다. 디폴트 옵션은 "최대한 많이"다


2) 트리마다 가지를 칠때 적용하는 옵션을 정의하는 'booster parameters'

2-1) eta : learning rate다. 트리에 가지가 많을수록 오버피팅하기 쉽다. 매 부스팅 스탭마다 weight를 주어 부스팅 과정에 과적합이 일어나지 않도록 한다.

2-2) gamma : information gain에서 -r로 표현한것이 있는데 그게 커지면 트리 깊이가 줄어들어 보수적인 모델이 된다. 디폴트 값은 0이다.

2-3) max_depth : 한 트리의 maximum depth이다. 숫자가 커질수록 모델의 복잡도가 커진다. 다시말해서 과적합 하기 쉽다. 디폴트는 6이고 이때 리프노드의 개수는 2의 6승 64개이다.

2-4) lambda(L2 reg-form) : L2 regularization form에 달리는 weights이다. 숫자가 클수록 보수적이 모델이 된다.

2-5) alpha(L1 reg-form) : L1 regularization form weights다. 숫자가 클수록 보수적인 모델이된다.

3) 학습과정에서 최적의 퍼포먼스를 결정하는 'learning task parameters'

3-1) objective : 목적함수다. reg:linear(linear-regression), binary:logistic(binary-logistic classification), count:poisson(count data poison regression) 등 다양하다.

3-2) eval_metric : 모델의 평가 함수를 조정하는 함수다. rmse(root mean square error), logloss(log-likelihood), map(mean average precision) 등, 해당데이터의 특성에 맞게 평가함수를 조정한다.

4) command line parameters

4-1) num_rounds : 부스팅 라운드를 결정한다. 랜덤하게 생성되는 모델이기 때문에 이 수가 적당히 큰게 좋다. epoch 옵션과 유사하다.