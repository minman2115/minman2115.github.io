---
layout: post
title: "데이터 품질문제와 테이터탐색 및 전처리 가이드라인"
tags: [데이터전처리]
comments: true
---

Data_Preprocessing_Studynotes_(20190515)

study program : https://www.fastcampus.co.kr/data_camp_ppc


#### [학습목표]


- 머신러닝 프로세스 이해


- 피드백 루프의 개념 및 사례 이해


- 주요 데이터 품질 문제의 정의 이해

(데이터 파편화, 데이터 분포 문제, 결측치, 이상치, 클래스 불균형, 차원의 저주)


- 데이터 탐색 및 전처리 가이드라인 이해


- 분석 모델 선택의 가이드라인 이해


#### [학습기록]

#### 1. 머신러닝의 정의

머신러닝은 컴퓨터에 명시적으로 프로그래밍을 하지 않고 학습할 수 있는 능력을 부여하는 분야를 말한다.

일반적인 프로그래밍은 인풋과 그 인풋을 처리하기 위한 프로그램을 컴퓨터에 투입시켜서 아웃풋을 얻는 그런 구조라고 한다면, 머신러닝은 인풋과 아웃풋(비지도 학습의 경우에는 아웃풋이 들어가지 않는다)이 주어졌을때 인풋과 아웃풋의 관계를 밝혀낼 수 있는 프로그램을 출력하는 것을 말한다.

#### 2. 머신러닝의 범위

- Descriptive analytics

이 결과가 왜 일어났는지 분석

단순통계 분석을 실시하는 단계다.

ex) 1년에 교통사고가 만건이 일어났는 것을 확인

- Dignostic analytics

진단적 분석까지가 데이터탐색이라고 할 수 있다.

ex) 만건이 일어난 이유를 보니까 날씨가 좋지 못해서 발생했다라고 수치로 파악함

- predictive analytics

여기까지가 일반적인 머신러닝이라고 할 수 있다.

ex) 비가 많이 오는 날은 교통사고가 평소보다 많이 나겠다고 수치적으로 예측


- presciptive analytics(처방적분석)

예를 들어서 교통사고 분석이라고 할 때 

ex) 토로를 미끄럽지 않게 해야겠다고 처방을 내리겠다고 판단



#### 3. 지도학습과 비지도학습의 중간이 있을까?

비지도학습은 정답을 주지 않고 데이터에 숨겨진 특징이나 구조를 발견하는 것을 말한다. 그렇다면 지도학습과 비지도 학습의 중간이 있을까?

생성모델, 준지도 학습이 있다.

준지도학습은 군집화를 통해서 지도학습을 실시한다.

#### 4. 책에서나 볼 수 있는 머신러닝 프로세스

말그대로 책에서 제시하는 이 프로세스는 책에서나 볼 수 있는 프로세스지. 대단히 비현실적이라고 할 수 있다. 이렇게 한번의 프로세스로 깔끔하게 진행되는 경우는 없다.

예를 들어서 모델링까지 하고 모델평가를 했는데 모델 퍼포먼스가 0이 나와버렸다. 그러면 보고서에도 0이라고 쓰고 제출하고 말 것인가. 데이터 탐색을 다시하던지, 데이터 수집을 다시하던지 반드시 이전 프로세스로 돌아가는 경우가 발생한다.

![1](https://user-images.githubusercontent.com/41605276/57864941-b3684400-7837-11e9-9883-62aae4eae596.jpg)

#### 5. 문제정의

전체 머신러닝 프로세스 가운데 가장 중요한 단계로, 구체적이고 명확한 목적의식을 가지고 머신러닝 프로세스를 시작해야 한다.

- 문제정의 단계서 수행하는 것들

1) 과업종류 결정(분류냐 예측이냐 등)

2) 클래스 정의

3) 사용 데이터 정의

- ex) 스팸메일 자동분류기 개발

1) 과업 종류 결정 : 분류

2) 클래스 정의 : 스팸인지 아닌지를 나타내는 변수정의 (Positive class : 스팸, Negative class : 정상메일)

3) 사용 데이터 정의 : 스팸메일을 포함한 메일 데이터

#### 6. 데이터 수집

- 문제정의에서 정의한 데이터를 수집하는 단계로 크롤링, 센서활용, 로그활용 등으로 데이터를 수집한다.


- 기존에 데이터가 주어져 있는 경우에는 데이터 수집단계를 생략한다.


- ex) 스팸 메일 자동분류기 개발

서버상에 있는 메일 데이터를 보유하고 있어서, 이 단계를 생략

#### 7. 데이터 탐색

- 데이터가 어떻게 생겼는지를 확인한다. 사실 문제정의 단계에서 머신러닝 프로세스 계획을 구체화 하지만 현실적으로 데이터를 실제로 확인하기 전까지는 이에 한계가 있다. 그래서 데이터 탐색단계를 통해  머신러닝 프로세스를 더욱 구체화 할 수 있다.


- 특히, 데이터탐색 결과는 데이터 전처리 과정에 크게 영향을 미치며, 데이터 탐색 단계에서 확인해야하는 내용은 다음과 같다.

1) 변수 별 분포확인 -> 변수변환 고려

2) 변수 간 상관성 확인 -> 변수 삭제 고려

3) 이상치와 결측치 체크 -> 이상치 제거 및 결측치 제거/추정 고려

4) 변수개수의 적절성 검토 -> 차원축소 기법 고려

5) 클래스 변수 분포확인 -> 클래스 불균형 문제 고려

- ex) 스팸메일 자동분류기 개발

1) 변수는 단의 출현 여부를 사용한다.

2) 결측치는 없는 것으로 확인되었으니 결측치 처리는 필요 없겠다.

3) 전체 메일에 등장한 단어수가 10만개로 확인이 되었으니 차원축소 기법을 적용하는 것을 고려해봐야겠다.

4) 5회 미만으로 등장한 단어수가 8만개나 되는데 이거는 분류에 큰 의미가 없겠다.

5) 같은 의미의 단어이지만 형태가 다른단어 (예를들어 단어의 현재형과 과저형)를 확인했으니 stemming이 필요하겠다.

6) 스팸메일의 갯수가 정상메일보다 100배나 적다. resampling이나 오분류 비용조정을 고려해봐야겠다.

#### 8. 데이터 전처리

- 모델링을 하기위해서 데이터를 모델링 할 수 있는 모양으로 다듬는 과정이라고 할 수 있다.


- 예를들어서 이미지나 텍스트 데이터는 이 데이터 자체를 분석하는 것이 아니라 데이터 전처리를 통해 모델이 인식할 수 있는 숫자(행렬)의 형태로 만들어 줘야 한다.


- 이 단계에서 수행하는 작업은 아래와 같다.

1) 결측값처리

2) 데이터 통합

3) 아웃라이어 제거

4) resampling

5) 피쳐선택

6) 더미변수 생성

- ex) 스팸메일 자동분류기 개발

1) 피쳐선택 기반의 차원축소 수행

2) 언더샘플링 기반의 클래스 불균형 문제 해결

#### 9. 모델링

step1) 모델선택

데이터 특성, 성능, 설명력 등을 기준으로 모델선택

ex1) 설명력이 중요한 경우 의사결정나무 혹은 베이지안 네트워크 사용

ex2) 이진 텍스트 분류를 하는경우 나이브베이즈 혹흔 서포트 벡터 머신을 사용

step2) 모델 파라미터 설정

모델의 성능을 결정짓는 파라미터를 설정

통상적으로는 유저들이 많이 사용하는 파라미터 집합에 속한 파라미터를 설정한다.

최적의 파라미터 설정은 상당히 어려운 과제임

ex) K-NN의 파라미터 설정

1) 이웃개수

2) 거리척도

step3) 모델학습 실시

#### 10. 모델평가

학습한 모델을 객관적인 지표를 이용해서 평가한다. 예를 들어서 분류모델을 평가한다고하면 우리가 알고있는 accuracy, precision, recall, F1-score 등이 있는데 둘 이상의 평가지표를 쓰는 것이 바람직하다.

![2](https://user-images.githubusercontent.com/41605276/57864976-c11dc980-7837-11e9-9040-4ed3ec7abc67.jpg)

예를 들어서 어떤 분류모델이 있는데 accuracy가 99.9%가 나왔다. 

이 모델은 좋은 모델인가? 좋은 모델이라고 단정할 수 없다. 구현한 분류모델의 confusion matrix가 아래와 같다고 하면 accuracy는 99.9%가 나오는데 recall은 0이 나오게 된다. 

이런 이유로 두가지 지표를 활용하는 것이다.

![3](https://user-images.githubusercontent.com/41605276/57864992-c713aa80-7837-11e9-9f72-b82d4ea6fa0a.jpg)

#### 11. 실질적인 머신러닝 프로세스

![1](https://user-images.githubusercontent.com/41605276/57864941-b3684400-7837-11e9-9883-62aae4eae596.jpg)

실제 프로젝트에서는 각각의 단계에서 이전 단계 또는 이전의 이전단계로 다시 돌아가는게 매우 흔하다. 이런 경우를 피드백 루프라고 하는데, 실제 머신러닝 프로세스의 소요시간은 피드백 루프 횟수에 정비례 한다고 할 수 있다.

#### 12. '문제정의' 단계가 잘못되었다면?

- 문제정의가 잘못되면 데이터수집, 전처리, 모델링 등 머신러닝 프로세스의 전반적인 과정에 상당히 부정적인 영향을 끼치게 된다. 


- 여기서 중요한 것은 문제를 정의할때 명확한 목적의식으로 구체적으로 머신러닝 프로세스를 구상해야 한다는 것이다. 


- 문제정의를 제대로 못한경우에는, 주로 데이터 탐색과 전처리를 기계적으로 한뒤, 모델링을 할때 비로소 무언가 잘못되었음을 깨닫고 문제정의로 다시 돌아가는 경우가 대부분이다.

![4](https://user-images.githubusercontent.com/41605276/57865039-dabf1100-7837-11e9-8ff9-9607b20395ff.jpg)

- 프로젝트 사례

머신러닝/빅데이터가 한창 인기를 끌기 시작할때 빅데이터를 활용한 분석을 무분별하게 시도하는 경우 이런 문제가 많이 발생했다.

1) 문제정의 : 어떤공장의 공정에서 발생하는 데이터를 바탕으로 공정을 최적화하고 싶다.

2) 데이터 : 생산공정에서 발생한 거의 모든 데이터(수십 테라바이트)

3) 어떠한 점에서 문제정의가 잘못되었는가 ?

공정을 최적화 하고 싶다는게 구체적으로 어떤 것을 어떻게 최적화하고 싶다는지 너무나도 모호하다.(비용을 최적화 하고싶은지, 기계의 생산효율성을 최적화 하고 싶은지 모호했다.)

주어진 데이터 역시 먼저 데이터가 쓸때없이 컸다. 

또한 피쳐가 어떤것인지 불분명한 것들이 많았고, 이 불분명한 피쳐가 어떤것인지 파악하기 위해 의뢰한 회사에 문의하였지만 영업비밀이라는 이유로 피쳐가 명확하게 어떤거지 알려주지 않는 등 애로사항들이 발생

4) 결론적으로도 프로젝트가 완성도가 높지 않았고 효과도 좋지 않았다.

#### 13. '데이터 수집' 단계가 잘못되었다면?

- 데이터 수집이 잘못되는 경우는 다음과 같이 구분할 수 있다.

1) 측정오류 등으로 인해, 수집한 데이터가 실제상황을 반영하지 못하는 경우

2) 해결하고자 하는 문제와 관련이 없는 데이터를 수집한 경우

- 주로 데이터 탐색단계 또는 모델평가 단계에서 무언가 잘못되었다는 것을 깨닫는다.

1) 데이터 탐색 단계 : "데이터가 무언가 이상하다?"

2) 모델평가 단계 : "모델성능이 무언가 이상하다?"

![5](https://user-images.githubusercontent.com/41605276/57865062-e3174c00-7837-11e9-9c41-bf90e96d0555.jpg)

- 프로젝트 사례

계절별로 어떤 물건의 품질에 관련된 머신러닝 프로젝트였는데 의뢰회사에서 제공한 데이터는 여름철 데이터 뿐이었음. 결론적으로 프로젝트를 수행할 수 없는 상황이었고 겨울철 데이터까지 전부 받은 후에 다시 진행했다.

#### 14. '데이터 탐색' 단계가 잘못되었다면?

- 데이터 탐색을 제대로 하지 않아서 이전 단계로 돌아가는 경우가 가장 흔한 케이스다.


- 데이터 탐색을 제대로 하지 않으면 데이터 전처리에 그대로 영향을 끼치게 되고, 그 결과 제대로 된 모델을 만들 수 없게 된다.


- 보통은 모델평가 단계에서 무안가 잘못되었다는 것을 꺠닫지만, 전처리, 모델선택 등 잘못된 단계로 되돌아 가는 경우가 많음


- 일반적으로 데이터 탐색 -> 데이터 전처리 -> ... -> 데이터 전처리 -> 모델링의 단계를 거치며, 이런 과정을 거치면서 이런 피드백 루프를 도는것은 너무나도 자연스러운 것이다.


- 프로젝트 사례

자동차 서비스 센터로 등록되는 클레임 가운데 안전 관련 클레임을 자동을 검출하는 시스템을 개발하는 텍스트 마이닝 프로젝트

'클레임 리포트'에서 오탈자가 상당히 많았지만, 제대로 탐색을 하지 않아 이를 놓치는 바람에 단어의 '스펠링 교정'을 해야하는 전처리 단계를 하지 않았고, 그 결과로 검출 성능이 떨어지게 되었다.

#### 15. '데이터 전처리' 단계가 잘못되었다면?

- 데이터 전처리의 목적은 크게 두가지가 있다.

하나는 분석 성능을 높이기 위한 전처리가 있고 하나는 분석 자체를 위한 전처리가 있다.

예를 들어서 이론적으로는 데이터의 missing이 있으면 모델학습 자체가 안된다. 이런 경우에서는 모델학습 시 모델학습 자체가 안되기 때문에 문제를 금방 발견할 수 있다. 그런데 위의 사례처럼 모델 accuracy가 99.9%로 나왔는데 리콜은 0이거나 이런 클래스 불균형 경우는 모델평가 시에 피드백 루프가 걸릴 수 밖에 없다. 

또 다른 예시로는 아래의 데이터가 있다고 치자. 보통 결측치가 있으면 결측치가 있는 행을 지우게 된다. 그래서 나는 결측치가 관측된 1 ~ 4 번 데이터를 지웠다. 그렇게 지우고 남은 완전 소수의 데이터로는 제대로 모델이 학습이 안될것이다. 그래서 이런경우에는 결측치를 제거하는 것이 아니라 어떤 대체, 추정이 필요한 케이스이다.

![7](https://user-images.githubusercontent.com/41605276/57865116-f6c2b280-7837-11e9-94fa-851955761f90.jpg)

- 데이터 전처리를 잘못하면 제대로 된 모델링이 되지 않아서, 모델링 혹은 모델평가 단계에서 다시 데이터 전처리 단계로 돌아오게 될 수 밖에 없다.

![6](https://user-images.githubusercontent.com/41605276/57865104-f1656800-7837-11e9-9f92-bdee9078ea7d.jpg)

- 부적절한 전처리 기법을 사용한 예시 : 결측치 비율이 매우 높고 데이터가 적은데 결측치를 제거한 사례


- 전처리를 하지 않은 예시 : 클래스 불균형에 대응하지 않음

#### 16. '모델링 / 모델평가' 단계가 잘못되었다면?

- 모델링에서는 주로 잘못된 모델 및 파라미터 선택으로 잘못되는 경우가 대부분이다.


- 주로 수 많은 모델을 학습해보고 가장 좋은 것을 고르게 되기 때문에 모델링 단계에서 잘못되는 경우는 거의 없음


- '모델평가' 단계에서는 적절하지 않는 지표를 사용해서 모델을 올바르게 평가하지 못하는 경우가 대부분이다.

ex) 지표를 하나만 사용하는 경우 예를들어 모델 accuracy가 99.9%로 확인이 되어 나는 정말 모델을 잘 만들었다고 착각할때가 있다.

하지만 아래의 그림처럼 confusion matrix를 그리고 recall을 계산하면 0이 되는 무언가 문제가 있는 모델을 만든 것이다.

![3](https://user-images.githubusercontent.com/41605276/57864992-c713aa80-7837-11e9-9f72-b82d4ea6fa0a.jpg)

#### 17. 피드백 루프의 최소화 방안

- 철저한 분석계획 수립만이 피드백 루프를 최소화 할 수 있다.


- 문제정의 단계에서 대략적인 분석계획을 수립하고, 데이터 탐색 단계에서 분석계획을 구체화 하는 방향으로 해야한다.


- ex) 위에서 자동차 서비스 센터 텍스트 마이닝 프로젝트

문제 정의 단계시 큰 프로세싱을 구상하고(텍스트 전처리 -> 특징선택 -> 앙상블모델 구현), 실제 데이터를 탐색할때 이런 큰 프로세싱에 대한 계획을 구체화 시킴

![8](https://user-images.githubusercontent.com/41605276/57865165-0e01a000-7838-11e9-804c-ec629b7f3616.jpg)

그렇다면 철저한 분석계획 수립은 어떻게 할 것인가 !

결론적으로는 데이터를 철저하게 탐색을 해야한다.

데이터 탐색이 문제를 파악하는 것이라고 하면 데이터 전처리는 이 문제를 해결하는 것이다.

#### 18. 현실의 데이터

현실의 데이터는 우리가 알고 있는 이쁜모양의 테이블 데이터가 아닌 경우가 많다.

#### 19. 데이터 파편화

- 효과적인 머신러닝 프로세스를 진행하려면 하나의 통합된 데이터 집합이 필요하다.


- 데이터가 분산되어있어서 발생되는 문제다. 


- 현실데이터는 데이터들끼리 따로노는 경우가 많다. 


- 예를들어서 마케팅 데이터라고 했을때 고객정보 데이터 따로 상품구매정보 데이터 따로 이런식으로 해놓는 경우가 대부분이다. 왜냐하면 전부 통합할경우 데이터 크기가 너무나도 커지기 때문에 저장과 관리를 어떻게 할 것인지에 대한 이슈가 생기기 때문이다.


- 또다른 예를 들면 공장에서 어떤 제품을 생산할때 공정에서 나오는 데이터라고 한다면 1번 공정라인 센서 데이터 하나 2번 공정라인 센서 하나 이런식으로 되어있다.


- 그래서 모델링을 위해서는 이렇게 따로 노는 얘들을 하나로 통합해주는 것이 필요하다.


- 데이터 파편화 해결유형 대표 3대장

1) 파편화된 데이터 모두 ID가 있고, ID를 기준으로 그대로 통합하면 되는 경우

ex) 일일 날씨 데이터 통합

![9](https://user-images.githubusercontent.com/41605276/57865182-15c14480-7838-11e9-96e0-26e713dacace.jpg)

2) 파편화된 데이터 모두 ID가 있고, ID마다 데이터가 따로 있는 경우

ex) 고객 정보 통합

![10](https://user-images.githubusercontent.com/41605276/57865189-1a85f880-7838-11e9-8b70-68fb260900c3.jpg)

3) 파편화된 데이터 모두 ID가 있고, 요약해야 하는 데이터가 포함된 경우

ex) 고객 정보 통합

![11](https://user-images.githubusercontent.com/41605276/57865196-1eb21600-7838-11e9-849b-b17be51872ae.jpg)

#### 20. 데이터 분포문제

- 일반화된 모델을 생성하는데 적합하지 않은 변수가 존재하여 발생하는 모든 종류의 문제


- 데이터 도메인 지식에 따라 문제가 다르기 때문에 명확한 가이드라인이 존재하지 않음


- 데이터 분포문제의 분류

1) 문자값을 가지는 변수가 존재하는 경우

2) 이상치가 존재하는 경우

2-1) 일반적인 분포에서 크게 벗어나는 이상치

ex) 신장이 250cm

2-2) 논리적 혹은 상식적으로 가질 수 없는 값 

ex) 신장이 -2cm

3) 하나의 값이나 범위에 지나치게 치우친 변수가 존재하는 경우

특정 x가 치우친 값이 아니라 다른 값을 가질때 그 얼마 없는 다른값의 영향을 너무많이 받는다.

3-1) numerical data

로그를 씌워주거나 스케일링으로 치우침 제거 가능

3-2) categorical data

범주형 변수는 원칙적으로는 치우침 문제를 해결할 수 없다. 그런데 범주형 변수를 굳이 나누자면 이진변수(0과 1로 구성)와 이진변수가 아닌변수(ex) A,B,C)가 있다. 이진변수는 치우침 문제를 해결하는 것이 불가능하다. 이진변수가 아닌경우에는 만약에 A가 있고 B랑 C가 도메인 지식으로 봤을때 그 값의 의미가 비슷한 경우에는 B와 C를 하나의 변수로 통합할 수도 있다. 이렇게 하기 위해서는 도메인 지식상 판단근거가 명확해야 한다.

예를 들어서 한국발 미국행 비행기 탑승자 데이터라고 했을때 한국인 데이터 50명 미국인 4명 영국인 1명 프랑스인 1명 이런식으로 분포가 지나치게 한국인으로 치우친 데이터라면 한국인 or 외국인 이런식으로 카테고리를 재분류를 하는 방안 말고는 효과적인 방법이 없다.

범주형 데이터인데 치우침이 심한 케이스는 '차원의 저주'문제를 해결할때 '특징선택' 기법적용 시 걸러지게 된다.  

4) 정규분포에서 크게 벗어난 변수가 존재하는 경우


5) 변수간 스케일 차이가 큰 경우

#### 21. 결측치 문제

- 결측치의 유형

1) Null, None : 값이 없는 것이 값인 데이터

통상 새로운 값으로 대체한다.

예를 들어서 해당 피쳐가 '직업'인 경우에는 None이나 Null 값은 '무직'으로 대체한다

2) N/A, NaN : Not Available의 약자로 엄밀한 의미에서 결측치

- 결측치 문제는 어느변수에서 결측이 발생했는지와 분포에 따라서 구분할 수 있다.

![12](https://user-images.githubusercontent.com/41605276/57865213-25d92400-7838-11e9-9fdd-37b4a52e8dd4.jpg)

소수의 변수에서 주로 발생한 경우 : v2와 v5 피쳐 제거

소수의 레코드에서 결측이 주로 발생한 경우 : 해당 레코드 제거

특정한 규칙이 없이 결측이 발생한 경우 : 통상 이경우가 가장 많은데 이 경우에는 데이터의 경우에 따라서 제거, 수정, 대체 등 종합적으로 고려해야 한다.

#### 22. 클래스 불균형 문제

- 분류문제에서만 발생하는 문제로 클래스 변수(종속변수)의 분포가 하나의 값(다수클래스)에 치우쳐서, 대부분 샘플을 다수 클래스로 분류하는 문제 발생


- 다수클래스 vs 소수 클래스 양상은 통상 positive class vs negative class가 되는 경우가 많다.

예를들어서 뇌 MRI 데이터를 이용해서 뇌종양을 판단하는 머신러닝 프로젝트라고 가정할때 통상 대부분의 데이터는 정상데이터 일것이고 그중에 소수가 뇌종양 데이터인데 우리가 관심있는 것은 소수의 샘플이 positive class이다. 이런 케이스에서 클래스 불균형 문제를 해결하지 않고 그냥 모델링을 하게되면 accuracy는 높을 것이나 recall이 형편없이 낮아서 병원에서 원하는 목적을 전혀 부합시키지 못하게 된다. 

클래스 불균형 문제를 해결한다는 것은 결국에는 recall은 높아지고, accuracy는 떨어진다.


- 일반적으로 클래스 불균형문제는 '클래스 불균형 비율'이라는 척도를 기준으로 분류한다. 다수클래스에 속한 샘플수룰 N이라고하고 소수클래스에 속한 샘플수를 n이라고 하면, 불균형 비율은 N/n으로 계산한다.


- 일반적으로 클래스 불균형 비율이 9 이상이면 "클래스 불균형을 의심" 으로 판단한다.

#### 23. '차원의 저주' 문제

- 변수 개수가 늘어남에 따라, 계산량이 기하급수적으로 늘어나는 문제


- 차원의 저주문제는 데이터 전처리 단계에서의 차원축소와 모델링 단계에서의 계산량이 적은 모델 선택으로 해결할 수 있다.

![13](https://user-images.githubusercontent.com/41605276/57865228-2a9dd800-7838-11e9-8bce-ba81170206df.jpg)

- 변수개수의 적절성은 샘플수를 고려해야한다.

#### 24. 데이터 탐색 및 전처리 과정을 요약한 플로우차트

![14](https://user-images.githubusercontent.com/41605276/57865239-2ffb2280-7838-11e9-8127-459e2dfef3ee.jpg)

#### 25. '모델선정' 문제

- 분석하고자 하는 데이터가 있을때 이 데이터를 분석하는데 가장 적절한 모델과 모델의 파라미터를 선정하는 문제


- 사실 어떤 모델이 좋다고 판단하는 것은 모델을 학습을 해보고 테스트 해보지 않는이상 모르는 것이다. 그래서 주로 경험에 기반한 선택(모델 직접 다 써보고 가장 좋은 걸 골라내는 방법)을 하는 경우가 많다.


- 또한 단순한 구조의 모델이 복잡한 구조의 모델보다 성능이 좋은 경우가 반드시 존재하기 때문에 이점을 잘 고려해야줘야 한다.

#### 26. '모델선정'에 영향을 주는 요인

1) 시간

분석시간이 적게 주어지면, 학습시간이 많이 소요되는 모델(예를들어서 신경망이나 서포트벡터머신 등)을 쓰는 것은 적절하지 않음

2) 데이터 크기

데이터 크기가 적으면 역시 복잡한 모델을 사용하는 것은 적절하지 않음

- 주요모델을 학습하는데 필요한 샘플 개수

각 모델을 학습하는데 필요한 절대적인 샘플 개수는 정확하게 알기가 어렵다.

분류 모델 간 비교

K-means <= 나이브베이즈 < 의사결정나무 < 로지스틱 회귀 < 랜덤포레스트 << SVN <= 신경망

예측 모델 간 비교

K-means <= 다중회귀 < 다항회귀 <= 의사결정나무 < 랜덤포레스트 << SVM 회귀 <= 신경망


보통 필요한 데이터 개수와 학습시간은 정비례한다.


3) 데이터 유형

데이터 유형에 따라 부적절한 모델을 선택하면 안된다.

4) 요구성능

요구성능이 높다면, 단순한 모델을 사용하는 것은 적절하지 않음

단순한 모델로도 성능이 좋게 나오는 경우도 존재한다. 단순한 모델의 성능이 잘 나오는 경우는 오버피팅 문제 또는 일반화 능력과 관련되어 있다.

#### 27. 모델별 주요 파라미터와 그에 따른 계산 복잡도

- 같은 모델이더라도 파라미터 설정에 따라 모델성능과 학습속도가 크게 달라진다. 따라서 모델별 주요 파라미터와 파라미터 설정에 따른 성능 등을 알아야 한다.


- 앙상블 모델은 단일 모델이 아니기 때문에 고려하지 않는다.

![15](https://user-images.githubusercontent.com/41605276/57865261-37223080-7838-11e9-8359-eac794a80507.jpg)
