---
layout: post
title: "다중공선성 대처방안"
tags: [선형회귀분석]
comments: true
---

.

[학습자료]

페이스북 텐서플로우 코리아 게시글을 읽고 정리한 내용입니다.

(2021년 1월 18일 임소현님 게시글)

[학습내용]

- 다중공선성이 높아보이는 feature들이 섞여 있는 data에 대한 regression model을 구현할때 일반적으로 대처하는 방안

방안 1) 다중공선성이 높은 해당 feature들을 VIF 등으로 찾아서 제거

방안 2) PCA를 통해서 차원 축소

방안 3) L1 패널티를 이용해서 피처 셀렛션이 자동으로 되도록 하는 방법

방안 4) correlation heatmap을 그려서 상관관계 높은 것 중 하나를 제거

- 그러면 correlation heatmap에서 서로 간의 상관관계가 높은 feature들이 5-6개 이상씩 발견될 때는 혹시 어떤 기준으로 제거하는 게 좋은지?

리그레션 돌리면 summary table을 뽑을 수 있을텐데 p value가 유의하지 않은 경우의 변수들 부터 제거해 보고 다시 돌리고 그런식으로 피쳐를 선별하는 방법이 있다. 위에서 언급한 VIF 결과를 참조해 볼 수도 있다. 다만 이런 식의 피처 선택은 prediction을 위해서는 이렇게 엄격하게 할필요까지는 없다. 물론 모델 설명을 위한 inference가 목적이면 엄격하게 하는게 맞다.

- 모델의 예측성능이 목적인 경우, LASSO, Rige,PCR, LARS 등을 사용할 수 있고, Autoencoder로 피처 뽑은 뒤 적합하는 것도 방법이다. 설명력을 지키고 싶은 경우라면 상관계수나 VIF를 이용해 순차적으로 다중공선성이 높은 변수를 제거해 나가는 것도 좋다. 아니면, 다중공선성이 큰 변수들 간 조합을 통한 도메인 기반 지수를 만드는 방법도 있다.

추가적으로 변수 클러스터링이란 방법도 있다. 원리는 관측치와 변수를 전치 시킨 뒤 군집화 하는 것인데 이걸 이 분석결과를 브릿지로 해서 공선성 제거하는 것도 가능하다.

- 결론적으로 모델의 설명력이 중요하냐 예측이 중요하냐에 따라 처리 방법이 다르다. 예측력만이 중요하면 regularization 이 들어간 모델을 쓰면 된다. 반면에 설명이 중요하면 피쳐를 논리적인 기준으로 가공해서, 중복되는 피쳐는 제거하는 방법이 일반적이다. VIF 를 이용해서 다중공선성 변수를 제거하는 것이 일반적으로 많이 쓰이는 방법이다. PCA도 좋은 방법이다. 그러나 PCA는 한단계를 거쳐서 해석해야하니 어려움이 있다. 중요한것은 복잡한 것이 아니라 간결해고 명확하게 설명할 수 있어야 한다.
