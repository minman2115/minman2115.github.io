---
layout: post
title: "Neural network 기초개념"
tags: [딥러닝]
comments: true
---

.

Deep_Learning_Studynotes_(20190629)

study program : https://www.fastcampus.co.kr/data_camp_deeplearning

#### [학습기록]

#### 1. 텐서플로우 기초


```python
import numpy as np
import tensorflow as tf
```


```python
print (tf.__version__)
```

    2.0.0-beta1
    


```python
#tf.enable_eager_execution()
```


```python
tf.executing_eagerly()
```




    True



[Defining Tensors]


```python
m1 = [[1.0, 2.0], 
      [3.0, 4.0]]
m2 = np.array([[1.0, 2.0],
              [3.0, 4.0]], dtype=np.float32)
m3 = tf.constant([[1.0, 2.0],
                 [3.0, 4.0]])

print(type(m1))
print(type(m2))
print(type(m3))
```

    <class 'list'>
    <class 'numpy.ndarray'>
    <class 'tensorflow.python.framework.ops.EagerTensor'>
    


```python
t1 = tf.convert_to_tensor(m1, dtype=tf.float32)
t2 = tf.convert_to_tensor(m2, dtype=tf.float32)
t3 = tf.convert_to_tensor(m3, dtype=tf.float32)

print(type(t1))
print(type(t2))
print(type(t3))
```

    <class 'tensorflow.python.framework.ops.EagerTensor'>
    <class 'tensorflow.python.framework.ops.EagerTensor'>
    <class 'tensorflow.python.framework.ops.EagerTensor'>
    

[Numpy Compatibility]


```python
ndarray = np.ones([3, 3])
print(ndarray,'\n')

print("TensorFlow operations convert numpy arrays to Tensors automatically")
tensor = tf.multiply(ndarray, 42)
print(tensor,'\n')


print("And NumPy operations convert Tensors to numpy arrays automatically")
print(np.add(tensor, 1),'\n')
# tf.add도 쓸 수 있다. 여기서 보여주고 싶은 것은 넘파이와 텐서플로우가 호환이 된다는 것이다.

print("The .numpy() method explicitly converts a Tensor to a numpy array")
print(tensor.numpy())
```

    [[1. 1. 1.]
     [1. 1. 1.]
     [1. 1. 1.]] 
    
    TensorFlow operations convert numpy arrays to Tensors automatically
    tf.Tensor(
    [[42. 42. 42.]
     [42. 42. 42.]
     [42. 42. 42.]], shape=(3, 3), dtype=float64) 
    
    And NumPy operations convert Tensors to numpy arrays automatically
    [[43. 43. 43.]
     [43. 43. 43.]
     [43. 43. 43.]] 
    
    The .numpy() method explicitly converts a Tensor to a numpy array
    [[42. 42. 42.]
     [42. 42. 42.]
     [42. 42. 42.]]
    

[Constants]

1.x 버전에서는 변수 선언 후 출력 시 오류가 발생했는데, 2버전은 아래와 같이 바로 출력이 가능하다

1.x 버전에서는 sess.run을 해주고 프린트를 해야 가능한 것이었다.


```python
hello = tf.constant("Hello World!")
print(hello)
```

    tf.Tensor(b'Hello World!', shape=(), dtype=string)
    


```python
a = tf.constant(1.5)
b = tf.constant(2.5)
print(a)
print(b)
```

    tf.Tensor(1.5, shape=(), dtype=float32)
    tf.Tensor(2.5, shape=(), dtype=float32)
    

[Operations]


```python
a_plus_b = tf.add(a, b)
print(a_plus_b)
```

    tf.Tensor(4.0, shape=(), dtype=float32)
    


```python
a_mul_b = tf.multiply(a, b)
print(a_mul_b)
```

    tf.Tensor(3.75, shape=(), dtype=float32)
    

[Variables]

머신러닝에서는 결국 w값을 찾는 것이 목적인데 처음에는 이 가중치 w가 어떤 값인지 모르니까 랜덤값으로 채우는 것이다. 

이때 보통은 가우시안 정규분포로 부터 랜덤한 값을 추출해서 쓴다. 아니면 유니폼분포를 쓰는 경우도 있다.


```python
weight = tf.Variable(tf.random_normal_initializer(stddev=0.1)([5, 2]))
# 평균이 0이고 표준편차가 0.1인 가우시안 정규분포 변수를 5행 2열 사이즈로 뽑는다.
print(weight)

# 1.x버전에서는 위와같이 variable을 선언하면 글로벌 베리어블 이니셜라이저 같은 것을 만들고
# 실행하고 저 웨이트를 또 sess.run을 또 실행해줘야 나왔는데 2버전은 바로 실행이 가능하다.
```

    <tf.Variable 'Variable:0' shape=(5, 2) dtype=float32, numpy=
    array([[-0.05714906, -0.08460012],
           [ 0.02706867,  0.1198655 ],
           [ 0.06843279,  0.05600017],
           [-0.10192732, -0.05903401],
           [ 0.03159029, -0.03104416]], dtype=float32)>
    

[Shape, Rank, Axis]


```python
t = tf.constant([1,2,3,4])
print(t.shape)

# 텐서플로우에서 shape를 찍으면 파이썬의 튜플형태로 나온다.
```

    (4,)
    


```python
t = tf.constant([[1,2],
                 [3,4]])
print(t.shape)
```

    (2, 2)
    


```python
t = tf.constant([[[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]],[[13, 14, 15, 16], [17, 18, 19, 20], [21, 22, 23, 24]]]])
print(t.shape)

# 괄호가 4개가 있으니까 일단 4차원이다.
# 이 4를 튜플의 맨 마지막에 써준다.
# 그리고 두번째 닫는괄호가 2개연속 나올때까지 이 괄호가 몇개 나온가 보니까 3개이다.
# 그러면 이 3을 튜플의 마지막에서 두번째로 써준다.
# 그 다음에 두개받는 괄호가 3개닫는 괄호나올때까지 몇번나왔는지 보니까 2개이다.
# 그 다음에 세개닫는 괄호가 네개 단는 괄호나올때까지 몇번나왔는지 보니까 1개이다.
# 그래서 (1,2,3,4)이고 이게 텐서플로우에서 shape이다.
```

    (1, 2, 3, 4)
    


```python
np.array(
[
    [
        [
            [1,2,3,4], 
            [5,6,7,8],
            [9,10,11,12]
        ],
        [
            [13,14,15,16],
            [17,18,19,20], 
            [21,22,23,24]
        ]
    ]
]
).shape
```




    (1, 2, 3, 4)



[Matmul VS multiply]


```python
matrix1 = tf.constant([[3., 3.]])
matrix2 = tf.constant([[2.],
                       [2.]])
print(tf.matmul(matrix1, matrix2))
```

    tf.Tensor([[12.]], shape=(1, 1), dtype=float32)
    


```python
print(matrix1*matrix2)
```

    tf.Tensor(
    [[6. 6.]
     [6. 6.]], shape=(2, 2), dtype=float32)
    

[Watch out broadcasting]


```python
matrix1 = tf.constant([[3., 3.]])
matrix2 = tf.constant([[2.],
                       [2.]])
print(matrix1+matrix2)
```

    tf.Tensor(
    [[5. 5.]
     [5. 5.]], shape=(2, 2), dtype=float32)
    


```python
matrix1 = tf.constant([[3., 3.]])
matrix2 = tf.constant([[2., 2.]])
print(matrix1+matrix2)
```

    tf.Tensor([[5. 5.]], shape=(1, 2), dtype=float32)
    

[Reduce Mean/Sum]


```python
print(tf.cast(tf.reduce_mean([1., 2.], axis=0),tf.float32))
# reduce_mean은 평균낸다는 것이다.

print(tf.cast(tf.reduce_mean([1, 2], axis=0),tf.int32))
```

    tf.Tensor(1.5, shape=(), dtype=float32)
    tf.Tensor(1, shape=(), dtype=int32)
    


```python
x = [[1., 2.],
     [3., 4.]]


print(tf.reduce_mean(x))
```

    tf.Tensor(2.5, shape=(), dtype=float32)
    


```python
# 아래와 같이 축을 정해서 reduce_mean을 할 수 있다.
# axis = 0은 행끼리 다 더해서 평균을 내는 것임
print(tf.reduce_mean(x, axis=0))
```

    tf.Tensor([2. 3.], shape=(2,), dtype=float32)
    


```python
print(tf.reduce_mean(x, axis=1))
# 반면에 axis =1 은 열끼리 더해서 평균을 낸다는 것이다.
```

    tf.Tensor([1.5 3.5], shape=(2,), dtype=float32)
    


```python
print(tf.reduce_mean(x, axis=-1))
# axis = -1은 맨마지막을 의미한다. 
# 0번 1번 축이 두개밖에 없는데 마지막이 1번 축이니까 1번축으로 reduce_mean을 한 것이다.
```

    tf.Tensor([1.5 3.5], shape=(2,), dtype=float32)
    


```python
print(tf.reduce_sum(x))
```

    tf.Tensor(10.0, shape=(), dtype=float32)
    


```python
print(tf.reduce_sum(x, axis=0))
```

    tf.Tensor([4. 6.], shape=(2,), dtype=float32)
    


```python
print(tf.reduce_sum(x, axis=-1))
```

    tf.Tensor([3. 7.], shape=(2,), dtype=float32)
    


```python
print(tf.reduce_mean(tf.reduce_sum(x, axis=-1)))
```

    tf.Tensor(5.0, shape=(), dtype=float32)
    

[Argmax with axis]


```python
x = [[5, 6, 7],
     [7, 6, 5]]
print(tf.argmax(x, axis=0))
# argmax는 max값을 찾아서 거기의 index를 리턴하는 것이다.
# 얘도 마찬가지로 축을 정해서 연산할 수 있다.
# axis는 0이니까 행끼리 연산한다는 것이다.
```

    tf.Tensor([1 0 0], shape=(3,), dtype=int64)
    


```python
print(tf.argmax(x, axis=1))
# 반연에 여기서는 axis가 1이기 때문에 열끼리 연산한다.
```

    tf.Tensor([2 0], shape=(2,), dtype=int64)
    


```python
print(tf.argmax(x, axis=-1))
```

    tf.Tensor([2 0], shape=(2,), dtype=int64)
    

[Reshape, squeeze, expand_dims]


```python
t = np.array([[[0, 1, 2], 
               [3, 4, 5]],
              
              [[6, 7, 8], 
               [9, 10, 11]]])
print(t.shape)
```

    (2, 2, 3)
    


```python
print(tf.reshape(t, shape=[-1, 3]))
# reshape도 가능하다. 
# -1로 되어 있으면 알아서 채우라는 말인데 무슨말이냐면
# 총 숫자가 12개이고 열이 3개짜리니까 행은 4로해서 채우라는 것이다. 
```

    tf.Tensor(
    [[ 0  1  2]
     [ 3  4  5]
     [ 6  7  8]
     [ 9 10 11]], shape=(4, 3), dtype=int64)
    


```python
print(tf.reshape(t, shape=[-1, 1, 3]))
# 결국에는 (4,1,3)이 된다.
```

    tf.Tensor(
    [[[ 0  1  2]]
    
     [[ 3  4  5]]
    
     [[ 6  7  8]]
    
     [[ 9 10 11]]], shape=(4, 1, 3), dtype=int64)
    


```python
print(tf.squeeze([[0], [1], [2]]))
# squeeze라는 것은 차원이 여러개 있는것을 한방에 1차원으로 줄여주는 것을 말한다.
```

    tf.Tensor([0 1 2], shape=(3,), dtype=int32)
    


```python
print(tf.expand_dims([0, 1, 2], 1))
# 반면에 expand_dim이라는 것은 여기서는 얘가 지금 1차원을 하나 뒤에 늘려준다는 것이다.
```

    tf.Tensor(
    [[0]
     [1]
     [2]], shape=(3, 1), dtype=int32)
    

[One hot]


```python
print(tf.one_hot([0, 1, 2, 0], depth=3))
```

    tf.Tensor(
    [[1. 0. 0.]
     [0. 1. 0.]
     [0. 0. 1.]
     [1. 0. 0.]], shape=(4, 3), dtype=float32)
    

[Type Casting]


```python
print(tf.cast([1.8, 2.2, 3.3, 4.9], tf.int32))
```

    tf.Tensor([1 2 3 4], shape=(4,), dtype=int32)
    


```python
print(tf.cast([True, False, 1 == 1, 0 == 1], tf.int32))
```

    tf.Tensor([1 0 1 0], shape=(4,), dtype=int32)
    

[Create a Dataset]


```python
a = np.arange(10)
print(a)
ds_tensors = tf.data.Dataset.from_tensor_slices(a)

# 데이터를 사용할 수 있게 전처리를 하면 네트워크에 데이터를 넣어줘야 하기 때문에
# input 데이터랑 정답 레이블을 묶어서 보통 데이터셋이라는 것을 만들고 파이프 라인을 구성한다.
```

    [0 1 2 3 4 5 6 7 8 9]
    

[Apply Transformations]


```python
ds_tensors = ds_tensors.map(tf.square).shuffle(20).batch(2)
# tf.square = 제곱을해라
# shuffle 괄호 안에 20은 20이라는 공간을 준다는 것이다 위에서는 10개를 만들었기 때문에
# 공간은 10개 이상만 주면 문제 없다.
# 예를 들어서 위와 같이 ds_tensors를 만들면 이걸 가지고 배치를 임의로 하라고 할 수도 있고, 셔플을 할 수도 있다.
```

[Iterate]


```python
# 데이터 셋을 한번씩 다 쓰는 것을 1에포크라고 한다.
# 보통 1에포크를 돌고나서 데이터셋을 셔플한다음에 또 에포크를 돈다.
print('Elements of ds_tensors:')
for _ in range(3):
  for x in ds_tensors:
    print(x)
```

    Elements of ds_tensors:
    tf.Tensor([36 81], shape=(2,), dtype=int64)
    tf.Tensor([4 1], shape=(2,), dtype=int64)
    tf.Tensor([49  0], shape=(2,), dtype=int64)
    tf.Tensor([64  9], shape=(2,), dtype=int64)
    tf.Tensor([16 25], shape=(2,), dtype=int64)
    tf.Tensor([36 81], shape=(2,), dtype=int64)
    tf.Tensor([4 1], shape=(2,), dtype=int64)
    tf.Tensor([49  0], shape=(2,), dtype=int64)
    tf.Tensor([64  9], shape=(2,), dtype=int64)
    tf.Tensor([16 25], shape=(2,), dtype=int64)
    tf.Tensor([36 81], shape=(2,), dtype=int64)
    tf.Tensor([4 1], shape=(2,), dtype=int64)
    tf.Tensor([49  0], shape=(2,), dtype=int64)
    tf.Tensor([64  9], shape=(2,), dtype=int64)
    tf.Tensor([16 25], shape=(2,), dtype=int64)
    

#### 2. 선형회귀, 로지스틱 회귀 기초개념

- 선형회귀의 기본적인 목표 -> 정비례 규칙을 찾고 싶다.


- 선형회귀는 딥러닝에서 계속 사용되는 것이다. 히든레이어에서 아웃풋레이어로 가는 마지막과정에서 무조건 선형회귀 아니면 로지스틱 회귀를 쓰기 때문이다. 딥러닝에서 classification을 하게되면 로지스틱 회귀를 쓸 것이고, 선형회귀를 한다면 선형회귀를 쓸 것이다.


- 리그레션은 입력으로 discrete한게 들어갈 수도 있고, continuous한게 들어갈 수도 있는데 출력으로는 continuous한 것을 출력하는 것을 말한다.


- 예를 들어서 내가 갖고 있는 데이터가 키와 몸무게 기록이 있는 학생들의 데이터라고 했을때 새로 전학온 학생의 키가 175cm라면 몸무게는 어떨지, 양의 상관관계가 있는 것인지 찾는 것이다.


- 아래 그림과 같이 이 검정색 점들(데이터)을 가장 잘 표현할 수 있는 직선을 찾고 그 직선위에서 예측을 하는 것이라고 할 수 있다.


- 이 선형회귀를 뉴럴네트워크로 만들면 아래의 그림과 같이 1개의 퍼셉트론이면 충분하다. 활성화 함수는 보통 시그모이드 함수 같은 non-linear 함수가 들어갔지만 선형회귀를 구현할때는 그냥 데이터를 변형없이 그대로 통과시키기만 하면 된다.

![1](https://user-images.githubusercontent.com/41605276/80909993-9a69e300-8d67-11ea-8c67-405a2c762cbe.png)

- 그렇다면 데이터를 표현하는 직선은 여러개가 될텐데 어떤 직선이 가장 좋은 것이고 어떤 직선은 나쁜직선인지 판단할 수 있어야 한다. 그래서 대표적으로 하는 방법이 Residula Sum of Square(잔차제곱합) 또는 mean squared error이다.

![2](https://user-images.githubusercontent.com/41605276/80909997-a6ee3b80-8d67-11ea-9003-5f3f854b9e2a.png)

- 그래서 우리는 이 잔차제곱합을 최소화하는 w와 b를 찾아야 한다. 그러면 어떻게 찾을 것이냐. cost function을 미분에서 최소값(미분=0이되는 점)을 찾아야 한다. 그래서 우리는 w로도 미분하고, b로도 미분하여 w로 미분했을때 0되는 점을 찾으면 그게 loss을 최소화하는 w를 찾는 것이다. b로 미분해서 0되는 점을 찾으면 그때 b값이 loss를 최소화하는 b가 될 것이다.

![3](https://user-images.githubusercontent.com/41605276/80910001-ace41c80-8d67-11ea-9a79-b9f560f17ed2.png)

- 예를 들어서 아래 그림과 같이 x와 y값을 갖는 데이터가 3개 있다고 치자. 이때 이 세점을 가장 잘 설명하는 선형회귀를 한다고하자.

![4](https://user-images.githubusercontent.com/41605276/80910005-b3729400-8d67-11ea-8ca3-0c858ff0ceb0.png)

- 위에서는 간단하게 x가 스칼리인 단순한 형태의 선형회귀를 한 것이었다. 보통 현실에서는 x라는게 스칼라값이 아니라 아래 예시와 같이 벡터값인 멀티베리어블 리니어 리그레션이 대부분이다.

![5](https://user-images.githubusercontent.com/41605276/80910007-b9687500-8d67-11ea-8553-a0b0d9af1465.png)

- 결론적으로 잔차제곱합을 최소화 하는 w를 구하는 공식이 있고, 아래와 같다.

$$\ w = (X^TX)^{-1} X^T y $$

위의 식을 증명하는 과정은 아래와 같다.

y헷 = Xw, e(잔차벡터) = y - y헷 = y - Xw

$$\ \begin{eqnarray}
\text{RSS}
&=&  e^Te \\
&=& (y - Xw)^T(y - Xw) \\
&=& y^Ty - 2y^T X w + w^TX^TXw  
\end{eqnarray} $$ 

잔차제곱합을 가장 작게하는 가중치 벡터 w를 구하기 위해 잔차제곱합의 그레디언트 벡터(w로 미분)를 구하면 아래와 같다.

$$\ \dfrac{d \text{RSS}}{d w} = -2 X^T y + 2 X^TX w $$

잔차가 최소가 되는 최적화 조건은 그레디언트 벡터가 0벡터여야 한다. 따라서 아래와 같은 식이 나온다.

dRSS / dW = 0

$$\ X^TX w = X^T y $$

$$\ w = (X^TX)^{-1} X^T y $$

단 XTX행렬의 역행렬이 존재해야하고, 양의 정부호 행렬이어야 한다. 또한 X의 각 행렬이 서로 독립이어야 한다. XTX행렬이 역행렬이 존재하지 않다는 의미는 해가 무수히 많거나 해가 없다는 의미이다.


- 선형회귀는 closed form이 위와 같이 존재한다. 최적점을 directly 구할 수 있다는 것이다.

![7](https://user-images.githubusercontent.com/41605276/80910014-c6856400-8d67-11ea-857c-ef24f0152a34.png)

- 위와 같은 경우도 주의해야 한다. 위와 같은 경우는 예를들어서 내가 풀어야 하는 미지수는 두개 인데 데이터를 한개 준 경우이다.


- 선형회귀로 classification도 가능한데 아래 예시와 같이 아웃라이어에는 취약하다는 단점이 있다.

![6](https://user-images.githubusercontent.com/41605276/80910018-cbe2ae80-8d67-11ea-8312-83ffc474f47b.png)

- 보통 잔차를 제곱하기 때문에 잔차가 커질 경우 이것이 극대화 되기 때문에 이런 현상이 있는 것이다. 그래서 잔차제곱합이 아니라 mean absolute error를 쓰기도 한다.


- 어쨌든 이런 문제점 때문에 나온 개념이 시그모이드 함수를 적용하는 것이다. 아주 크거나 아주 작은 데이터에 영향을 받지 않았으면 좋겠고, 바이너리 classification에 맞게 0에서 1사이 값으로 출력하는 것이다. 


- 그래서 선형회귀에 로지스틱 함수를 적용한 것이 로지스틱 선형회귀다. 뉴럴네트워크에서도 퍼셉트론 한개에 활성화 함수로 시그모이드를 집어넣어주면 로지스틱 선형회귀를 구현할 수 있다.

![8](https://user-images.githubusercontent.com/41605276/80910022-d1d88f80-8d67-11ea-87b5-9897f5bbf4c3.png)

- 선형회귀와 마찬가지로 cost function을 정의해줘야 한다. 로지스틱 리그레션의 로스함수는 위에 나와있는 것을 미분하여 나온 결과(아래 수식에서 가장 하단에 있는 빨간색박스, LL)을 최소화 시켜주면 된다. 

![16](https://user-images.githubusercontent.com/41605276/80910027-d8670700-8d67-11ea-9ba0-0c0b26cf79ea.png)

\begin{eqnarray}
w_{k+1} 
&=& w_{k} - \eta_k \dfrac{1}{m} \sum_{i=1}^m \big(\mu(x_i; w_k) - y_i  \big ) x_i\\
\end{eqnarray}


- 그러면 로지스틱 회귀분석을 확률적인 관점에서 접근해보자.


- 로지스틱 회귀분석에서 손실함수로 크로스엔트로피를 주로 많이 쓴다. mean squared error를 쓸 수도 있지만 통상적으로는 크로스 엔트로피를 많이 쓴다. 위에서 정의한 로스함수가 베르누이 확률분포의 MLE인데 이게 결국에는 크로스 엔트로피를 말하는 것이다. 

![9](https://user-images.githubusercontent.com/41605276/80910031-ddc45180-8d67-11ea-8eda-8dbcc26c3e68.png)

- 크로스 엔트로피는 그래서 pi에다가 데이터셋의 정답의 분포를 넣고, qi에다가는 내 모델이 예측한 값의 분포를 넣어서 엔트로피를 계산하게 된다. 그래서 이 크로스 엔트로피를 최소화 하는 것은 p와 q의 분포가 가까워 지도록 만들어지는 것이다. 그러면 결과적으로는 H(p)에 p와 q의 쿨벡라이불러 디버전스를 더한 것이 되고 이 값을 최소화 시켜야 한다.

![10](https://user-images.githubusercontent.com/41605276/80910035-e3ba3280-8d67-11ea-8735-c07543766e14.png)

- p와 q가 가까울 수록 KL Divergence가 작아지게 된다. 반면에 멀어질 수록 커진다. 결국에는 크로스엔트로피를 최소화 한다는 것은 KL Divergence 즉, 실제 정답의 확률분포와 내 네트워크가 예측한 확률분포가 최대한 같게 만든다는 것이다.


- 결국에는 아래와 같은 식이 나오고 이 케이스에서는 선형회귀처럼 closed form이 없기 때문에 미분을 사용해서 iterative하게 최적점을 찾아야 한다.

![11](https://user-images.githubusercontent.com/41605276/80910045-ea48aa00-8d67-11ea-9452-61fc10074a63.png)

- 그레디언트가 벡터의 미분이기 때문에 항상 가리키는 방향이 있다. 이 가리키는 방향이 최대로 상승하는 방향이고 그래서 그것의 반대방향으로 조금식 이동해야한다.


- 만개의 데이터가 있다면 만개 데이터를 다 집어넣고 그거에 대해서 loss를 만개 계산하고 로스를 평균해서 그레디언트를 조금 업데이트하고, 다시 만개의 데이터를 이용해서 loss 계산하고 로스를 평균해서 그레디언트를 조금 업데이트하는 이런 과정이 너무 비효율적이어서 나온 것이 SGD 방법이다.


- 미니배치 사이즈를 더 작은 배치사이즈를 가져가면 경험적으로 일반화 성능이 증가한다는 연구결과가 있다. 


- 아래 빨간 글씨와 같이 배치사이즈에 비례해서 learning rate를 키워줘야 한다.

![12](https://user-images.githubusercontent.com/41605276/80910052-f03e8b00-8d67-11ea-9577-e8031dd1f86b.png)

- 로지스틱 회귀분석의 확률적인 관점

![13](https://user-images.githubusercontent.com/41605276/80910054-f6346c00-8d67-11ea-99e9-254a6d53cd44.png)

- 결국에는 Maximum likelihood estimation이 핵심이다. 예를 들어서 어떤 물건을 동전던지기 처럼 던져서 앞면이 나올 확률을 계산한다고 하면 10번던져서 앞면이 6번 나왔다고 하면 MLE를 계산하면 0.6의 확률로 앞면이 나올것이라고 판단할 수 있는 것이다. 다시말해서 p(앞면이 나올 확률)가 얼마면 10번 던졌을때 6번 나올 확률이 최대가 될 것이냐이다.


- 선형회귀는 가우시안 정규분포를 가정하고 한다. 그래서 내 네트워크에서 가우시안 정규분포를 표현하려면 평균과 분산이 필요한데 보통 분산을 1로 넣고 평균을 내 네트워크의 아웃풋값을 넣는것이다. 다시말해 내 네트워크는 y에 대한 평균값을 예측하는 것이다. 그래서 이 내 네트워크의 예측값이 얼마가 되면 y의 평균이 제일 확률이 커질지 (평균이 y가 되면 확률이 커질 것이다) 구하는 것이다. 그래서 세타랑 x가 주어지면 y가 나올 확률을 최대화하는 모델을 만드는 것이다. 


- 이를 위해 아래 그림과 같은 개념을 가정한다. 이러한 가정을 바탕으로 NLL을 최소화 시키는 것을 목적으로 한다.

![14](https://user-images.githubusercontent.com/41605276/80910061-fb91b680-8d67-11ea-98f0-71bb8eeed162.png)

- 그래서 확률론적인 관점에서의 선형회귀에서 평균을 예측한다는 것은 아래 그림과 같다. y가 세타(w)x + e(엡실론 = 노이즈)로 되어 있어서 원래 직선이 있는데 노이즈의 변동이 있을 수 있다는 것이다. 그래서 나는 아래 그림에서 빨간선을 예측하고 싶다는 것이다. 그리고 로지스틱 리그레션에서는 베르누이 분포를 가정하기 때문에 아래처럼 표현할 수 있다. 그래서 x랑 세타가 주어졌을때 나오는 모델의 예측값이 1이될 확률을 구하는 것이다. 


- 결론적으로는 확률론적인 관점에서 각각 가우시안분포와 베르누이 분포의 log likelihood가 되는 것이다. classification에서 MSE는 거의 안쓴다고 보면 된다. 딥러닝에서 back propogation할때 문제가 발생하기 때문이다.

![15](https://user-images.githubusercontent.com/41605276/80910069-02b8c480-8d68-11ea-8271-cc8d4843345c.png)

#### 3. 텐서플로우로 구현하는 선형회귀 기초예시


```python
# For reproducibility
np.random.seed(777)
```


```python
# inputs
x = np.linspace(0, 1, 100, dtype=np.float32)

# ground truth
#slopes = np.random.normal(1, 0.5, 100).astype(np.float32)
#intercept = 2.

slopes = 1
intercept = np.random.normal(2, 0.2, 100).astype(np.float32) 
# intercept는 y절편을 말하는건데 가우시안노이즈를 추가했다.
# 평균을 2로하고 표준편차를 0.2로해서 숫자를 100개를 뽑은 것이다.

# outputs
y = x * slopes + intercept

print(slopes,'\n')
print(intercept,'\n')
```

    1 
    
    [1.9547869 1.824274  1.8056791 2.010833  2.0122182 2.2347631 2.2287183
     2.077177  2.1068094 2.1087186 1.9466289 1.91932   1.9549191 1.8770003
     2.2847564 2.2275352 1.8689951 2.1924345 2.1293433 2.0995014 1.7575988
     1.6364014 2.181351  2.2058055 2.099426  2.3211308 1.9810917 2.0393143
     2.2172887 2.1068354 2.0735013 1.4907011 1.9785335 1.9774646 1.9980901
     1.8917161 1.8111721 2.1072378 1.9168694 2.064694  2.0898936 2.4954464
     1.9638982 2.0016527 1.9123851 2.2182038 2.0242357 1.8930213 2.2925956
     1.7977242 2.0249991 1.6656373 2.3446465 2.1401873 2.3759246 2.336075
     1.9173069 1.8972042 1.9103351 1.9130999 2.0994534 2.0899262 1.9150633
     1.6544553 1.8792466 2.0961046 2.0391808 2.3070164 1.9809688 1.7562392
     1.8053478 2.2675219 1.9953964 1.8409156 2.1230865 1.8717061 1.9040357
     1.8411719 1.8584155 1.96766   2.0622861 1.5282812 2.181365  2.26566
     2.1062274 2.1265802 2.1384265 1.7657336 2.1723344 1.578645  1.905852
     1.8994441 1.9445403 2.231417  2.2262204 1.7743596 1.9463279 2.162859
     1.8059686 2.0007808] 
    
    


```python
plt.scatter(x, y)
plt.plot(x, x * 1 + 2., label="ground truth", c="r")
plt.legend()
plt.show()
```


![95_0](https://user-images.githubusercontent.com/41605276/80910523-eb2f0b00-8d6a-11ea-955b-3eaeb5d72db5.png)


```python
x.dtype
```




    dtype('float32')




```python
y.dtype
```




    dtype('float32')




```python
x.shape
```




    (100,)




```python
y.shape
```




    (100,)




```python
# Computation
## Variables = Parameters = Weights
w = tf.Variable(.1, tf.float32)
b = tf.Variable(0., tf.float32)

# y = 0.1x + 0 부터 시작하겠다는 의미이다.
```


```python
learning_rate = 0.1

loss_list, w_list, b_list = [], [], []

for epoch in range(20): 
# 데이터가 100가 있는데 미니배치를 하지는 않을 것이고 통째로 20 에포크를 돈다는 것이다.
    with tf.GradientTape() as tape: 
        ## prediction = y_hat = hypothesis
        preds = x * w + b # (100,)
        loss = tf.reduce_mean(tf.square(preds - y))
        
    w_grad, b_grad = tape.gradient(loss, [w, b])
    # 그레디언트로 w와 b로 미분해라
    w.assign_sub(learning_rate * w_grad)
    # 이전의 w값에다가 러닝레이트 곱하기 w그레디언트 계산한 것을 할당해라
    b.assign_sub(learning_rate * b_grad)
    print(epoch+1, "\t", loss.numpy(), "\t", w.numpy(), "\t", b.numpy())
    loss_list.append(loss.numpy())
    w_list.append(w.numpy())
    b_list.append(b.numpy())
```

    1 	 6.148821 	 0.36019328 	 0.49210268
    2 	 3.443053 	 0.55374247 	 0.8597654
    3 	 1.9355677 	 0.697557 	 1.1345408
    4 	 1.0956739 	 0.80425787 	 1.3399796
    5 	 0.6277118 	 0.88326555 	 1.4936606
    6 	 0.36696243 	 0.94161135 	 1.6087046
    7 	 0.22165686 	 0.9845434 	 1.6949052
    8 	 0.14066862 	 1.0159788 	 1.7595725
    9 	 0.095513895 	 1.0388412 	 1.8081628
    10 	 0.070323855 	 1.0553128 	 1.8447487
    11 	 0.056257486 	 1.067022 	 1.8723704
    12 	 0.048389196 	 1.0751845 	 1.8932967
    13 	 0.04397484 	 1.0807074 	 1.9092215
    14 	 0.041485578 	 1.0842679 	 1.9214091
    15 	 0.04006961 	 1.086371 	 1.9308032
    16 	 0.03925238 	 1.0873938 	 1.9381081
    17 	 0.038769484 	 1.0876175 	 1.9438498
    18 	 0.03847358 	 1.0872521 	 1.9484208
    19 	 0.038282588 	 1.0864542 	 1.9521141
    20 	 0.038150713 	 1.0853403 	 1.9551486
    


```python
plt.plot(loss_list, label="loss")
plt.plot(w_list, label="w")
plt.plot(b_list, label="b")
plt.legend()
plt.show()
```


![102_0](https://user-images.githubusercontent.com/41605276/80910533-fbdf8100-8d6a-11ea-8da3-e7116245a1ba.png)




```python
# 빨간색 선이 모델에서 예측한 선, 초록색이 정답
plt.scatter(x, y)
plt.plot(x, x * w_list[-1] + b_list[-1], label="model", c="r")
plt.plot(x, x * 1 + 2., label="ground truth", c="g")
plt.legend()
plt.show()
```


![103_0](https://user-images.githubusercontent.com/41605276/80910542-0bf76080-8d6b-11ea-8aa0-e62153c90a95.png)



#### 4. 텐서플로우의 캐라스로 구현하는 선형회귀 기초예시


```python
# For reproducibility
np.random.seed(777)
```


```python
# inputs
x = np.linspace(0, 1, 100, dtype=np.float32)

# ground truth
#slopes = np.random.normal(1, 0.5, 100).astype(np.float32)
#intercept = 2.

slopes = 1
intercept = np.random.normal(2, 0.2, 100).astype(np.float32)

# outputs
y = x * slopes + intercept
```


```python
slopes
```




    1




```python
intercept
```




    array([1.9063582, 1.835435 , 1.9869239, 1.8573276, 2.1812701, 2.1532474,
           2.1652107, 1.7352635, 1.6495111, 2.2004898, 2.1089618, 2.3790321,
           1.8461285, 1.7193809, 1.8735065, 1.8882253, 1.7533537, 1.9120992,
           2.1829574, 2.053008 , 1.723326 , 2.1371024, 2.0912182, 1.9077251,
           2.01894  , 1.6914377, 2.495874 , 2.0913734, 1.9372255, 2.0042074,
           2.1921587, 2.0116966, 1.9107935, 2.0638394, 2.1682336, 1.6934476,
           1.9436831, 2.3488905, 1.8651522, 2.1176803, 2.3608727, 2.41125  ,
           2.2909164, 1.9723177, 2.0685744, 1.8544763, 1.7192107, 1.7518778,
           1.9113035, 1.990535 , 2.151537 , 1.9695828, 1.9457442, 1.8800321,
           1.5946192, 2.0660684, 1.9338338, 1.9930116, 2.0579495, 1.878746 ,
           1.9463191, 2.2382956, 2.0315228, 2.2349648, 2.264182 , 1.8303926,
           2.1491416, 1.9376757, 1.7897869, 1.7847006, 2.090122 , 2.0817482,
           1.7140917, 2.2034855, 1.9836458, 1.9232163, 1.9523549, 2.0017576,
           2.1040938, 2.080741 , 1.9196435, 1.860551 , 2.1291966, 1.9448934,
           1.924158 , 2.393607 , 2.0404994, 2.0745394, 2.1962693, 2.1472924,
           2.2822602, 1.9746964, 2.1106315, 1.8368928, 2.1077404, 1.556441 ,
           1.8187416, 1.7075751, 1.864487 , 2.3045607], dtype=float32)




```python
plt.scatter(x, y)
plt.plot(x, x * 1 + 2., label="ground truth", c="r")
plt.legend()
plt.show()
```


![109_0](https://user-images.githubusercontent.com/41605276/80910547-17e32280-8d6b-11ea-96de-76fb7300140b.png)




```python
x.dtype
```




    dtype('float32')




```python
y.dtype
```




    dtype('float32')




```python
x.shape
```




    (100,)




```python
y.shape
```




    (100,)




```python
l0 = tf.keras.layers.Dense(units=1, input_shape=[1])
# dense layer라고해서 fully connected layer이다.
# 하나의 입력이 있고 하나의 units(출력의 갯수)가 있는 것이다.
# input shape = 1로 되어 있는데 데이터 100개가 있고 이게 다 들어갈거지만 
# 데이터가 하나씩 스칼라로 들어가기 때문에 1이다.
```


```python
model = tf.keras.models.Sequential([l0])
# 모델.시퀀스에 레이어를 넣어주면 된다.
```


```python
model.summary()
# 레이어가 하나이고 입력으로 들어갈 것은 
# (None, 1)은 None은 항상 배치사이즈이다. 
# 데이터는 배치사이즈 만큼 들어갈거고 우리는 100개 다 집어넣을 것이다.
# 그리고 아웃풋은 항상 1로 나오는 걸로 할 것이다.
# 파라미터는 w랑 b 두개이다.
```

    Model: "sequential"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    dense (Dense)                (None, 1)                 2         
    =================================================================
    Total params: 2
    Trainable params: 2
    Non-trainable params: 0
    _________________________________________________________________
    


```python
model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.SGD(0.1))
```


```python
history = model.fit(x, y, epochs=20)
```

    Train on 100 samples
    Epoch 1/20
    100/100 [==============================] - 1s 7ms/sample - loss: 5.3434
    Epoch 2/20
    100/100 [==============================] - 0s 93us/sample - loss: 0.5485
    Epoch 3/20
    100/100 [==============================] - 0s 90us/sample - loss: 0.1098
    Epoch 4/20
    100/100 [==============================] - 0s 89us/sample - loss: 0.0609
    Epoch 5/20
    100/100 [==============================] - 0s 104us/sample - loss: 0.0569
    Epoch 6/20
    100/100 [==============================] - 0s 79us/sample - loss: 0.0542
    Epoch 7/20
    100/100 [==============================] - 0s 97us/sample - loss: 0.0522
    Epoch 8/20
    100/100 [==============================] - 0s 97us/sample - loss: 0.0505
    Epoch 9/20
    100/100 [==============================] - 0s 86us/sample - loss: 0.0493
    Epoch 10/20
    100/100 [==============================] - 0s 113us/sample - loss: 0.0483
    Epoch 11/20
    100/100 [==============================] - 0s 72us/sample - loss: 0.0474
    Epoch 12/20
    100/100 [==============================] - 0s 86us/sample - loss: 0.0464
    Epoch 13/20
    100/100 [==============================] - 0s 87us/sample - loss: 0.0446
    Epoch 14/20
    100/100 [==============================] - 0s 91us/sample - loss: 0.0445
    Epoch 15/20
    100/100 [==============================] - 0s 98us/sample - loss: 0.0435
    Epoch 16/20
    100/100 [==============================] - 0s 96us/sample - loss: 0.0429
    Epoch 17/20
    100/100 [==============================] - 0s 98us/sample - loss: 0.0423
    Epoch 18/20
    100/100 [==============================] - 0s 97us/sample - loss: 0.0414
    Epoch 19/20
    100/100 [==============================] - 0s 93us/sample - loss: 0.0416
    Epoch 20/20
    100/100 [==============================] - 0s 95us/sample - loss: 0.0407
    


```python
plt.xlabel('Epoch Number')
plt.ylabel("Loss Magnitude")
plt.plot(history.history['loss'])
```




![119_1](https://user-images.githubusercontent.com/41605276/80910554-27fb0200-8d6b-11ea-8fe4-d0047d2b791e.png)




```python
model.variables[0].numpy(), model.variables[1].numpy()
# 0번은 w, 1번은 b를 말하는 것이다.
```




    (array([[0.82106805]], dtype=float32), array([2.0804424], dtype=float32))




```python
plt.scatter(x, y)
plt.plot(x, x * model.variables[0][0].numpy() + model.variables[1].numpy(), label="model", c="r")
plt.plot(x, x * 1 + 2., label="ground truth", c="g")
plt.legend()
plt.show()
```


![121_0](https://user-images.githubusercontent.com/41605276/80910559-334e2d80-8d6b-11ea-9a8c-3ab087416fbf.png)


#### 5. 실제 데이터를 이용한 선형회귀 구현예시

- 사용한 데이터 : birth_life_2010.txt


- 독립변수 : 국가별 평균출생률


- 종속변수 : 국가별 기대수명


```python
#DATA_FILE = './data/birth_life_2010.txt'
DATA_FILE = '/content/gdrive/My Drive/TensorFlow_Training_13th/data/birth_life_2010.txt'
```


```python
def read_birth_life_data(filename):
    """
    Read in birth_life_2010.txt and return:
    data in the form of NumPy array
    n_samples: number of samples
    """
    text = open(filename, 'r').readlines()[1:]
    data = [line[:-1].split('\t') for line in text]
    births = [float(line[1]) for line in data]
    lifes = [float(line[2]) for line in data]
    data = list(zip(births, lifes))
    n_samples = len(data)
    data = np.asarray(data, dtype=np.float32)
    return data, n_samples
```


```python
data, n_samples = read_birth_life_data(DATA_FILE)
data[:3]
```




    array([[ 1.822  , 74.82825],
           [ 3.869  , 70.81949],
           [ 3.911  , 72.15066]], dtype=float32)




```python
w = tf.Variable(0.1, tf.float32)
b = tf.Variable(0., tf.float32)
```


```python
learning_rate = 0.001
optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)
```


```python
for epoch in range(100):
    total_loss = 0.
    for x, y in data:
        with tf.GradientTape() as tape:
            hypothesis = w * x + b
            loss = tf.reduce_mean(tf.square(hypothesis - y))
        grads = tape.gradient(loss, [w, b])
        optimizer.apply_gradients(grads_and_vars=zip(grads, [w, b]))
        # sgd라는 옵티마이저를 이용해서 그레디언트를 업데이트 해달라는 의미이고
        # grads and vars라는 곳에는 그레디언트랑 weight 바이어스를 zip으로 묶어서 넣어주면 된다.
        total_loss += loss
    print('Epoch {0}: {1}'.format(epoch+1, total_loss/n_samples))
```

    Epoch 1: 1656.550048828125
    Epoch 2: 957.05224609375
    Epoch 3: 845.3574829101562
    Epoch 4: 751.33642578125
    Epoch 5: 668.1957397460938
    Epoch 6: 594.6158447265625
    Epoch 7: 529.498779296875
    Epoch 8: 471.8717956542969
    Epoch 9: 420.87432861328125
    Epoch 10: 375.7457275390625
    Epoch 11: 335.8111877441406
    Epoch 12: 300.47357177734375
    Epoch 13: 269.2049865722656
    Epoch 14: 241.5377655029297
    Epoch 15: 217.05789184570312
    Epoch 16: 195.3992156982422
    Epoch 17: 176.23704528808594
    Epoch 18: 159.28453063964844
    Epoch 19: 144.2869415283203
    Epoch 20: 131.0201873779297
    Epoch 21: 119.28470611572266
    Epoch 22: 108.90458679199219
    Epoch 23: 99.72322845458984
    Epoch 24: 91.60327911376953
    Epoch 25: 84.4225845336914
    Epoch 26: 78.07245635986328
    Epoch 27: 72.45730590820312
    Epoch 28: 67.49275970458984
    Epoch 29: 63.103614807128906
    Epoch 30: 59.22303771972656
    Epoch 31: 55.793113708496094
    Epoch 32: 52.76158905029297
    Epoch 33: 50.08254623413086
    Epoch 34: 47.715213775634766
    Epoch 35: 45.623287200927734
    Epoch 36: 43.77528762817383
    Epoch 37: 42.142906188964844
    Epoch 38: 40.701255798339844
    Epoch 39: 39.42827224731445
    Epoch 40: 38.304073333740234
    Epoch 41: 37.31173324584961
    Epoch 42: 36.435970306396484
    Epoch 43: 35.66320037841797
    Epoch 44: 34.98141860961914
    Epoch 45: 34.38019561767578
    Epoch 46: 33.8498649597168
    Epoch 47: 33.38246536254883
    Epoch 48: 32.97057342529297
    Epoch 49: 32.60768508911133
    Epoch 50: 32.288116455078125
    Epoch 51: 32.00660705566406
    Epoch 52: 31.758989334106445
    Epoch 53: 31.54110336303711
    Epoch 54: 31.34950065612793
    Epoch 55: 31.181076049804688
    Epoch 56: 31.033130645751953
    Epoch 57: 30.903223037719727
    Epoch 58: 30.789226531982422
    Epoch 59: 30.689340591430664
    Epoch 60: 30.601768493652344
    Epoch 61: 30.525074005126953
    Epoch 62: 30.457931518554688
    Epoch 63: 30.399337768554688
    Epoch 64: 30.348064422607422
    Epoch 65: 30.30340003967285
    Epoch 66: 30.264480590820312
    Epoch 67: 30.23057746887207
    Epoch 68: 30.20111083984375
    Epoch 69: 30.175609588623047
    Epoch 70: 30.153446197509766
    Epoch 71: 30.134305953979492
    Epoch 72: 30.11781883239746
    Epoch 73: 30.10361671447754
    Epoch 74: 30.09145164489746
    Epoch 75: 30.081008911132812
    Epoch 76: 30.072124481201172
    Epoch 77: 30.06454086303711
    Epoch 78: 30.05818748474121
    Epoch 79: 30.05280303955078
    Epoch 80: 30.048303604125977
    Epoch 81: 30.044593811035156
    Epoch 82: 30.041576385498047
    Epoch 83: 30.0390682220459
    Epoch 84: 30.037050247192383
    Epoch 85: 30.035449981689453
    Epoch 86: 30.034282684326172
    Epoch 87: 30.033401489257812
    Epoch 88: 30.032764434814453
    Epoch 89: 30.03238868713379
    Epoch 90: 30.03215980529785
    Epoch 91: 30.03208351135254
    Epoch 92: 30.032203674316406
    Epoch 93: 30.03240394592285
    Epoch 94: 30.03264045715332
    Epoch 95: 30.03304100036621
    Epoch 96: 30.03343391418457
    Epoch 97: 30.033906936645508
    Epoch 98: 30.034433364868164
    Epoch 99: 30.034929275512695
    Epoch 100: 30.0355281829834
    


```python
# plot the results
plt.plot(data[:,0], data[:,1], 'bo', label='Real data')
plt.plot(data[:,0], data[:,0] * w.numpy() + b.numpy(), 'r', label='Predicted data')
plt.legend()
plt.show()
```


![129_0](https://user-images.githubusercontent.com/41605276/80910574-406b1c80-8d6b-11ea-9f6c-7fc5d7f1392d.png)


#### 6. 실제 데이터를 이용한 선형회귀 구현예시(미니배치를 적용해보자)


```python
#DATA_FILE = './data/birth_life_2010.txt'
DATA_FILE = '/content/gdrive/My Drive/TensorFlow_Training_13th/data/birth_life_2010.txt'
```


```python
def read_birth_life_data(filename):
    """
    Read in birth_life_2010.txt and return:
    data in the form of NumPy array
    n_samples: number of samples
    """
    text = open(filename, 'r').readlines()[1:]
    data = [line[:-1].split('\t') for line in text]
    births = [float(line[1]) for line in data]
    lifes = [float(line[2]) for line in data]
    data = list(zip(births, lifes))
    n_samples = len(data)
    data = np.asarray(data, dtype=np.float32)
    return data, n_samples
```


```python
data, n_samples = read_birth_life_data(DATA_FILE)
```


```python
w = tf.Variable(0.1, tf.float32)
b = tf.Variable(0., tf.float32)
```


```python
learning_rate = 0.01
optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)
```


```python
batch_size = 10
n_epoch = 100

total_steps = int(n_samples/batch_size)
for epoch in range(n_epoch):
    total_loss = 0.
    for i in range(total_steps):
        x = data[i*batch_size:(i+1)*batch_size, 0]
        y = data[i*batch_size:(i+1)*batch_size, 1]
        with tf.GradientTape() as tape:
            hypothesis = w * x + b
            loss = tf.reduce_mean(tf.square(hypothesis - y))
        grads = tape.gradient(loss, [w, b])
        optimizer.apply_gradients(grads_and_vars=zip(grads, [w, b]))
        total_loss += loss / total_steps
    print('Epoch {0}: {1}'.format(epoch+1, total_loss))
```

    Epoch 1: 265.4019470214844
    Epoch 2: 276.8383483886719
    Epoch 3: 248.3880157470703
    Epoch 4: 222.95660400390625
    Epoch 5: 200.50357055664062
    Epoch 6: 180.68170166015625
    Epoch 7: 163.18255615234375
    Epoch 8: 147.73382568359375
    Epoch 9: 134.09532165527344
    Epoch 10: 122.0547103881836
    Epoch 11: 111.42464447021484
    Epoch 12: 102.03982543945312
    Epoch 13: 93.75440216064453
    Epoch 14: 86.4394302368164
    Epoch 15: 79.98108673095703
    Epoch 16: 74.27924346923828
    Epoch 17: 69.24494934082031
    Epoch 18: 64.80011749267578
    Epoch 19: 60.87559509277344
    Epoch 20: 57.410587310791016
    Epoch 21: 54.35100173950195
    Epoch 22: 51.649654388427734
    Epoch 23: 49.26433181762695
    Epoch 24: 47.15803909301758
    Epoch 25: 45.29821014404297
    Epoch 26: 43.655887603759766
    Epoch 27: 42.20565414428711
    Epoch 28: 40.92494201660156
    Epoch 29: 39.793941497802734
    Epoch 30: 38.79512023925781
    Epoch 31: 37.912994384765625
    Epoch 32: 37.13389587402344
    Epoch 33: 36.4458122253418
    Epoch 34: 35.838050842285156
    Epoch 35: 35.30128479003906
    Epoch 36: 34.827083587646484
    Epoch 37: 34.40825271606445
    Epoch 38: 34.03824996948242
    Epoch 39: 33.711368560791016
    Epoch 40: 33.42259979248047
    Epoch 41: 33.167396545410156
    Epoch 42: 32.94196319580078
    Epoch 43: 32.74275588989258
    Epoch 44: 32.56673812866211
    Epoch 45: 32.4111328125
    Epoch 46: 32.273616790771484
    Epoch 47: 32.15208435058594
    Epoch 48: 32.044639587402344
    Epoch 49: 31.94965171813965
    Epoch 50: 31.865678787231445
    Epoch 51: 31.79144859313965
    Epoch 52: 31.725784301757812
    Epoch 53: 31.66773223876953
    Epoch 54: 31.616374969482422
    Epoch 55: 31.570955276489258
    Epoch 56: 31.53074836730957
    Epoch 57: 31.495176315307617
    Epoch 58: 31.463703155517578
    Epoch 59: 31.435819625854492
    Epoch 60: 31.411174774169922
    Epoch 61: 31.389333724975586
    Epoch 62: 31.36998176574707
    Epoch 63: 31.352853775024414
    Epoch 64: 31.33767318725586
    Epoch 65: 31.324214935302734
    Epoch 66: 31.312301635742188
    Epoch 67: 31.30173110961914
    Epoch 68: 31.292354583740234
    Epoch 69: 31.284040451049805
    Epoch 70: 31.27666664123535
    Epoch 71: 31.270109176635742
    Epoch 72: 31.264297485351562
    Epoch 73: 31.259143829345703
    Epoch 74: 31.254547119140625
    Epoch 75: 31.250469207763672
    Epoch 76: 31.24685287475586
    Epoch 77: 31.243614196777344
    Epoch 78: 31.24074935913086
    Epoch 79: 31.238170623779297
    Epoch 80: 31.23590660095215
    Epoch 81: 31.233884811401367
    Epoch 82: 31.23208236694336
    Epoch 83: 31.23044776916504
    Epoch 84: 31.22901153564453
    Epoch 85: 31.22772789001465
    Epoch 86: 31.226593017578125
    Epoch 87: 31.225549697875977
    Epoch 88: 31.22464370727539
    Epoch 89: 31.223812103271484
    Epoch 90: 31.223087310791016
    Epoch 91: 31.222410202026367
    Epoch 92: 31.221820831298828
    Epoch 93: 31.221288681030273
    Epoch 94: 31.220809936523438
    Epoch 95: 31.220378875732422
    Epoch 96: 31.219993591308594
    Epoch 97: 31.219640731811523
    Epoch 98: 31.219329833984375
    Epoch 99: 31.219045639038086
    Epoch 100: 31.21879005432129
    


```python
# plot the results
plt.plot(data[:,0], data[:,1], 'bo', label='Real data')
plt.plot(data[:,0], data[:,0] * w.numpy() + b.numpy(), 'r', label='Predicted data')
plt.legend()
plt.show()
```


![137_0](https://user-images.githubusercontent.com/41605276/80910582-4bbe4800-8d6b-11ea-8aa0-d5e2d8ca778a.png)


#### 7. 실제 데이터를 이용한 선형회귀 구현예시(미니배치를 적용해보자 + 텐서플로우의 유용한 매서드를 이용)


```python
batch_size = 10
n_epoch = 100
```


```python
#DATA_FILE = './data/birth_life_2010.txt'
DATA_FILE = '/content/gdrive/My Drive/TensorFlow_Training_13th/data/birth_life_2010.txt'
```


```python
def read_birth_life_data(filename):
    """
    Read in birth_life_2010.txt and return:
    data in the form of NumPy array
    n_samples: number of samples
    """
    text = open(filename, 'r').readlines()[1:]
    data = [line[:-1].split('\t') for line in text]
    births = [float(line[1]) for line in data]
    lifes = [float(line[2]) for line in data]
    data = list(zip(births, lifes))
    n_samples = len(data)
    data = np.asarray(data, dtype=np.float32)
    return data, n_samples
```


```python
data, n_samples = read_birth_life_data(DATA_FILE)
```


```python
dataset = tf.data.Dataset.from_tensor_slices((data[:,0], data[:,1]))
dataset = dataset.shuffle(1000).batch(10)
```


```python
w = tf.Variable(0.1, tf.float32)
b = tf.Variable(0., tf.float32)
```


```python
learning_rate = 0.01
optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)
```


```python
total_steps = int(n_samples/batch_size)
for epoch in range(n_epoch):
    total_loss = 0.
    for x, y in dataset:        
        with tf.GradientTape() as tape:
            hypothesis = w * x + b
            loss = tf.reduce_mean(tf.square(hypothesis - y))
        grads = tape.gradient(loss, [w, b])
        optimizer.apply_gradients(grads_and_vars=zip(grads, [w, b]))
        total_loss += loss / total_steps
    print('Epoch {0}: {1}'.format(epoch+1, total_loss))
```

    Epoch 1: 1742.0859375
    Epoch 2: 1126.128662109375
    Epoch 3: 979.6088256835938
    Epoch 4: 852.522216796875
    Epoch 5: 742.4463500976562
    Epoch 6: 647.1064453125
    Epoch 7: 564.5300903320312
    Epoch 8: 493.0089416503906
    Epoch 9: 431.0635986328125
    Epoch 10: 377.412109375
    Epoch 11: 330.9443054199219
    Epoch 12: 290.6987609863281
    Epoch 13: 255.8425750732422
    Epoch 14: 225.65428161621094
    Epoch 15: 199.5089874267578
    Epoch 16: 176.86538696289062
    Epoch 17: 157.25486755371094
    Epoch 18: 140.27125549316406
    Epoch 19: 125.56282806396484
    Epoch 20: 112.8250961303711
    Epoch 21: 101.79405212402344
    Epoch 22: 92.24114227294922
    Epoch 23: 83.96859741210938
    Epoch 24: 76.80487823486328
    Epoch 25: 70.60147094726562
    Epoch 26: 65.22976684570312
    Epoch 27: 60.57827377319336
    Epoch 28: 56.55058288574219
    Epoch 29: 53.06315612792969
    Epoch 30: 50.04361343383789
    Epoch 31: 47.42922592163086
    Epoch 32: 45.16574478149414
    Epoch 33: 43.20611572265625
    Epoch 34: 41.509586334228516
    Epoch 35: 40.04093551635742
    Epoch 36: 38.76959991455078
    Epoch 37: 37.66910171508789
    Epoch 38: 36.716522216796875
    Epoch 39: 35.89202117919922
    Epoch 40: 35.17844009399414
    Epoch 41: 34.5609245300293
    Epoch 42: 34.02655029296875
    Epoch 43: 33.564151763916016
    Epoch 44: 33.164058685302734
    Epoch 45: 32.817935943603516
    Epoch 46: 32.51848602294922
    Epoch 47: 32.25947570800781
    Epoch 48: 32.03544998168945
    Epoch 49: 31.841718673706055
    Epoch 50: 31.674179077148438
    Epoch 51: 31.529327392578125
    Epoch 52: 31.404138565063477
    Epoch 53: 31.295909881591797
    Epoch 54: 31.2023868560791
    Epoch 55: 31.1215877532959
    Epoch 56: 31.051780700683594
    Epoch 57: 30.99148178100586
    Epoch 58: 30.93941879272461
    Epoch 59: 30.89447784423828
    Epoch 60: 30.855690002441406
    Epoch 61: 30.822223663330078
    Epoch 62: 30.793354034423828
    Epoch 63: 30.768463134765625
    Epoch 64: 30.74700927734375
    Epoch 65: 30.72852897644043
    Epoch 66: 30.71260643005371
    Epoch 67: 30.69890022277832
    Epoch 68: 30.687114715576172
    Epoch 69: 30.676965713500977
    Epoch 70: 30.66825294494629
    Epoch 71: 30.660762786865234
    Epoch 72: 30.654346466064453
    Epoch 73: 30.64883041381836
    Epoch 74: 30.644105911254883
    Epoch 75: 30.640071868896484
    Epoch 76: 30.636619567871094
    Epoch 77: 30.633670806884766
    Epoch 78: 30.63115119934082
    Epoch 79: 30.62900161743164
    Epoch 80: 30.62717628479004
    Epoch 81: 30.625629425048828
    Epoch 82: 30.624313354492188
    Epoch 83: 30.62320899963379
    Epoch 84: 30.622264862060547
    Epoch 85: 30.621477127075195
    Epoch 86: 30.620819091796875
    Epoch 87: 30.620267868041992
    Epoch 88: 30.61981201171875
    Epoch 89: 30.619428634643555
    Epoch 90: 30.619117736816406
    Epoch 91: 30.618854522705078
    Epoch 92: 30.6186466217041
    Epoch 93: 30.61848258972168
    Epoch 94: 30.61834716796875
    Epoch 95: 30.61824607849121
    Epoch 96: 30.61817169189453
    Epoch 97: 30.618114471435547
    Epoch 98: 30.618070602416992
    Epoch 99: 30.618040084838867
    Epoch 100: 30.618026733398438
    


```python
# plot the results
plt.plot(data[:,0], data[:,1], 'bo', label='Real data')
plt.plot(data[:,0], data[:,0] * w.numpy() + b.numpy(), 'r', label='Predicted data')
plt.legend()
plt.show()
```


![147_0](https://user-images.githubusercontent.com/41605276/80910588-57117380-8d6b-11ea-86bc-d8c5c50b1bf9.png)


#### 8. 멀티레이어 퍼셉트론에서 멀티 클래스 처리

- 결론적으로 얘기하면 softmax를 쓰면 된다. 예를 들어 클래스가 개, 고양이, 사자, 호랑이 4개가 있다고 치자. 그러면 아래 왼쪽그림처럼 output을 낼때 각각의 노드에 시그모이드를 쓸 수 있다. 개일 확률, 고양이일 확률, 호랑이일확률 이런식으로 할 수 있다. 하지만 이론적으로 전부 1이 될 수도 있고, 전부 0이 될수도 있다는 문제가 발생한다. 보통 그래서 이런 경우에는 멀티 레이블 문제를 풀때 정도 사용하고, 보통은 소프트맥스를 쓰게 된다.


- 그래서 소프트맥스 함수는 각각의 z에다가 exp를 취한 다음에 전부 이를 더한 수를 각각의 z의 exp 취한 것으로 나누어주면 된다. 그러면 아래 그림의 빨간색 박스처럼 된다.


- 그러면 ajL을 다 더한게 1이 되기 때문에 확률처럼 보이게 된다.

![1](https://user-images.githubusercontent.com/41605276/80910113-4ca1aa80-8d68-11ea-82e0-721bc2405264.png)

- 멀티클래스의 분류를 할때는 소프트맥스를 마지막 레이어의 활성화 함수로 쓰게 된다. regression 할때는 보통 활성화 함수를 쓰지는 않는다. 가끔 시그모이드난 하이퍼볼릭 탄젠트를 쓰는 경우도 있는데 이 경우는 회귀를 하는데 회귀의 목표치가 0 ~ 1 인경우이다. 그리고 classification할때는 binary classification 할때는 보통 시그모이드를 쓰고, 그외에 멀티클래스면 소프트맥스를 쓰게 된다.


- 그러면 소프트맥스의 loss는 어떻게 계산하는가. 이때 loss function은 크로스엔트로피를 쓴다. 보통 분류문제에서는 크로스엔트로피를 쓴다고 보면된다. 크로스엔트로피는 바이너리 크로스엔트로피만 받는거 같은데 어떻게 멀티클래스를 처리하냐. 정답인 클래스와 정답이 아닌 나머지 클래스들 두덩어리로 나누어서 처리하면 된다.

![2](https://user-images.githubusercontent.com/41605276/80910114-53302200-8d68-11ea-819d-eed127637e3b.png)

- 그러면 예를 들어서 계산을 해보자. 2가지 모델이 있다고 치자 이 모델의 classification error는 둘다 33%다. 이때 크로스엔트로피와, squared loss에 따른 각각의 loss를 구해보자

![3](https://user-images.githubusercontent.com/41605276/80910119-588d6c80-8d68-11ea-8072-0154edd02d6b.png)

- 딱봐도 model2가 더 좋은 모델이다. model1은 아리까리한 확률로 class를 맞췄지만 model2는 상대적으로 model1보다 확실한 확률로 class를 맞췄기 때문이다. loss 값을 실제로 계산해도 model2가 더 loss가 적게 나온다. 


- MSE는 참고로 정답에서 멀어질 수록 학습속도가 떨어지는 문제가 있다.

#### 9. 활성화 함수

- 아래 그림과 같이 여러 활성화 함수가 있고, 이 외에도 더 있지만 통상 아래 있는 함수들이 가장 많이 쓰인다. 그리고 이중에서도 relu가 가장 많이 쓰이는 편이다. 내가 활성화 함수에 대해 잘 모르겠다 싶으면 랠루를 쓰는 것이 가장 무난하다.

![4](https://user-images.githubusercontent.com/41605276/80910127-62af6b00-8d68-11ea-9bc7-9604605d934c.png)

[시그모이드 함수]

- 특징 : 모든 입력값에 대해 0 ~ 1 사이의 값의 출력으로 변환해준다. 


- 문제점 :

1) Saturated neurons “kill” the gradients

그레디언트 소멸문제. 그레디언트가 0에 가까워지는 영역이 있는 문제


2) Sigmoid outputs are not zero centered

시그모이드 아웃풋이 음수가 안나오는 문제

시그모이드로 나오는 출력은 모두 양수이기 때문에 이 출력값이 다음 노드로 들어간다면 입력이 전부 역시 양수가 들어가게 된다. 특히 back propogation할때 input이 모두 positive일때 w에 대한 그레디언트가 모두 다 음수이거나 모두 다 양수이게 된다. 다시말해서 모든 w에 대해서 미분값이 전부다 양수이거나 전부다 음수이거나해서 최적화 시 아래 그림처럼 1사분면과 3사분면 방향으로 밖에 못가는 문제가 발생한다. 그래서 아래 그림처럼 zig zag path로 최적값을 찾게 되는데 아예 최적값을 못찾는것은 아니지만 속도가 느리다. 결론은 학습속도가 느리다는 것이다.

![5](https://user-images.githubusercontent.com/41605276/80910130-69d67900-8d68-11ea-8bf7-1be53d4dbfaa.png)

3) Exp () is a bit compute expensive

exp 연산이 있기 때문에 컴퓨터가 연산하는데 부담이 있다.(이런 문제점 때문에 지니불순도를 대신하여 사용하기도 한다.)

[하이퍼볼릭 탄젠트 함수]

![6](https://user-images.githubusercontent.com/41605276/80910136-6fcc5a00-8d68-11ea-8722-fcc98f181893.png)

- 기울기가 가장클때는 1이다. 그래서 그레디언트의 크기가 항상 1보다 작거나 같게 된다. 그래서 saturated 영역이 있어서 시그모이드 함수와 마찬가지로 그레디언트 소멸문제가 발생할 수 있다.

[랠루 함수]

![7](https://user-images.githubusercontent.com/41605276/80910137-7529a480-8d68-11ea-8326-1b8efea471c3.png)

- 그레디언트 계산하면 0 아니면 1이다. 그래서 0은 차피 그냥 날아가버릴것이고 forward 방향으로 갈때 연산이 안되고 사라져버리기 때문에 backword로 올때 그레디언트가 0이어도 문제가 되지 않는다.


- 문제점

1) Not zero centered output

2) An annoyance dead ReLU Slide

모든 레이어는 f(wx+b)로 쓸 수 있는데 예를들어 w를 초기값을 잘못줘서 아래 그림과 같이 빨간색 선으로 그어버리게 되면 dead 랠루에 빠져서 가중치 업데이트가 불가능하게 된다. 또는 learning rate를 잘못줘서 선을 빨간색 선처럼 그어버리게 되면 또 데드랠루에 빠져서 가중치 업데이트가 아예 불가능해진다. 초기값을 부여할때 그래서 트릭으로 바이어스값을 살짝 양수로 줘서 바이어스 만큼 약간 양수쪽으로 쉬프트되기 때문에 완전히 다 데드랠루에 빠지지 않는다고 한다.

![8](https://user-images.githubusercontent.com/41605276/80910146-7a86ef00-8d68-11ea-9212-269083f7cbec.png)

그래서 사람들이 랠루처럼 음수쪽을 전부 버리는 것이 올바른것이냐 생각하게 되었고 음수쪽에도 약간의 기울기를 주자는 아이디어가 나왔다. 

그래서 아래 그림과 같이 랠루의 단점을 보완한 함수들이 등장했다.

![9](https://user-images.githubusercontent.com/41605276/80910147-807cd000-8d68-11ea-8be9-f0956ceefacc.png)

- ELU에서 음수쪽에 살짝 꺽은 이유는 아웃라이어에 둔감하게 만들기 위해서다.

[maxout]

랠루와 위키랠루 이런 얘들의 정규화 버전이다.

![10](https://user-images.githubusercontent.com/41605276/80910150-87a3de00-8d68-11ea-89db-3fee8034feab.png)

#### 10. 데이터 전처리

- 이미지 데이터의 전처리

variance를 노멀라이징을 잘 안하는 편이다. 왜냐하면 픽셀값이 0 ~ 255로 보통 정해져 있기 때문이다.


그러면 min max 스케일링 같은거 할때는 어떻게 하냐. alexnet에서는 예를 들어서 이미지가 3만장이 있으면 3만장의 이미지에 대해 각각의 사진에 대한 픽셀값의 평균을 계산한다. 반면에 vgcnet에서는 채널별로 평균을 구해서 적용했다. 

#### 11. 가중치 초기화

모든 w에 대해 같은 값으로 초기화를 해주면 어떻게 될까. 예를 들어 모든 w값을 constant로 주게되면 얘네들이 똑같이 업데이트가 되어 학습이 거의 안된다고 보면 된다. 그래서 가중치를 줄때 w를 모두 랜덤하게해서 다르게 줘야한다.


그러면 네트워크를 딥하게 해도 학습이 잘 될 수 있도록 초기값을 어떻게 줘야 할까. 가장 기초적인 아이디어는 아래 그림과 같이 가우시안 노멀분포에서 랜덤하게 뽑아서 w에 할당해주는 것이다.

아래 그림의 예시는 가중치값에 대해서 하이퍼볼릭 탄젠트 함수를 통과한 레이어의 출력값(output값) 대한 분산을 보여주는 것이다. 

** 아래 그림에서 참고사항 = fan_in : 입력개수, fan_in : 출력개수

![11](https://user-images.githubusercontent.com/41605276/80910157-8d99bf00-8d68-11ea-90d8-831a6bf15bf5.png)

- 실제 가우시안 분포로 w값을 뽑는 것을 시뮬레이션하면 레이어가 깊어질 수록 평균이 0이고 표준편차도 0이 되버리는 문제가 발생한다. 입력으로 들어오는 값이 0의 근처의 값이 들어오고 거기에 w도 0에 가까운 값이 들어오게 되면 하이퍼볼릭탄젠트 함수는 0 근처에서 그냥 linear하게 통과시키기 때문에 점점 0으로 수렴하게 된다.


- 이런문제를 막아보고자 가중치를 키우는데 가우시안 노멀분포에서 0.01이 아니라 1을 곱해봤다. 그런데 분포를 보니까 양쪽 극단으로 쫙 퍼진 현상을 볼 수 있다. 왜냐하면 하이퍼볼릭 탄젠트 함수가 모든 입력에 대해서 -1 ~ 1 사이로 출력을 주니까 다 극단으로 가게 된다. 그래서 세츄에이션 영역으로 빠져버렸다 그리고 그레디언트가 0이 되어버리는 문제가 발생한다.

![12](https://user-images.githubusercontent.com/41605276/80910161-94283680-8d68-11ea-9770-aac61516a59c.png)

- 이런 문제 때문에 나온것이 하비에르 초기화 방법이다. 결과적으로 분포 모양을 보면 w값이 가우시안 정규분포를 이쁘게 이루고 있다. 이 가중치를 표준편차를 정해놓고 무작정 초기화 하는 것은 좋지 않은 방법이라고 판단하고, 퍼셉트론의 가지가 몇개 달려있는지 보고 그 표준편차를 정해야한다는 아이디어다.  그래서 in/out 의 variance 를 같게 해보자


- 그런데 하비에르 초기화 방법은 activation 함수를 linear한 함수라고 가정한 것이 문제다. 그러나 활성화 함수중에 non-linear한 함수가 대부분이다. 만약에 아래 그림처럼 랠루함수를 활성화 함수로 쓰는 경우에 하비에르 초기화 방법을 쓰게 되면 분산이 0으로 점점 줄어드는 문제가 발생한다.

![13](https://user-images.githubusercontent.com/41605276/80910166-9b4f4480-8d68-11ea-9d5a-07a7eb94176f.png)

- 그래서 Activation function 을 ReLU 나 PReLU를 쓰고도 in/out의 variance를 동일하게 해보자 해서 나온 것이 위의 그림과 같은  He 초기화 방법이다. 


#### 가중치 초기화 결론 

사실 가중치 초기화를 대충 막 해도 batch nomalization 때문에 학습이 잘 된다. 분포가 0이 되거나 쪼그라드는 문제가 있는데 매 레이어마다 정규화를 하면 이런 문제가 사라진다. 그래도 초기의 학습방향을 잘 잡기 위해 가중치 초기화를 잘 해야하는 것이다. 캐라스에서는 initializer API의 디폴트값으로 하비에르 initializer를 쓴다.


** batch nomalization : 매 레이어마다 정규화를 시켜주는 개념

#### 11. Learning Rate

- 러닝레이트도 하이퍼파라미터로 상당히 중요한 요소이다. 러닝레이트가 너무 크면 데드렐루에 빠질 수도 있고, 반면에 너무 작으면 학습이 잘 안될수도 있다.

![14](https://user-images.githubusercontent.com/41605276/80910167-a2765280-8d68-11ea-9779-83985e63480b.png)

- 이런 러닝레이트의 고민으로 나온 방법이 Leanring Rate Decay다. 

쉽게 말해서 학습되는 것을 모니터링 하다가 잘 학습이 안된다고 하면 러닝레이트를 탄력적으로 적용하는 것이다.

![15](https://user-images.githubusercontent.com/41605276/80910173-a86c3380-8d68-11ea-900a-96ff6a782ebb.png)

- cyclic learning rate 방법도 있다.

![16](https://user-images.githubusercontent.com/41605276/80910185-bc179a00-8d68-11ea-95bf-c3566dfdcf8f.png)

#### 12. 정규화방법

![17](https://user-images.githubusercontent.com/41605276/80910191-c33ea800-8d68-11ea-8ab5-f058de8e0c0e.png)

가로 축이 모델사이즈라고 보면 되는데 결론적으로 적절한 모델사이즈를 찾는 것이 중요하다.

내가 풀고자 하는 문제를 풀 수 있는 가장 작은 모델을 쓰는 것을 만드는 것이 가장좋다고 하는데 이는  참 애매한 개념이다. 하이퍼 파라미터 튜닝할것도 많은데 현실적으로 찾을 수 없다.

그래서 딥러닝에서는 모델을 일단 키우고 대신에 generalization gap을 최대한 줄이는 방법을 찾아보자는 방법을 일반적으로 쓴다.

그래서 많이 쓰는 정규화 방법중 하나가 early stopping이다. 아래 오른쪽 그림처럼 gap이 커지기 전에 멈추는 방법인데 어디서 멈춰야 할지 아는 것이 쉽지는 않다.

![18](https://user-images.githubusercontent.com/41605276/80910206-d487b480-8d68-11ea-9d94-a6eb56337a1e.png)

또 다른 방법으로 generalization gap을 직접적으로 줄여주는 것이 정규화방법이다. 

일반적인 loss function에 추가로 penalty term을 추가해서 이 penalty term이 커질수록 loss가 커지는 것처럼 효과를 주는 것을 말한다.

L2 방법은 모든 가중치값들을 제곱해서 더한다. L1 방법은 반면에 모든 가중치값들의 절대값을 취해서 더한다. elastic net 방법은 L1방법과 L2방법을 적절하게 조화시킨 방법이다.

그래서 핵심은 W값들이 너무 튀게 하지 않게 줄여줌으로써 함수의 일반화를 유도하는 것이다.

![19](https://user-images.githubusercontent.com/41605276/80910215-dfdae000-8d68-11ea-9a34-f414e41a93e0.png)

정규화를 할 수 있는 방법으로 Dropout 이라는 방법도 있다. 특정 노드에 대해서 동전을 던져서 이 노드를 살릴지 죽일지 결정하여 노드를 날리는 방법이다. 동전 던지기 확률은 사용자가 파라미터로 지정해줄 수 있다. 이렇게 임의의 노드를 날려서 과적합을 막을 수 있다.

트레인할때 노드를 드랍아웃으로 날리고 학습을 하고, 테스트 할때는 다시 전부 노드를 살려서 테스트를 하게 된다. 아래 그림과 같이 만약에 드랍아웃 확률이 0.5인 네트워크가 있다고 하자. training time에는 둘다 살아있는 경우, 둘다죽은경우, 하나만 사는 경우로 하면 1/4씩 해서 각각의 경우에 대한 기대값을 구한다. 그리고 test time에는 dropout 확률을 곱해서 원래 크기를 맞춰준다.

![20](https://user-images.githubusercontent.com/41605276/80910228-e701ee00-8d68-11ea-9acc-f149b7b22826.png)

정규화를 위한 또 다른 방법으로 Batch normalization이 있다. 이 방법이 가장 대중적으로 많이 쓰이는 방법이다. 

간단하게 말하면 배치 정규화는 학습 시의 미니배치를 한 단위로 정규화를 하는 것으로 분포의 평균이 0, 분산이 1이 되도록 정규화(nomalize)하는 것을 말한다.

먼저 Input으로 사용된 미니배치의 평균과 분산을 계산을 한다. 그 다음 hidden layer의 활성화값 및 출력값에 대해서 평균이 0, 분산이 1이 되도록 정규화를 한다(=변환). 그래서 데이터 분포가 덜 치우치게 되고 배치 정규화 단계마다 확대scale와 이동shift 변환을 수행한다.

데이터가 있으면 아래 그림과 같이 N이 batch size다. 이 랜덤으로 뽑힌 특정 batch size의 데이터에 대해서 첫번째 레이어에 들어가는 것을 mean zero라고 하고, 그 다음부터 들어가는 것은 batch가 한꺼번에 통과해서 출력이 batch 단위로 나올건데 그 batch 단위로 나오는 출력에 대해서 노멀라이즈를 하는 것이다. 그런데 이렇게 무작정 노멀라이즈를 하면 바이어스를 더해주는 의미가 없고, variance도 이렇게 정규화해서 1로 맞추는것도 가장 바람직한 방법은 아니다. 그래서 이 노멀라이즈 한 배치 출력값에 대해 감마를 곱하고 배타를 더해준다. 즉 w를 곱해주고 b를 다시 더해주는 셈이 된다. 이 감마와 베타도 학습을 하면서 최적의 값을 찾아나간다. 

이런 배치 노멀라이제이션을 해주면 그레디언트 플로우가 잘 흘러가는 장점이 있다. w값의 초기화를 대충해도 잘 학습이 된다. 또한 learning rate를 키워도 잘 학습이 된다고 알려져 있다. 왜냐하면 distribution이 잘 유지되기 때문이다. 또한 정규화 효과도 있다.

![21](https://user-images.githubusercontent.com/41605276/80910235-ecf7cf00-8d68-11ea-8464-8dc110a376e2.png)

이 배치노멀라이제이션도 트레인과 테스트를 다르게 해주는 것이 특징이다. 트레이닝할때 배치 단위로 평균과 분산을 구했는데, 테스트 타임에 배치단위의 데이터가 들어올거라는 보장이 없기 때문이다. 그러면 얘를들어서 나는 이미지 데이터를 가지고 뉴럴네트워크를 트레이닝할때 100장의 배치단위로 배치노멀라이제이션을 해줬는데 그러면 모델 서비스를 제공할때 사람들이 100장 이미지를 올릴때까지 기다려야 하냐. 이런 문제를 해결하기 위해서 트레이닝 할때 배치의 평균들의 평균을 계산해놨다가 이걸 테스트 타임에 한장이 들어와도 이 평균값을 이용해서 테스트를 할 수 있게 해준다. 다시말해서 트레이닝 타임에 학습할때 썼던 평균과 분산의 평균과 분산을 기록해두었다가 테스트 할때 써먹게 된다.

이 배치 노멀라이즈도 단점이 있는데 배치사이즈가 작으면 문제가 생길 수 있다. 왜그러냐면 아무래도 평균을 이용하기 때문에 노이즈에 취약할 수 있다. 샘플링의 양이 적을수록 variance가 엄청커지기 때문이다.

그 밖에 데이터를 어떻게 쪼개는지에 따라서 노멀라이즈 방법이 달라지게 된다.

또한 오버피팅을 잡는 가장 확실한 방법은 데이터의 양을 늘려주는 것인데 내가 갖고 있는 데이터를 살짝 변형해서 데이터의 수를 강제로 늘려주는 방법도 있을것이다. 이를 data augmentation이라고 한다.

![22](https://user-images.githubusercontent.com/41605276/80910239-f3864680-8d68-11ea-86b2-fca1b1d643f4.png)

#### 13. tensorflow를 이용한 logistic regression 구현실습 1

## Pima Indians Diabetes Dataset for Binary Classification

This dataset describes the medical records for Pima Indians and whether or not each patient will have an onset of diabetes within five years.

This dataset can be downloaded from https://www.kaggle.com/kumargh/pimaindiansdiabetescsv

이 dataset의 몇가지 주요 항목을 살펴보면 다음과 같습니다

- 인스턴스 수 : 768개
- 속성 수 : 8가지
- 클래스 수 : 2가지

8가지 속성(1번~8번)과 결과(9번)의 상세 내용은 다음과 같습니다.

1. 임신 횟수
2. 경구 포도당 내성 검사에서 2시간 동안의 혈장 포도당 농도
3. 이완기 혈압 (mm Hg)
4. 삼두근 피부 두겹 두께 (mm)
5. 2 시간 혈청 인슐린 (mu U/ml)
6. 체질량 지수
7. 당뇨 직계 가족력
8. 나이 (세)
9. 5년 이내 당뇨병이 발병 여부


```python
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
#from sklearn.preprocessing import MinMaxScaler

print(tf.__version__)
```

    2.0.0-beta1
    


```python
#tf.enable_eager_execution()
```


```python
#DATA_FILE = './data/pima-indians-diabetes.csv'
DATA_FILE = '/content/gdrive/My Drive/TensorFlow_Training_13th/data/pima-indians-diabetes.csv'
```


```python
xy = np.loadtxt(DATA_FILE, delimiter=',', dtype=np.float32)
x_train = xy[:, 0:-1]
y_train = xy[:, [-1]]
# 여기서 -1이라는 것은 맨 마지막 부터인것은 동일하나 대괄호가 들어가면 디멘전이 달라지게 된다.

print(x_train.shape, y_train.shape)
print(xy)
```

    (768, 8) (768, 1)
    [[  6.    148.     72.    ...   0.627  50.      1.   ]
     [  1.     85.     66.    ...   0.351  31.      0.   ]
     [  8.    183.     64.    ...   0.672  32.      1.   ]
     ...
     [  5.    121.     72.    ...   0.245  30.      0.   ]
     [  1.    126.     60.    ...   0.349  47.      1.   ]
     [  1.     93.     70.    ...   0.315  23.      0.   ]]
    


```python
# 피쳐들의 스케일이 다르면 가중치를 곱해져서 더할건데 이때 스케일이 큰숫자가 가장 영향력이 커지기 때문에
# 모든데이터에서 이 데이터들 중에 미니멈값을 뺀 숫자를 맥시멈에서 미니멈을 뺀 것을 나눠주게 된다.
# 통상 피쳐들을 0 ~ 1 사이의 값으로 노멀라이징하는 전처리를 해주게 된다.

def MinMaxScaler(data):
    ''' Min Max Normalization
    Parameters
    ----------
    data : numpy.ndarray
        input data to be normalized
        shape: [Batch size, dimension]
    Returns
    ----------
    data : numpy.ndarry
        normalized data
        shape: [Batch size, dimension]
    References
    ----------
    .. [1] http://sebastianraschka.com/Articles/2014_about_feature_scaling.html
    '''
    numerator = data - np.min(data, 0)
    denominator = np.max(data, 0) - np.min(data, 0)
    # noise term prevents the zero division
    return numerator / (denominator + 1e-7)
  
  # 여기서 10의 -7승이 왜 들어갔냐면 모든숫자가 다 같으면 맥시멈 - 미니멈이 0이 되기 때문에 그것을 방지하기 위함이다.
```


```python
x_train = MinMaxScaler(x_train)
x_train
```




    array([[0.3529412 , 0.74371856, 0.59016395, ..., 0.5007451 , 0.23441501,
            0.48333332],
           [0.05882353, 0.42713568, 0.5409836 , ..., 0.39642325, 0.11656704,
            0.16666667],
           [0.47058824, 0.919598  , 0.52459013, ..., 0.34724292, 0.25362936,
            0.18333334],
           ...,
           [0.29411766, 0.6080402 , 0.59016395, ..., 0.390462  , 0.07130657,
            0.15      ],
           [0.05882353, 0.63316584, 0.4918033 , ..., 0.44858423, 0.11571307,
            0.43333334],
           [0.05882353, 0.46733668, 0.57377046, ..., 0.45305514, 0.10119555,
            0.03333334]], dtype=float32)




```python
batch_size = x_train.shape[0]
n_epoch = 1000
learning_rate = 0.1
```


```python
dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(1000).batch(batch_size)
```


```python
w = tf.Variable(tf.random_normal_initializer()([8, 1]))
# 8행 1열 매트릭스가 되야지 길이가 8짜리 x가 들어오면 곱할 수 있기 때문이다.
# 그래서 8값에 입력의 길이를 보통 넣어주게 된다.

b = tf.Variable(tf.random_normal_initializer()([1]))
```


```python
def logistic_regression(inputs):
    hypothesis = tf.keras.activations.sigmoid(tf.matmul(inputs, w) + b)
    return hypothesis
```


```python
def loss_fn(inputs, labels):
    hypothesis = logistic_regression(inputs)
    loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(labels, hypothesis))
    return loss
```


```python
def grad(inputs, labels):
    hypothesis = logistic_regression(inputs)
    with tf.GradientTape() as tape:
        loss = loss_fn(inputs, labels)
    grads = tape.gradient(loss, [w, b])
    return grads
```


```python
def accuracy_fn(inputs, labels):
    hypothesis = logistic_regression(inputs)
    prediction = tf.cast(hypothesis > 0.5, dtype=tf.float32)
    # true는 1.0, false는 0.0을 리턴해줄 것이다.
    
    accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, labels), dtype=tf.float32))
    return accuracy
```


```python
optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)
```


```python
total_steps = int(x_train.shape[0]/batch_size)
for epoch in range(n_epoch):
    total_loss = 0.
    for x, y in dataset: 
        grads = grad(x, y)        
        optimizer.apply_gradients(grads_and_vars=zip(grads, [w, b]))
        loss = loss_fn(x, y)
        total_loss += loss / total_steps
    if (epoch+1) % 10 == 0:
        print('Epoch {0}: {1:.8f}'.format(epoch+1, total_loss))
```

    Epoch 10: 0.67067021
    Epoch 20: 0.66268939
    Epoch 30: 0.65868026
    Epoch 40: 0.65606815
    Epoch 50: 0.65396786
    Epoch 60: 0.65206867
    Epoch 70: 0.65026015
    Epoch 80: 0.64850199
    Epoch 90: 0.64677942
    Epoch 100: 0.64508677
    Epoch 110: 0.64342165
    Epoch 120: 0.64178276
    Epoch 130: 0.64016962
    Epoch 140: 0.63858140
    Epoch 150: 0.63701773
    Epoch 160: 0.63547802
    Epoch 170: 0.63396186
    Epoch 180: 0.63246888
    Epoch 190: 0.63099843
    Epoch 200: 0.62955028
    Epoch 210: 0.62812376
    Epoch 220: 0.62671870
    Epoch 230: 0.62533456
    Epoch 240: 0.62397087
    Epoch 250: 0.62262732
    Epoch 260: 0.62130350
    Epoch 270: 0.61999905
    Epoch 280: 0.61871356
    Epoch 290: 0.61744678
    Epoch 300: 0.61619812
    Epoch 310: 0.61496741
    Epoch 320: 0.61375433
    Epoch 330: 0.61255842
    Epoch 340: 0.61137944
    Epoch 350: 0.61021698
    Epoch 360: 0.60907078
    Epoch 370: 0.60794050
    Epoch 380: 0.60682589
    Epoch 390: 0.60572672
    Epoch 400: 0.60464257
    Epoch 410: 0.60357314
    Epoch 420: 0.60251826
    Epoch 430: 0.60147756
    Epoch 440: 0.60045081
    Epoch 450: 0.59943789
    Epoch 460: 0.59843826
    Epoch 470: 0.59745193
    Epoch 480: 0.59647858
    Epoch 490: 0.59551787
    Epoch 500: 0.59456968
    Epoch 510: 0.59363371
    Epoch 520: 0.59270978
    Epoch 530: 0.59179777
    Epoch 540: 0.59089726
    Epoch 550: 0.59000814
    Epoch 560: 0.58913022
    Epoch 570: 0.58826333
    Epoch 580: 0.58740717
    Epoch 590: 0.58656162
    Epoch 600: 0.58572656
    Epoch 610: 0.58490169
    Epoch 620: 0.58408684
    Epoch 630: 0.58328193
    Epoch 640: 0.58248663
    Epoch 650: 0.58170098
    Epoch 660: 0.58092457
    Epoch 670: 0.58015746
    Epoch 680: 0.57939935
    Epoch 690: 0.57865018
    Epoch 700: 0.57790965
    Epoch 710: 0.57717788
    Epoch 720: 0.57645446
    Epoch 730: 0.57573932
    Epoch 740: 0.57503241
    Epoch 750: 0.57433361
    Epoch 760: 0.57364255
    Epoch 770: 0.57295936
    Epoch 780: 0.57228380
    Epoch 790: 0.57161576
    Epoch 800: 0.57095510
    Epoch 810: 0.57030171
    Epoch 820: 0.56965548
    Epoch 830: 0.56901628
    Epoch 840: 0.56838399
    Epoch 850: 0.56775862
    Epoch 860: 0.56713992
    Epoch 870: 0.56652778
    Epoch 880: 0.56592220
    Epoch 890: 0.56532294
    Epoch 900: 0.56473005
    Epoch 910: 0.56414336
    Epoch 920: 0.56356275
    Epoch 930: 0.56298822
    Epoch 940: 0.56241953
    Epoch 950: 0.56185669
    Epoch 960: 0.56129956
    Epoch 970: 0.56074816
    Epoch 980: 0.56020230
    Epoch 990: 0.55966181
    Epoch 1000: 0.55912691
    


```python
print('Accuracy: {}'.format(accuracy_fn(x_train, y_train)))
```

    Accuracy: 0.7200520634651184
    

#### 14. tensorflow를 이용한 logistic regression 구현실습 2

## Importing Libraries


```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.utils import to_categorical
import numpy as np
import matplotlib.pyplot as plt
import os

print(tf.__version__)
print(keras.__version__)
```

    2.0.0-beta1
    2.2.4-tf
    

## Enable Eager Mode


```python
if tf.__version__ < '2.0.0':
    tf.enable_eager_execution()
```

## Hyper Parameters


```python
learning_rate = 0.001
training_epochs = 20
batch_size = 100
n_class = 10
```

## MNIST/Fashion MNIST Data


```python
## MNIST Dataset #########################################################
mnist = keras.datasets.mnist
class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']
##########################################################################

## Fashion MNIST Dataset #################################################
#mnist = keras.datasets.fashion_mnist
#class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
##########################################################################
```

## Datasets


```python
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()  
```

    Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
    11493376/11490434 [==============================] - 0s 0us/step
    


```python
type(train_images), type(train_labels)
```




    (numpy.ndarray, numpy.ndarray)




```python
train_images.shape, train_labels.shape
```




    ((60000, 28, 28), (60000,))




```python
test_images.shape, test_labels.shape
```




    ((10000, 28, 28), (10000,))




```python
n_train = train_images.shape[0]
n_test = test_images.shape[0]
```


```python
plt.figure()
plt.imshow(train_images[0], cmap=plt.cm.binary)
plt.colorbar()
```




    <matplotlib.colorbar.Colorbar at 0x7f15c638b1d0>




![227_1](https://user-images.githubusercontent.com/41605276/80910591-62649f00-8d6b-11ea-87d0-92f3e91043c9.png)



```python
plt.figure(figsize=(15,15))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]])
```


![228_0](https://user-images.githubusercontent.com/41605276/80910624-ae174880-8d6b-11ea-99e2-2051456d871b.png)



```python
train_images = train_images.astype(np.float32) / 255.
test_images = test_images.astype(np.float32) / 255.
    
train_labels = to_categorical(train_labels, n_class)
test_labels = to_categorical(test_labels, n_class)    
    
train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(
                buffer_size=100000).batch(batch_size)
test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(batch_size)
```

## Model Function


```python
def create_model():
    model = keras.Sequential()
    model.add(keras.layers.Flatten(input_shape=(28,28)))
    model.add(keras.layers.Dense(10, kernel_initializer=tf.keras.initializers.RandomNormal(),
                                activation='softmax'))    
    return model
```


```python
model = create_model()
model.summary()
```

    Model: "sequential"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    flatten (Flatten)            (None, 784)               0         
    _________________________________________________________________
    dense (Dense)                (None, 10)                7850      
    =================================================================
    Total params: 7,850
    Trainable params: 7,850
    Non-trainable params: 0
    _________________________________________________________________
    

## Loss Function




```python
def loss_fn(model, images, labels):
    predictions = model(images, training=True)
    loss = tf.reduce_mean(keras.losses.categorical_crossentropy(labels, predictions))   
    return loss
```

## Calculating Gradient & Updating Weights


```python
def train(model, images, labels):
    with tf.GradientTape() as tape:
        loss = loss_fn(model, images, labels)
    grads = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(grads, model.trainable_variables))
```

## Caculating Model's Accuracy


```python
def evaluate(model, images, labels):
    predictions = model(images, training=False)
    correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(labels, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))    
    return accuracy
```

## Optimizer


```python
optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
```

## Training


```python
# train my model
print('Learning started. It takes sometime.')
for epoch in range(training_epochs):
    avg_loss = 0.
    avg_train_acc = 0.
    avg_test_acc = 0.
    train_step = 0
    test_step = 0
    
    for images, labels in train_dataset:
        train(model,images, labels)
        loss = loss_fn(model, images, labels)
        acc = evaluate(model, images, labels)        
        avg_loss = avg_loss + loss
        avg_train_acc = avg_train_acc + acc
        train_step += 1
    avg_loss = avg_loss / train_step
    avg_train_acc = avg_train_acc / train_step
    
    for images, labels in test_dataset:        
        acc = evaluate(model, images, labels)        
        avg_test_acc = avg_test_acc + acc
        test_step += 1    
    avg_test_acc = avg_test_acc / test_step    

    print('Epoch:', '{}'.format(epoch + 1), 'loss =', '{:.8f}'.format(avg_loss), 
          'train accuracy = ', '{:.4f}'.format(avg_train_acc), 
          'test accuracy = ', '{:.4f}'.format(avg_test_acc))


print('Learning Finished!')
```

    Learning started. It takes sometime.
    

    WARNING: Logging before flag parsing goes to stderr.
    W0706 04:04:00.560467 139733226547072 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
    Instructions for updating:
    Use tf.where in 2.0, which has the same broadcast rule as np.where
    

    Epoch: 1 loss = 0.62537342 train accuracy =  0.8450 test accuracy =  0.9039
    Epoch: 2 loss = 0.34447038 train accuracy =  0.9061 test accuracy =  0.9140
    Epoch: 3 loss = 0.30790135 train accuracy =  0.9153 test accuracy =  0.9180
    Epoch: 4 loss = 0.29076752 train accuracy =  0.9192 test accuracy =  0.9222
    Epoch: 5 loss = 0.28040630 train accuracy =  0.9218 test accuracy =  0.9239
    Epoch: 6 loss = 0.27327609 train accuracy =  0.9237 test accuracy =  0.9250
    Epoch: 7 loss = 0.26795337 train accuracy =  0.9256 test accuracy =  0.9254
    Epoch: 8 loss = 0.26376852 train accuracy =  0.9266 test accuracy =  0.9252
    Epoch: 9 loss = 0.26036763 train accuracy =  0.9274 test accuracy =  0.9257
    Epoch: 10 loss = 0.25752684 train accuracy =  0.9283 test accuracy =  0.9261
    Epoch: 11 loss = 0.25509214 train accuracy =  0.9290 test accuracy =  0.9269
    Epoch: 12 loss = 0.25297555 train accuracy =  0.9298 test accuracy =  0.9274
    Epoch: 13 loss = 0.25111151 train accuracy =  0.9304 test accuracy =  0.9275
    Epoch: 14 loss = 0.24945579 train accuracy =  0.9311 test accuracy =  0.9274
    Epoch: 15 loss = 0.24797162 train accuracy =  0.9318 test accuracy =  0.9278
    Epoch: 16 loss = 0.24662957 train accuracy =  0.9323 test accuracy =  0.9277
    Epoch: 17 loss = 0.24539943 train accuracy =  0.9325 test accuracy =  0.9275
    Epoch: 18 loss = 0.24427384 train accuracy =  0.9329 test accuracy =  0.9273
    Epoch: 19 loss = 0.24323754 train accuracy =  0.9331 test accuracy =  0.9274
    Epoch: 20 loss = 0.24227658 train accuracy =  0.9334 test accuracy =  0.9273
    Learning Finished!
    


```python
def plot_image(i, predictions_array, true_label, img):
    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])

    plt.imshow(img,cmap=plt.cm.binary)

    predicted_label = np.argmax(predictions_array)
    if predicted_label == true_label:
        color = 'blue'
    else:
        color = 'red'

    plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                100*np.max(predictions_array),
                                class_names[true_label]),
                                color=color)

def plot_value_array(i, predictions_array, true_label):
    predictions_array, true_label = predictions_array[i], true_label[i]
    plt.grid(False)
    #plt.xticks([])
    plt.xticks(range(n_class), class_names, rotation=90)
    plt.yticks([])
    thisplot = plt.bar(range(n_class), predictions_array, color="#777777")
    plt.ylim([0, 1]) 
    predicted_label = np.argmax(predictions_array)
 
    thisplot[predicted_label].set_color('red')
    thisplot[true_label].set_color('blue')
```


```python
rnd_idx = np.random.randint(1, n_test//batch_size)
img_cnt = 0
for images, labels in test_dataset:
    img_cnt += 1
    if img_cnt != rnd_idx:
        continue
    predictions = model(images, training=False)
    num_rows = 5
    num_cols = 3
    num_images = num_rows*num_cols
    labels = tf.argmax(labels, axis=-1)
    plt.figure(figsize=(3*2*num_cols, 4*num_rows))
    plt.subplots_adjust(hspace=1.0)
    for i in range(num_images):
        plt.subplot(num_rows, 2*num_cols, 2*i+1)
        plot_image(i, predictions.numpy(), labels.numpy(), images.numpy())
        plt.subplot(num_rows, 2*num_cols, 2*i+2)
        plot_value_array(i, predictions.numpy(), labels.numpy())        
    break
```


![245_0](https://user-images.githubusercontent.com/41605276/80910627-ba9ba100-8d6b-11ea-98e4-f83628f8843e.png)


#### 15. 신경망 필기노트로 정리

#### 그림, 실습코드 등 학습자료 출처 : https://datascienceschool.net


#### 1) 신경망 개요

![1](https://user-images.githubusercontent.com/41605276/56879791-4150da80-6a95-11e9-8829-98c906dfc49b.jpg)

- 신경망은 크게봐서 basis function의 형태를 모수값으로 변화시킬 수 있는 함수모형이다. 그 이유는 비선형적인 데이터들을 처리하기 위함이다.


- 기존에 커널이나 basis function을 사용할때는 사람이 기저함수을 골라놓고 이것을 고정해서 쓰는데 신경망은 이 기저함수를 기계가 자동으로 바꿔주게 된다. 따라서 신경망을 adaptive basis function model이라고 부르기도 한다.


- 형태로는 퍼셉트론을 여러층으로 쌓아놓기 때문에 multi-layer perceptron이라고도 부른다.


- 우리가 알고 있는 퍼셉트론은 classification을 0 아니면 1 두개의 바이너리로 할 수 있는 판별함수 모형이다.


예를들어 x라는 이미지를 입력하게 되면 x라는 이미지와 w라는 가중치와 inner product해서 아래와 같이 들어오게 된다. inner product시 이미지에 1이라는 상수항을 미리 augmentation을 시켰으면 x와 w의 innerproduct로 끝났을텐데 신경망에서는 이 1을 나중에 계산상의 편의성을 위해 미리 augmentation을 시키지 않고 바깥쪽으로 빼버린다.

[신경망에서 쓰는 퍼셉트론의 형태]

x1 -> w1 -> 

x2 -> w2 ->  a = w.T+b   ->  z = h(a) -> y헷

x3 -> w3 ->


$$\ a = \sum_{i=1}^3 w_i x_i + b = w^T x + b $$

h는 활성화 함수(activation function)를 말한다.

#### 2) 시그모이드 활성화 함수

![2](https://user-images.githubusercontent.com/41605276/56879796-4877e880-6a95-11e9-8af4-ad54c7fbac87.jpg)

- 여기까지는 선형모형이고 위의 이 a라는 값을 어떤 비선형 함수에 통과시켜서 z값을 추출하게 된다. 핵심은 비선형 함수를 써야한다는 것이다. 비선형함수를 사용하지 않으면 신경망을 여러겹으로 쌓는 의미가 없다.


- 먼저 활성화 함수를 알아봐야 하는데 신경망은 보통 로지스틱함수를 많이 쓴다. 그 이유는 우리가 최적화를 하려면 미분값을 계산해야 하는데 로지스틱함수는 미분값을 계산할때 다음과 같이 쉽게 계산할 수 있기 때문이다. $$\ \dfrac{d\sigma(a)}{da} = \sigma(a)(1-\sigma(a)) = \sigma(a)\sigma(-a) $$

- 그리고 classification을 해야하기 때문에 $$\ \hat{y} = \text{sign}\left(z - \dfrac{1}{2}\right) = \text{round}(z) $$ 처럼 0.5를 기준으로 classification을 할 수 있다.

- 기존의 퍼셉트론은 헤비사이드 스텝함수를 이용해서 classification을 하였으나 미분이 안된다는 단점때문에 미분이 되는 로지스틱 함수를 이용하는 형태로 x 백터가 들어갔을때 y헷이 나오는 것을 신경망에서는 채택했다

#### 3) 비선형 기저함수

![3](https://user-images.githubusercontent.com/41605276/56879807-5299e700-6a95-11e9-8621-c85becaa6cef.jpg)

- 하지만 이렇게 하면 y헷은 어디까지나 직선형태가 된다는 문제가 있다. 이 직선형태가 되면 실제로 classification이 안되는 데이터들이 많다. 예를 들어 XOR문제 같은거..


- 그래서 우리는 basis function 방식을 쓸 수 있다. 이 방식이 뭐냐 원래는 x를 쓰는게 맞는데 비선형적인 함수형태를 통과시키자는 것이다. 전체적으로  $$\ a = w^T x + b $$ 형태를 쓰되 x대신에 x를 basis function $$\ \phi(x) $$에 통과시킨 것을 사용하자는 것이다.


- 따라서 아래와 같이 활성화 함수를 쓸 수 있다. $$\ z = h \left( \sum_{j=1}^J w_j \phi_j(x) + b \right) = h \left( w^T \phi(x) + b \right) $$ 여기서 J는 J개의 많은 기저함수를 사용한다는 의미에서 J인 것이다.


- 파이(x)는 다차원 함수이다. x백터가 들어가면 백터가 나오는 형태인데 들어갈때 차원과 나올때 차원은 다를 수 있다. 예를 들어 x백터가 3차원이었는데 100개의 파이가 있었다면 100차원 백터가 나온다는 것이다. 파이를 많이 생각해내면 생각해 낼 수록 좋다 왜냐하면 이 비선형 함수중에 하나는 데이터를 설명할 수 있기 떄문이다. 문제는 파이가 또 너무 많아지면 x간에 상관관계가 심해져서 오버피팅이 발생하거나 컨디션넘버가 높아지는 안좋은 현상이 발생한다.


- 그래서 가장 좋은것은 데이터의 비선형성에 딱맞는 적절한 개수의 파이만 있으면 좋은데 사람은 그것을 시각적으로 확인해서 조율할 수 있는 부분에서 한계가 있기 때문에 현실적으로는 그냥 무작정 많이 파이를 만들어보도록 기계한테 의존하는 것이다.

#### 4) 하이퍼 파라미터에 의해 모양이 바뀌는 비선형 기저 함수

![4](https://user-images.githubusercontent.com/41605276/56879821-5b8ab880-6a95-11e9-80e6-ae2a5c5c70de.jpg)

- 그래서 뭔가 이 파이자체도 모양을 바꿔서 이런저런 파이를 골라내고 싶다. 다시말해 기저함수를 여러개 써본다음에 그중에 좋은게 뭔지를 내가 찾고 싶다. 1차 2차 3차... 등의 함수를 써보고 싶다. 그렇게 하려면 모형자체를 바꾸는 하이퍼파라미터를 조절하면 된다. 좋은 파이를 찾는다는 것은 하이퍼파라미터 최적화를 한다는 의미이다.


- 이 파이에 모양을 바꿀 수 있는 하이퍼파라미터를 하나 생각을 한다. $$\ z = h \left( w^T \phi(x ; \theta) + b \right) $$ 그게 이 식에서 세타가 그것을 의미한다. 예를 들어서 x의 세타승이라고 하면 세타가 1일때는 1차함수, 세타가 2일때는 2차함수 이런방식이 되는 것이다. 그래서 이 세타를 할 수 있는 것을 다써보고 가장 좋은 것을 고르는 것이 하이퍼파라미터 최적화이다.


- 이 파이를 찾는데 어떤 방법이 좋을까 생각하다가 사람들이 발견한 것이 이 파이를 갖다가 뭔가 비선형 함수를 써야하는데 사람이 생각하기에 한계가 있으니까 퍼셉트론 자체에 활성화함수를 파이로 바로 활용해보자는 것이다. 


- $$\ z = h \left( \sum_{j=1}^M w_j h \left(w_{j}^{(1)} x + b_j^{(1)} \right)  + b \right) $$ 이런식으로..


- 위 식에서 w와 b를 바꿔주게 되면 원래 파이의 모양이 달라지게 되는 효과와 같다는 것이다. 다시말해 이 w와 b를 조절해주면 우리가 쓰는 파이라고 하는 basis function이 변한다는 것이다. 이런식으로 만들면 신경망을 구현할 수 있다.

- 정말로 이런식으로 하면 비선형 문제를 풀수 있는가에 대해 수학적으로 증명한 정리 Universal Approximation Theorem에서는 이 basis function(파이)을 무한히 많이 사용하면 어떠한 형태의 함수와도 유사한 형태의 함수 z(x) 를 만들 수 있다고 한다.파이를 몇개를 만들어야 한다고 단정하지는 않았다.


- 퍼셉트론은 하나만 썼을경우 linear한 문제밖에 못풀지만 그걸 여러개로 연결시켜서 네트워크를 만들게되면 XOR 같은 비선형문제도 풀 수 있다.


- 신경망에서는 Multi-classification을 할때 OvR 방식을 사용하기 위해 출력계층을 여러개 두는 경우도 있다. 통상 저렇게 여러개의 출력계층을 둘때는 출력계층에 소프트맥스 함수를 붙인다. 소프트맥스 함수는 들어가는 입력의 순서는 바뀌지 않으면서 모두 더했을때 합이 1이되게 하는 함수이다. 소프트맥스 함수를 쓰게되면 마치 확률인것처럼 보이게 된다. 실제 확률은 아니지만.. 어떤 카테고리 확률값으로 보이는 것이다.

#### 5) Multi-Layer Perceptrons

![5](https://user-images.githubusercontent.com/41605276/56879836-66454d80-6a95-11e9-84da-1aa828089c06.jpg)

#### 6) 신경망 가중치 표기법

![6](https://user-images.githubusercontent.com/41605276/56879841-6d6c5b80-6a95-11e9-8fe3-b84a88edbd2e.jpg)

- 신경망에서 가중치를 표기할때 주의해야할 점이 있다. $$\ w^{(l)}_{j,i} $$ 와 같이 표기해야 한다. l-1 번째 계층의 i번째 뉴런과 l번째 계층에서 j번째 뉴련을 연결하는 가중치라는 의미이다.


- 왜 이렇게 하느냐. 이렇게 뒤집어서 하게 되면 우리가 알고 있는 행렬의 원소기호 쓰는 방식으로 w를 묶어서 메트릭스를 만들 수 있다. 그리고 여기서 뒤쪽으로 넘어와서 y값 계산하는 과정을 메트릭스하고 벡터의 곱으로 표현할 수 있다. 아직까지는 활성화 함수를 통과한 상태는 아닌것이다.

#### 7) feedforward propagation(순방향 전파)

![7](https://user-images.githubusercontent.com/41605276/56879852-752c0000-6a95-11e9-953d-db1a01407a55.jpg)

- l−1 번째 계층의 출력과  l 번째 계층의 출력은 다음과 같은 관계가 있다. $$\ a^{(l)} = {W^{(l)}} z^{(l-1)} + b^{(l)} $$, $$\ z^{(l)} = h\left({W^{(l)}} z^{(l-1)} + b^{(l)}\right) $$, $$\ z^{(0)} = x $$, $$\ \hat{y} = z^{(L)} $$


- 그래서 앞단에서 출력한 z값과 그 중간을 연결하는 네트워크들(w) 곱한다음에 b값을 더해주면 신경망 내부에 있는 활성화 함수 값이 된다. 근데 얘는 출력은 아니다. 출력이 되려면 h 활성화 함수를 통과해야 한다.


- 다시정리하면 앞단에서 z가 나오게 되면 걔를 w와 곱하고 b를 더해서 활성화 함수값 구하고 그값을 활성화 함수를 통과시키고 나면 이 단의 출력이 된다. 앞단에서 뒷단까지 순차적으로 계층마다 이 과정을 반복하면 된다.


- 위와 같은 과정을 feedforward propagation(순방향 전파)라고 한다.

#### 8) 오차함수와 가중치 최적화

![8](https://user-images.githubusercontent.com/41605276/56879866-7fe69500-6a95-11e9-827f-0edad3d64a44.jpg)

- 퍼셉트론에서는 w의 값을 잘 조절하면 classification을 잘 할수 있다는 것이 핵심이었다. 신경망에서도 마찬가지로 w와 b를 잘 찾으면 classification을 잘 할 수 있다.


- 그런데 신경망에서는 이 w와 b를 찾는데에도 성능을 높이기 위해 파이라는 기저함수로 쓰게되었다. 


- 과거에는 w값을 좋은것을 찾아서 고정을 시키고, 파이는 그리드서치를 통해 최적화를 시켰었으나 너무 번거로우니 그냥 w와 파이를 한방에 찾을 수 있는 방법이 없을까 수학자들이 고민하였다.


- 다시말해 하이퍼파라미터 튜닝, 기저함수 찾는 과정, 모델 fitting과정 이 세개를 한방에 처리하자는 것이다.


- 목적함수는 예를 들어서 사진을 넣었을때 개면 1, 개가 아니면 0으로 출력되도록 말이다.


- 그렇게 하려면 트레이닝용 데이터는 있어야 한다. 그래서 목적함수를 어떻게 잡을 것인가. 다음과 같은 오차함수 수식을 이용한다. $$\ \begin{eqnarray}  C(w,b) = \sum_{i=1}^N C_i(w,b) =  \sum_{i=1}^N \| y_i - z_i^{(L)}(w,b) \|^2 
\end{eqnarray} $$


- 이 때  N 은 트레이닝 데이터의 갯수이다. 로지스틱 활성 함수를 이용한 분류 문제를 풀 때는 정답  y 가 클래스  k 에 속하는 데이터에 대해  k 번째 값만 1이고 나머지는 0인 원핫인코딩(one-hot-encoding) 벡터이다.


- 예를들어서 이미지가 여러장 있으면 이 이미지를 하나씩 넣게 된다. 사진을 넣으면 y헷이 나오게 되면 이게 개사진이 맞는 정답이면 1이어야 하고 아니면 0으로 나와야 한다.


- 위의 식처럼 유클리디안 거리를 이용해서 모든 이미지에 대해 실제 정답과 y헷값이 가능하면 가장 최소화하는 w와 b값을 찾으면 된다. 여기서 말하는 w와 b는 전처리 부분에 들어가는 w와 실제퍼셉드론에 들어가는 b를 원샷에 찾겠다는 것이다.


- 우리가 알고 있듯이 중간에 활성화 함수들이 막 끼워져 있다. 그래서 상당히 찾는 과정이 복잡해진다. 결론적으로 그레디언트 백터를 찾아서 조금씩 더 좋은 값으로 전진하는 방법을 채택해야한다. 신경망에서도 이 방법을 쓰면 된다.


- 수식으로 표현하면 다음과 같다. $$\ \begin{eqnarray}
  w_{k+1}  &=& w_{k} - \mu \frac{\partial C}{\partial w} \\
  b_{k+1} &=& b_{k} - \mu \frac{\partial C}{\partial b}
\end{eqnarray} $$ 이고 여기서 뮤는 최적화 스텝사이즈를 말한다.

#### 9) back propagation

![9](https://user-images.githubusercontent.com/41605276/56879877-8a089380-6a95-11e9-943d-860431e64e31.jpg)

- 만약에 입력계층이 784개이고 은닉계층이 15개 출력계층이 10개인 경우 w와 b는 몇개를 찾아야 하나. w는 앞단에 11760개 + 뒷단에 150개를 찾으면 된다. b는 앞단에 15개 + 뒷단에 10개 이다. 우리가 찾아야할 파라미터의 수는 11935개가 되는 것이다.


- 이말은 약 12000차원에서 최적화를 실시한다는 의미이고 그레디언트 백터는 약 12000개를 찾아야 한다는 것이다. 또한 미분을 12000번하면 된다는 의미이다.


- 문제는 C를 구하려면 사진을 한장씩 집어넣으면서 y헷이 얼마나 나오는지 보고 걔와 y를 빼서 애러값을 구해서 더하고 이러는 과정을 사진갯수만큼 해줘야한다.


- 데이터수가 커지면 감당이 안된다.. 너무 계산양이 커지게 되므로 그레디언트 백터를 구할때 효율적으로 하기 위해서 back propagation(역전파)라는 방법을 수학자들이 생각했다.


- 역전파 방법은 위의 수치적 미분을 하는것 보다는 훨씬 계산양이 줄어들게 된다.


- 먼저 델타를 뒤에서 앞으로 전파한다. 델타는 c를 a로 미분한 것이며 다음과 같다. $$\ \delta_j^{(l)} = \dfrac{\partial C}{\partial a_j^{(l)}} $$


- 그런데 a라는 것은 노드마다 하나씩 존재하게 된다. a의 갯수는 즉 노드의 개수가 된다. 아까는 a가 아니라 네트워크 엣지 w를 구해야하는 것인데 그것에 비해서는 상당히 줄어든 개수기 때문에 일단 a를 먼저 구하겠다는 것이다.


- 사실상 그래서 델타는 노드 하나마다 붙어있게 된다. 


- 그리고 델타를 계산할 수 있는 수식을 수학자들이 찾았는데 그 수식은 다음과 같다.
$$\ \begin{eqnarray} \delta^{(l-1)}_j = h'(a^{(l-1)}_j) \sum_{i=1}^{N_{(l)}} w^{(l)}_{ij} \delta^{(l)}_i
\end{eqnarray} $$

위식에서 N(l)은 l번째 레이어의 노드의 갯수를 말한다.


그리고 여기서 h프라임은 미분에서 만든 도함수를 의미한다. 활성화함수가 아니다. 그니까 aj l-1을 activation 함수를 미분해서 만든 도함수에 집어넣으면 무슨 숫자가 하나 나올것이다(h프라임함수의 출력은 기울기 상수가 나옴.스칼라다).


- 델타값l-1을 구하는데 델타 l을 이용하게 된다. 이게 무슨말이냐면 뒷단에 있는 델타를 이용해 앞단에 있는 델타를 구한다는 것이다.


- 그래서 해당 단에서 모든 j에 대해 기호로 쓸 경우에는 다음과 같은 식을 쓴다. 다시말해 위의 식을 벡터와 행렬의 식으로 쓰면 다음과 같다. $$\ \delta^{(l-1)} = h'(a^{(l-1)}) \odot ({W^T}^{(l)} \delta^{(l)}) $$ 여기서 $$\ \odot $$ 기호는 Hadamard Product, Schur product, 혹은 element-wise product 라고 하는데 예를들어 다음과 같다.


- $$\ x \odot y = 
\left(\begin{array}{c} x_1 \\ x_2 \\ x_3 \end{array}\right) \odot
\left(\begin{array}{c} y_1 \\ y_2 \\ y_3 \end{array}\right) 
= \left(\begin{array}{c} x_1 y_1 \\ x_2 y_2 \\ x_3 y_3 \end{array}\right) $$


- 이런식으로 back propogation을 하면 되는데 시작하는 지점은 y와 y헷의 차이, 즉 잔차를 쓰면 된다. 잔차가 마지막 부분의 델타다. 수식으로는 $$\ \delta^{(L)}_j = y_j - z_j $$와 같다.


- 여기까지하면 델타를 구하게 되는 것이고 우리의 원래 목적은 w와 b에 대한 미분값을 구해야하는 것이므로 그것은 다음과 같이 해주면 된다.


- 오차값에서 가중치에 대한 미분은 다음과 같이 구한다. 앞단에 있는 z와 뒷단에 있는 델타를 곱하면 된다. $$\ \frac{\partial C}{\partial w^{(l)}_{ji}} = \delta^{(l)}_j z^{(l-1)}_i $$ 요고를 앞단으로 계속 전파해주면 된다. 


- 또한 바이어스에 대한 미분값은 다음과 같은데 공교롭게도 그냥 델타 자체다.

b라는건 노드하나마다 b라는 값이 있고, b라는 얘의 미분값도 노드마다 달려있는데 그게 그냥 델타 자체라는 것이다.

$$\ \frac{\partial C}{\partial b^{(l)}_{j}} = \delta^{(l)}_j $$

![10](https://user-images.githubusercontent.com/41605276/56879884-955bbf00-6a95-11e9-8d90-27346565d0c5.jpg)

![11](https://user-images.githubusercontent.com/41605276/56879893-9c82cd00-6a95-11e9-8a4e-ea39c845321d.jpg)

#### 10) back propagation 의 증명

참고로 l번째 layer의 a값은 l+1번째 layer에 대한 어떤 함수라는 것이 성립한다.

l+1 단의 벡터를 집어넣으면 l번째 단의 a가 나오는 z의 역함수가 존재한다. 

왜냐하면 a하고 z를 연결해주는 것이 시그모이드 함수인데 이 시그모이드 함수의 역함수가 존재하기 때문이다.

![12](https://user-images.githubusercontent.com/41605276/56879901-a5739e80-6a95-11e9-9e83-323e2c7f2a69.jpg)

#### 11) Stochastic Gradient Descent

![13](https://user-images.githubusercontent.com/41605276/56879906-ad334300-6a95-11e9-8097-b7f69729b8d8.jpg)


- 이렇게해서 w값을 피팅할 수는 있는데 여전히 계산량은 많다. 왜냐하면 먼저 C에 대한 미분값을 찾아야 하는데 C라는게 이미지 한장한장 넣었을때 오차의 합이고 이걸 w로 미분한다는 것은 한장한장에 대한 오차의 미분의 합이라는 것이다.


- 이는 전체 오차를 구한것이 아니고 사진한장에 대한 오차를 구하는 것인데 이것을 이미지 갯수만큼 실시하고 델타를 모두 더하는게 전체 오차에 대한 델타가 되는 것이다.


- back propagation을 10만장의 이미지라면 10만번 100만장이면 100만번 해야하는데 꼭 이렇게 무식하게 반복을 해야하냐라는 것에서 나온 아이디어가 Stochastic Gradient Descent 방법이다. 


- 데이터의 특성이 10만개가 갖고 있는 특성이나 이중에 100개를 뽑았을때 데이터 특성이나 크게 다르지 않다는 것이다. 그렇기 때문에 굳이 10만개를 다 안써도 된다는 것이다.


- 다시말해 일부데이터만 이용해서 그레디언트 백터를 계산하는 것이다. 


- 데이터를 10만개 전부 다쓰게 되면 목적함수의 값이 반드시 줄어드는 형태로 나오지만 SGD는 줄어들기도하고 늘어나기도 하는 형태로 왔다갔다하게 된다. 그러나 특이한건 수렴속도는 두개가 비슷하다는 점이다.


- 따라서 계산량이 너무 많다보니까 줄여서 해보자는 방법이 현실적으로 많이 쓰인다.


- 그렇다면 또 문제가 되는 것이 전체 데이터중에 n개만 뽑아서 써야 하는데 어떤것을 빼서 써야하냐 주사위를 써서 랜덤 초이스를 해야하냐. 이 랜덤 초이스 자체도 연산이기 때문에 부담스럽다.


- 현실적으로는 그래서 데이터가 10만개 있으면 맨앞에 데이터 n개만써서 그레디언트를 업데이트 한다.


- 그 다음에는 n개 이후에 데이터를 쓰게 된데 새로운 데이터를 써보기 위해서. 그래서 또 그레디언트를 업데이트 해준다.


- 이렇게 데이터를 부분적으로 잘라서 그레디언트를 업데이트를 계속해주게 된다.

$$\ \dfrac{\partial C}{\partial w_k} = \sum_{i=1}^N \dfrac{\partial C_i}{\partial w_k} $$, $$\ w_{k+1} = w_k - \mu \dfrac{\partial C}{\partial w_k} $$


- 실제로 w는 미니배치사이즈 만큼 사용해서 업데이트해주고 미니배치를 데이터개수만큼 다 쓸 경우를 1 에포크라고 한다.


- 정리하면 신경망의 계수는 다음과 같이 찾으면 된다.(신경망 fitting하기)

맨첨에 w와 b값을 임의로 집어넣어넣는다. 그다음에 이미지 한장을 입력하게되면 임의로 집어넣은 w와 b값을 이용해서 feedforward propagation을 하게되고 a와 z값을 계산하게 된다. 최종출력계층의 z와 실제 y간의 오차를 계산해서 다시 back propagation을 해주게 된다. 그러면 델타가 나오게 되는데 델타와 z값을 곱해서 그레디언트 값을 계산을 한다. 그러면 이게 그레디언트 한번 계산된것이다. 이것을 이미지 개수만큼 반복해야 하지만 계산량이 워낙 많기 때문에 minibatch-size 만큼만 이미지를 뽑아서 iteration을 해주면 된다. 그래서 생긴 그레디언트들를 모두 평균낸다. 그 만큼 또 w와 b를 갱신해준다. 그 다음에 미니배치 사이즈만큼 또 이터레이션해주어 그레디언트 값을 업데이트해주고 그 그레디언트를 이용해서 w와 b를 반복한다.


#### # [요약정리]


- 신경망모형은 `기저함수`도 모수값에 의해 변화할 수 있는 적응형 기저함수모형이며 구조적으로는 여러개의 퍼셉트론 레이어를 쌓아놓은 형태이므로 `MLP(Multi-layer perceptron)`으로도 불린다.


- 신경망에 속한 퍼셉트론은 `neuron, node`라고 불린다. 각 계층은 다음 계층에 대해 적응형 기저함수의 역할을 한다. 최초의 계층은 입력계층, 마지막 계층은 출력계층, 중간은 은닉계층이라고 한다.


### # 신경망 계수탐색 프로세스

#### 1) initialize

모든 w,b 값을 임의의 값으로 초기화

#### 2) input

하나의 표본데이터 $$\ x_i $$로 입력 계층 설정

#### 3) feedforward propagation

모든 뉴런에 대해 a, z값 계산

#### 4) output and error calculation

최종출력계층의 값 $$\ z^{(L)} $$ 및 오차 $$\ \delta^{(L)} $$계산

#### 5) back propagation

반대방향으로 오차 $$\ \delta $$ 전파 

#### 6) gradient calculation

표본데이터 $$\ x_i $$에 의한 오차함수의 미분값(그레디언트) $$\ \frac{\partial C_i}{\partial w}=z \, \delta $$, $$\ \frac{\partial C_i}{\partial b}=\delta $$ 계산

#### 7) minibatch-size iteration

표본데이터를 $\ x_{i+1} $로 바꾸어 미니배치크기 만큼 2) ~ 6) 단계를 반복

#### 8) weight update

미니배치크기 만큼의 데이터를 사용한 후 그레디언트 $$\ \frac{\partial C}{\partial w} $$, $$\ \frac{\partial C}{\partial b} $$ 계산

이 그레디언트 값으로 w, b값을 업데이트


- 단순하게 수치적으로 미분을 계산한다면 모든 가중치에 대해서 개별적으로 미분을 계산해야 한다. 그러나 `Back propagation`방법을 사용하면 모든 가중치에 대한 미분값을 한번에 계산할 수 있다.


### # 신경망 성능 개선방법

- 크로스 엔트로피 형태의 오차함수를 사용하면 출력 레이어에서 활성화 함수의 도함수에 의한 영향을 제거 할 수 있다.

크로스 엔트로피 형태의 오차함수 : 

$$\ \begin{eqnarray} 
  C = y \log z^{(L)} + (1-y) \log (1-z^{(L)})
\end{eqnarray} $$

- 활성화 함수로 로지스틱 함수 대신 하이퍼탄젠트를 사용하면 도함수의 최댓값이 로지스틱 함수의 4배인 1이 되므로 그레디언트 감소현상이 줄어든다.

하이퍼탄젠트 : 

$$\ \begin{eqnarray}
  \tanh(a) \equiv \frac{e^a-e^{-a}}{e^a+e^{-a}} = 2\sigma(2a) - 1
\end{eqnarray} $$

`** 아래 두개는 가장많이 쓰는 방법으로 알려져 있다.`

- ReLu 활성화함수를 사용하는 것이다. 렐루는 가중치 총합 a가 큰 경우에도 기울기(그레디언트)가 1로 유지되므로 a가 커도 그레디언트 감소현상이 발생하지 않는다. CNN과 같이 레이어의 수가 많은 경우에 유용하다.


- dropout 정규화 방법은 이러한 문제를 해결하기 위해 에포크 마다 임의의 은닉계층 뉴런의 p%(보통 절반) dropout하여 최적화 과정에 포함하지 않는 방법이다.


### # 자주 사용하는 신경망 최적화 방법(그레디언트에 변형을 주는 방법)

** 기본 그레디언트 방법 : $$\ w_{k+1} = w_k - \mu_k g(w_k) = w_k - v_k $$

#### 1. decay 방법 : step size를 줄여 oscillation 현상을 회피

$$\ \mu_{k+1} = \mu_{k} \dfrac{1}{1 + \text{decay}} $$

#### 2. momentum 방법 : 진행하던 방향으로 계속 진행하게하여 최적화를 빠르게 수행

$$\ v_{k+1} = \text{momentum} \cdot v_k - \mu_k g(w_k) $$
