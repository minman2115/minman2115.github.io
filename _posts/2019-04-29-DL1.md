---
layout: post
title: "Neural network 기초개념"
tags: [딥러닝]
comments: true
---

.

#### 그림, 실습코드 등 학습자료 출처 : https://datascienceschool.net


#### 1. 신경망 개요

![1](https://user-images.githubusercontent.com/41605276/56879791-4150da80-6a95-11e9-8829-98c906dfc49b.jpg)

- 신경망은 크게봐서 basis function의 형태를 모수값으로 변화시킬 수 있는 함수모형이다. 그 이유는 비선형적인 데이터들을 처리하기 위함이다.


- 기존에 커널이나 basis function을 사용할때는 사람이 기저함수을 골라놓고 이것을 고정해서 쓰는데 신경망은 이 기저함수를 기계가 자동으로 바꿔주게 된다. 따라서 신경망을 adaptive basis function model이라고 부르기도 한다.


- 형태로는 퍼셉트론을 여러층으로 쌓아놓기 때문에 multi-layer perceptron이라고도 부른다.


- 우리가 알고 있는 퍼셉트론은 classification을 0 아니면 1 두개의 바이너리로 할 수 있는 판별함수 모형이다.


예를들어 x라는 이미지를 입력하게 되면 x라는 이미지와 w라는 가중치와 inner product해서 아래와 같이 들어오게 된다. inner product시 이미지에 1이라는 상수항을 미리 augmentation을 시켰으면 x와 w의 innerproduct로 끝났을텐데 신경망에서는 이 1을 나중에 계산상의 편의성을 위해 미리 augmentation을 시키지 않고 바깥쪽으로 빼버린다.

[신경망에서 쓰는 퍼셉트론의 형태]

x1 -> w1 -> 

x2 -> w2 ->  a = w.T+b   ->  z = h(a) -> y헷

x3 -> w3 ->


$$\ a = \sum_{i=1}^3 w_i x_i + b = w^T x + b $$

h는 활성화 함수(activation function)를 말한다.

#### 2. 시그모이드 활성화 함수

![2](https://user-images.githubusercontent.com/41605276/56879796-4877e880-6a95-11e9-8af4-ad54c7fbac87.jpg)

- 여기까지는 선형모형이고 위의 이 a라는 값을 어떤 비선형 함수에 통과시켜서 z값을 추출하게 된다. 핵심은 비선형 함수를 써야한다는 것이다. 비선형함수를 사용하지 않으면 신경망을 여러겹으로 쌓는 의미가 없다.


- 먼저 활성화 함수를 알아봐야 하는데 신경망은 보통 로지스틱함수를 많이 쓴다. 그 이유는 우리가 최적화를 하려면 미분값을 계산해야 하는데 로지스틱함수는 미분값을 계산할때 다음과 같이 쉽게 계산할 수 있기 때문이다. $$\ \dfrac{d\sigma(a)}{da} = \sigma(a)(1-\sigma(a)) = \sigma(a)\sigma(-a) $$

- 그리고 classification을 해야하기 때문에 $$\ \hat{y} = \text{sign}\left(z - \dfrac{1}{2}\right) = \text{round}(z) $$ 처럼 0.5를 기준으로 classification을 할 수 있다.

- 기존의 퍼셉트론은 헤비사이드 스텝함수를 이용해서 classification을 하였으나 미분이 안된다는 단점때문에 미분이 되는 로지스틱 함수를 이용하는 형태로 x 백터가 들어갔을때 y헷이 나오는 것을 신경망에서는 채택했다

#### 3. 비선형 기저함수

![3](https://user-images.githubusercontent.com/41605276/56879807-5299e700-6a95-11e9-8621-c85becaa6cef.jpg)

- 하지만 이렇게 하면 y헷은 어디까지나 직선형태가 된다는 문제가 있다. 이 직선형태가 되면 실제로 classification이 안되는 데이터들이 많다. 예를 들어 XOR문제 같은거..


- 그래서 우리는 basis function 방식을 쓸 수 있다. 이 방식이 뭐냐 원래는 x를 쓰는게 맞는데 비선형적인 함수형태를 통과시키자는 것이다. 전체적으로  $$\ a = w^T x + b $$ 형태를 쓰되 x대신에 x를 basis function $$\ \phi(x) $$에 통과시킨 것을 사용하자는 것이다.


- 따라서 아래와 같이 활성화 함수를 쓸 수 있다. $$\ z = h \left( \sum_{j=1}^J w_j \phi_j(x) + b \right) = h \left( w^T \phi(x) + b \right) $$ 여기서 J는 J개의 많은 기저함수를 사용한다는 의미에서 J인 것이다.


- 파이(x)는 다차원 함수이다. x백터가 들어가면 백터가 나오는 형태인데 들어갈때 차원과 나올때 차원은 다를 수 있다. 예를 들어 x백터가 3차원이었는데 100개의 파이가 있었다면 100차원 백터가 나온다는 것이다. 파이를 많이 생각해내면 생각해 낼 수록 좋다 왜냐하면 이 비선형 함수중에 하나는 데이터를 설명할 수 있기 떄문이다. 문제는 파이가 또 너무 많아지면 x간에 상관관계가 심해져서 오버피팅이 발생하거나 컨디션넘버가 높아지는 안좋은 현상이 발생한다.


- 그래서 가장 좋은것은 데이터의 비선형성에 딱맞는 적절한 개수의 파이만 있으면 좋은데 사람은 그것을 시각적으로 확인해서 조율할 수 있는 부분에서 한계가 있기 때문에 현실적으로는 그냥 무작정 많이 파이를 만들어보도록 기계한테 의존하는 것이다.

#### 4. 하이퍼 파라미터에 의해 모양이 바뀌는 비선형 기저 함수

![4](https://user-images.githubusercontent.com/41605276/56879821-5b8ab880-6a95-11e9-80e6-ae2a5c5c70de.jpg)

- 그래서 뭔가 이 파이자체도 모양을 바꿔서 이런저런 파이를 골라내고 싶다. 다시말해 기저함수를 여러개 써본다음에 그중에 좋은게 뭔지를 내가 찾고 싶다. 1차 2차 3차... 등의 함수를 써보고 싶다. 그렇게 하려면 모형자체를 바꾸는 하이퍼파라미터를 조절하면 된다. 좋은 파이를 찾는다는 것은 하이퍼파라미터 최적화를 한다는 의미이다.


- 이 파이에 모양을 바꿀 수 있는 하이퍼파라미터를 하나 생각을 한다. $$\ z = h \left( w^T \phi(x ; \theta) + b \right) $$ 그게 이 식에서 세타가 그것을 의미한다. 예를 들어서 x의 세타승이라고 하면 세타가 1일때는 1차함수, 세타가 2일때는 2차함수 이런방식이 되는 것이다. 그래서 이 세타를 할 수 있는 것을 다써보고 가장 좋은 것을 고르는 것이 하이퍼파라미터 최적화이다.


- 이 파이를 찾는데 어떤 방법이 좋을까 생각하다가 사람들이 발견한 것이 이 파이를 갖다가 뭔가 비선형 함수를 써야하는데 사람이 생각하기에 한계가 있으니까 퍼셉트론 자체에 활성화함수를 파이로 바로 활용해보자는 것이다. 


- $$\ z = h \left( \sum_{j=1}^M w_j h \left(w_{j}^{(1)} x + b_j^{(1)} \right)  + b \right) $$ 이런식으로..


- 위 식에서 w와 b를 바꿔주게 되면 원래 파이의 모양이 달라지게 되는 효과와 같다는 것이다. 다시말해 이 w와 b를 조절해주면 우리가 쓰는 파이라고 하는 basis function이 변한다는 것이다. 이런식으로 만들면 신경망을 구현할 수 있다.

- 정말로 이런식으로 하면 비선형 문제를 풀수 있는가에 대해 수학적으로 증명한 정리 Universal Approximation Theorem에서는 이 basis function(파이)을 무한히 많이 사용하면 어떠한 형태의 함수와도 유사한 형태의 함수 z(x) 를 만들 수 있다고 한다.파이를 몇개를 만들어야 한다고 단정하지는 않았다.


- 퍼셉트론은 하나만 썼을경우 linear한 문제밖에 못풀지만 그걸 여러개로 연결시켜서 네트워크를 만들게되면 XOR 같은 비선형문제도 풀 수 있다.


- 신경망에서는 Multi-classification을 할때 OvR 방식을 사용하기 위해 출력계층을 여러개 두는 경우도 있다. 통상 저렇게 여러개의 출력계층을 둘때는 출력계층에 소프트맥스 함수를 붙인다. 소프트맥스 함수는 들어가는 입력의 순서는 바뀌지 않으면서 모두 더했을때 합이 1이되게 하는 함수이다. 소프트맥스 함수를 쓰게되면 마치 확률인것처럼 보이게 된다. 실제 확률은 아니지만.. 어떤 카테고리 확률값으로 보이는 것이다.

#### 5. Multi-Layer Perceptrons

![5](https://user-images.githubusercontent.com/41605276/56879836-66454d80-6a95-11e9-84da-1aa828089c06.jpg)

#### 6. 신경망 가중치 표기법

![6](https://user-images.githubusercontent.com/41605276/56879841-6d6c5b80-6a95-11e9-8fe3-b84a88edbd2e.jpg)

- 신경망에서 가중치를 표기할때 주의해야할 점이 있다. $$\ w^{(l)}_{j,i} $$ 와 같이 표기해야 한다. l-1 번째 계층의 i번째 뉴런과 l번째 계층에서 j번째 뉴련을 연결하는 가중치라는 의미이다.


- 왜 이렇게 하느냐. 이렇게 뒤집어서 하게 되면 우리가 알고 있는 행렬의 원소기호 쓰는 방식으로 w를 묶어서 메트릭스를 만들 수 있다. 그리고 여기서 뒤쪽으로 넘어와서 y값 계산하는 과정을 메트릭스하고 벡터의 곱으로 표현할 수 있다. 아직까지는 활성화 함수를 통과한 상태는 아닌것이다.

#### 7. feedforward propagation(순방향 전파)

![7](https://user-images.githubusercontent.com/41605276/56879852-752c0000-6a95-11e9-953d-db1a01407a55.jpg)

- l−1 번째 계층의 출력과  l 번째 계층의 출력은 다음과 같은 관계가 있다. $$\ a^{(l)} = {W^{(l)}} z^{(l-1)} + b^{(l)} $$, $$\ z^{(l)} = h\left({W^{(l)}} z^{(l-1)} + b^{(l)}\right) $$, $$\ z^{(0)} = x $$, $$\ \hat{y} = z^{(L)} $$


- 그래서 앞단에서 출력한 z값과 그 중간을 연결하는 네트워크들(w) 곱한다음에 b값을 더해주면 신경망 내부에 있는 활성화 함수 값이 된다. 근데 얘는 출력은 아니다. 출력이 되려면 h 활성화 함수를 통과해야 한다.


- 다시정리하면 앞단에서 z가 나오게 되면 걔를 w와 곱하고 b를 더해서 활성화 함수값 구하고 그값을 활성화 함수를 통과시키고 나면 이 단의 출력이 된다. 앞단에서 뒷단까지 순차적으로 계층마다 이 과정을 반복하면 된다.


- 위와 같은 과정을 feedforward propagation(순방향 전파)라고 한다.

#### 8. 오차함수와 가중치 최적화

![8](https://user-images.githubusercontent.com/41605276/56879866-7fe69500-6a95-11e9-827f-0edad3d64a44.jpg)

- 퍼셉트론에서는 w의 값을 잘 조절하면 classification을 잘 할수 있다는 것이 핵심이었다. 신경망에서도 마찬가지로 w와 b를 잘 찾으면 classification을 잘 할 수 있다.


- 그런데 신경망에서는 이 w와 b를 찾는데에도 성능을 높이기 위해 파이라는 기저함수로 쓰게되었다. 


- 과거에는 w값을 좋은것을 찾아서 고정을 시키고, 파이는 그리드서치를 통해 최적화를 시켰었으나 너무 번거로우니 그냥 w와 파이를 한방에 찾을 수 있는 방법이 없을까 수학자들이 고민하였다.


- 다시말해 하이퍼파라미터 튜닝, 기저함수 찾는 과정, 모델 fitting과정 이 세개를 한방에 처리하자는 것이다.


- 목적함수는 예를 들어서 사진을 넣었을때 개면 1, 개가 아니면 0으로 출력되도록 말이다.


- 그렇게 하려면 트레이닝용 데이터는 있어야 한다. 그래서 목적함수를 어떻게 잡을 것인가. 다음과 같은 오차함수 수식을 이용한다. $$\ \begin{eqnarray}  C(w,b) = \sum_{i=1}^N C_i(w,b) =  \sum_{i=1}^N \| y_i - z_i^{(L)}(w,b) \|^2 
\end{eqnarray} $$


- 이 때  N 은 트레이닝 데이터의 갯수이다. 로지스틱 활성 함수를 이용한 분류 문제를 풀 때는 정답  y 가 클래스  k 에 속하는 데이터에 대해  k 번째 값만 1이고 나머지는 0인 원핫인코딩(one-hot-encoding) 벡터이다.


- 예를들어서 이미지가 여러장 있으면 이 이미지를 하나씩 넣게 된다. 사진을 넣으면 y헷이 나오게 되면 이게 개사진이 맞는 정답이면 1이어야 하고 아니면 0으로 나와야 한다.


- 위의 식처럼 유클리디안 거리를 이용해서 모든 이미지에 대해 실제 정답과 y헷값이 가능하면 가장 최소화하는 w와 b값을 찾으면 된다. 여기서 말하는 w와 b는 전처리 부분에 들어가는 w와 실제퍼셉드론에 들어가는 b를 원샷에 찾겠다는 것이다.


- 우리가 알고 있듯이 중간에 활성화 함수들이 막 끼워져 있다. 그래서 상당히 찾는 과정이 복잡해진다. 결론적으로 그레디언트 백터를 찾아서 조금씩 더 좋은 값으로 전진하는 방법을 채택해야한다. 신경망에서도 이 방법을 쓰면 된다.


- 수식으로 표현하면 다음과 같다. $$\ \begin{eqnarray}
  w_{k+1}  &=& w_{k} - \mu \frac{\partial C}{\partial w} \\
  b_{k+1} &=& b_{k} - \mu \frac{\partial C}{\partial b}
\end{eqnarray} $$ 이고 여기서 뮤는 최적화 스텝사이즈를 말한다.

#### 9. back propagation

![9](https://user-images.githubusercontent.com/41605276/56879877-8a089380-6a95-11e9-943d-860431e64e31.jpg)

- 만약에 입력계층이 784개이고 은닉계층이 15개 출력계층이 10개인 경우 w와 b는 몇개를 찾아야 하나. w는 앞단에 11760개 + 뒷단에 150개를 찾으면 된다. b는 앞단에 15개 + 뒷단에 10개 이다. 우리가 찾아야할 파라미터의 수는 11935개가 되는 것이다.


- 이말은 약 12000차원에서 최적화를 실시한다는 의미이고 그레디언트 백터는 약 12000개를 찾아야 한다는 것이다. 또한 미분을 12000번하면 된다는 의미이다.


- 문제는 C를 구하려면 사진을 한장씩 집어넣으면서 y헷이 얼마나 나오는지 보고 걔와 y를 빼서 애러값을 구해서 더하고 이러는 과정을 사진갯수만큼 해줘야한다.


- 데이터수가 커지면 감당이 안된다.. 너무 계산양이 커지게 되므로 그레디언트 백터를 구할때 효율적으로 하기 위해서 back propagation(역전파)라는 방법을 수학자들이 생각했다.


- 역전파 방법은 위의 수치적 미분을 하는것 보다는 훨씬 계산양이 줄어들게 된다.


- 먼저 델타를 뒤에서 앞으로 전파한다. 델타는 c를 a로 미분한 것이며 다음과 같다. $$\ \delta_j^{(l)} = \dfrac{\partial C}{\partial a_j^{(l)}} $$


- 그런데 a라는 것은 노드마다 하나씩 존재하게 된다. a의 갯수는 즉 노드의 개수가 된다. 아까는 a가 아니라 네트워크 엣지 w를 구해야하는 것인데 그것에 비해서는 상당히 줄어든 개수기 때문에 일단 a를 먼저 구하겠다는 것이다.


- 사실상 그래서 델타는 노드 하나마다 붙어있게 된다. 


- 그리고 델타를 계산할 수 있는 수식을 수학자들이 찾았는데 그 수식은 다음과 같다.
$$\ \begin{eqnarray} \delta^{(l-1)}_j = h'(a^{(l-1)}_j) \sum_{i=1}^{N_{(l)}} w^{(l)}_{ij} \delta^{(l)}_i
\end{eqnarray} $$

위식에서 N(l)은 l번째 레이어의 노드의 갯수를 말한다.


그리고 여기서 h프라임은 미분에서 만든 도함수를 의미한다. 활성화함수가 아니다. 그니까 aj l-1을 activation 함수를 미분해서 만든 도함수에 집어넣으면 무슨 숫자가 하나 나올것이다(h프라임함수의 출력은 기울기 상수가 나옴.스칼라다).


- 델타값l-1을 구하는데 델타 l을 이용하게 된다. 이게 무슨말이냐면 뒷단에 있는 델타를 이용해 앞단에 있는 델타를 구한다는 것이다.


- 그래서 해당 단에서 모든 j에 대해 기호로 쓸 경우에는 다음과 같은 식을 쓴다. 다시말해 위의 식을 벡터와 행렬의 식으로 쓰면 다음과 같다. $$\ \delta^{(l-1)} = h'(a^{(l-1)}) \odot ({W^T}^{(l)} \delta^{(l)}) $$ 여기서 $$\ \odot $$ 기호는 Hadamard Product, Schur product, 혹은 element-wise product 라고 하는데 예를들어 다음과 같다.


- $$\ x \odot y = 
\left(\begin{array}{c} x_1 \\ x_2 \\ x_3 \end{array}\right) \odot
\left(\begin{array}{c} y_1 \\ y_2 \\ y_3 \end{array}\right) 
= \left(\begin{array}{c} x_1 y_1 \\ x_2 y_2 \\ x_3 y_3 \end{array}\right) $$


- 이런식으로 back propogation을 하면 되는데 시작하는 지점은 y와 y헷의 차이, 즉 잔차를 쓰면 된다. 잔차가 마지막 부분의 델타다. 수식으로는 $$\ \delta^{(L)}_j = y_j - z_j $$와 같다.


- 여기까지하면 델타를 구하게 되는 것이고 우리의 원래 목적은 w와 b에 대한 미분값을 구해야하는 것이므로 그것은 다음과 같이 해주면 된다.


- 오차값에서 가중치에 대한 미분은 다음과 같이 구한다. 앞단에 있는 z와 뒷단에 있는 델타를 곱하면 된다. $$\ \frac{\partial C}{\partial w^{(l)}_{ji}} = \delta^{(l)}_j z^{(l-1)}_i $$ 요고를 앞단으로 계속 전파해주면 된다. 


- 또한 바이어스에 대한 미분값은 다음과 같은데 공교롭게도 그냥 델타 자체다.

b라는건 노드하나마다 b라는 값이 있고, b라는 얘의 미분값도 노드마다 달려있는데 그게 그냥 델타 자체라는 것이다.

$$\ \frac{\partial C}{\partial b^{(l)}_{j}} = \delta^{(l)}_j $$

![10](https://user-images.githubusercontent.com/41605276/56879884-955bbf00-6a95-11e9-8d90-27346565d0c5.jpg)

![11](https://user-images.githubusercontent.com/41605276/56879893-9c82cd00-6a95-11e9-8a4e-ea39c845321d.jpg)

#### 10. back propagation 의 증명

참고로 l번째 layer의 a값은 l+1번째 layer에 대한 어떤 함수라는 것이 성립한다.

l+1 단의 벡터를 집어넣으면 l번째 단의 a가 나오는 z의 역함수가 존재한다. 

왜냐하면 a하고 z를 연결해주는 것이 시그모이드 함수인데 이 시그모이드 함수의 역함수가 존재하기 때문이다.

![12](https://user-images.githubusercontent.com/41605276/56879901-a5739e80-6a95-11e9-9e83-323e2c7f2a69.jpg)

#### 11. Stochastic Gradient Descent

![13](https://user-images.githubusercontent.com/41605276/56879906-ad334300-6a95-11e9-8097-b7f69729b8d8.jpg)


- 이렇게해서 w값을 피팅할 수는 있는데 여전히 계산량은 많다. 왜냐하면 먼저 C에 대한 미분값을 찾아야 하는데 C라는게 이미지 한장한장 넣었을때 오차의 합이고 이걸 w로 미분한다는 것은 한장한장에 대한 오차의 미분의 합이라는 것이다.


- 이는 전체 오차를 구한것이 아니고 사진한장에 대한 오차를 구하는 것인데 이것을 이미지 갯수만큼 실시하고 델타를 모두 더하는게 전체 오차에 대한 델타가 되는 것이다.


- back propagation을 10만장의 이미지라면 10만번 100만장이면 100만번 해야하는데 꼭 이렇게 무식하게 반복을 해야하냐라는 것에서 나온 아이디어가 Stochastic Gradient Descent 방법이다. 


- 데이터의 특성이 10만개가 갖고 있는 특성이나 이중에 100개를 뽑았을때 데이터 특성이나 크게 다르지 않다는 것이다. 그렇기 때문에 굳이 10만개를 다 안써도 된다는 것이다.


- 다시말해 일부데이터만 이용해서 그레디언트 백터를 계산하는 것이다. 


- 데이터를 10만개 전부 다쓰게 되면 목적함수의 값이 반드시 줄어드는 형태로 나오지만 SGD는 줄어들기도하고 늘어나기도 하는 형태로 왔다갔다하게 된다. 그러나 특이한건 수렴속도는 두개가 비슷하다는 점이다.


- 따라서 계산량이 너무 많다보니까 줄여서 해보자는 방법이 현실적으로 많이 쓰인다.


- 그렇다면 또 문제가 되는 것이 전체 데이터중에 n개만 뽑아서 써야 하는데 어떤것을 빼서 써야하냐 주사위를 써서 랜덤 초이스를 해야하냐. 이 랜덤 초이스 자체도 연산이기 때문에 부담스럽다.


- 현실적으로는 그래서 데이터가 10만개 있으면 맨앞에 데이터 n개만써서 그레디언트를 업데이트 한다.


- 그 다음에는 n개 이후에 데이터를 쓰게 된데 새로운 데이터를 써보기 위해서. 그래서 또 그레디언트를 업데이트 해준다.


- 이렇게 데이터를 부분적으로 잘라서 그레디언트를 업데이트를 계속해주게 된다.

$$\ \dfrac{\partial C}{\partial w_k} = \sum_{i=1}^N \dfrac{\partial C_i}{\partial w_k} $$, $$\ w_{k+1} = w_k - \mu \dfrac{\partial C}{\partial w_k} $$


- 실제로 w는 미니배치사이즈 만큼 사용해서 업데이트해주고 미니배치를 데이터개수만큼 다 쓸 경우를 1 에포크라고 한다.


- 정리하면 신경망의 계수는 다음과 같이 찾으면 된다.(신경망 fitting하기)

맨첨에 w와 b값을 임의로 집어넣어넣는다. 그다음에 이미지 한장을 입력하게되면 임의로 집어넣은 w와 b값을 이용해서 feedforward propagation을 하게되고 a와 z값을 계산하게 된다. 최종출력계층의 z와 실제 y간의 오차를 계산해서 다시 back propagation을 해주게 된다. 그러면 델타가 나오게 되는데 델타와 z값을 곱해서 그레디언트 값을 계산을 한다. 그러면 이게 그레디언트 한번 계산된것이다. 이것을 이미지 개수만큼 반복해야 하지만 계산량이 워낙 많기 때문에 minibatch-size 만큼만 이미지를 뽑아서 iteration을 해주면 된다. 그래서 생긴 그레디언트들를 모두 평균낸다. 그 만큼 또 w와 b를 갱신해준다. 그 다음에 미니배치 사이즈만큼 또 이터레이션해주어 그레디언트 값을 업데이트해주고 그 그레디언트를 이용해서 w와 b를 반복한다.


#### # [요약정리]


- 신경망모형은 `기저함수`도 모수값에 의해 변화할 수 있는 적응형 기저함수모형이며 구조적으로는 여러개의 퍼셉트론 레이어를 쌓아놓은 형태이므로 `MLP(Multi-layer perceptron)`으로도 불린다.


- 신경망에 속한 퍼셉트론은 `neuron, node`라고 불린다. 각 계층은 다음 계층에 대해 적응형 기저함수의 역할을 한다. 최초의 계층은 입력계층, 마지막 계층은 출력계층, 중간은 은닉계층이라고 한다.


### # 신경망 계수탐색 프로세스

#### 1) initialize

모든 w,b 값을 임의의 값으로 초기화

#### 2) input

하나의 표본데이터 $$\ x_i $$로 입력 계층 설정

#### 3) feedforward propagation

모든 뉴런에 대해 a, z값 계산

#### 4) output and error calculation

최종출력계층의 값 $$\ z^{(L)} $$ 및 오차 $$\ \delta^{(L)} $$계산

#### 5) back propagation

반대방향으로 오차 $$\ \delta $$ 전파 

#### 6) gradient calculation

표본데이터 $$\ x_i $$에 의한 오차함수의 미분값(그레디언트) $$\ \frac{\partial C_i}{\partial w}=z \, \delta $$, $$\ \frac{\partial C_i}{\partial b}=\delta $$ 계산

#### 7) minibatch-size iteration

표본데이터를 $\ x_{i+1} $로 바꾸어 미니배치크기 만큼 2) ~ 6) 단계를 반복

#### 8) weight update

미니배치크기 만큼의 데이터를 사용한 후 그레디언트 $$\ \frac{\partial C}{\partial w} $$, $$\ \frac{\partial C}{\partial b} $$ 계산

이 그레디언트 값으로 w, b값을 업데이트


- 단순하게 수치적으로 미분을 계산한다면 모든 가중치에 대해서 개별적으로 미분을 계산해야 한다. 그러나 `Back propagation`방법을 사용하면 모든 가중치에 대한 미분값을 한번에 계산할 수 있다.


### # 신경망 성능 개선방법

- 크로스 엔트로피 형태의 오차함수를 사용하면 출력 레이어에서 활성화 함수의 도함수에 의한 영향을 제거 할 수 있다.

크로스 엔트로피 형태의 오차함수 : 

$$\ \begin{eqnarray} 
  C = y \log z^{(L)} + (1-y) \log (1-z^{(L)})
\end{eqnarray} $$

- 활성화 함수로 로지스틱 함수 대신 하이퍼탄젠트를 사용하면 도함수의 최댓값이 로지스틱 함수의 4배인 1이 되므로 그레디언트 감소현상이 줄어든다.

하이퍼탄젠트 : 

$$\ \begin{eqnarray}
  \tanh(a) \equiv \frac{e^a-e^{-a}}{e^a+e^{-a}} = 2\sigma(2a) - 1
\end{eqnarray} $$

`** 아래 두개는 가장많이 쓰는 방법으로 알려져 있다.`

- ReLu 활성화함수를 사용하는 것이다. 렐루는 가중치 총합 a가 큰 경우에도 기울기(그레디언트)가 1로 유지되므로 a가 커도 그레디언트 감소현상이 발생하지 않는다. CNN과 같이 레이어의 수가 많은 경우에 유용하다.


- dropout 정규화 방법은 이러한 문제를 해결하기 위해 에포크 마다 임의의 은닉계층 뉴런의 p%(보통 절반) dropout하여 최적화 과정에 포함하지 않는 방법이다.


### # 자주 사용하는 신경망 최적화 방법(그레디언트에 변형을 주는 방법)

** 기본 그레디언트 방법 : $$\ w_{k+1} = w_k - \mu_k g(w_k) = w_k - v_k $$

#### 1. decay 방법 : step size를 줄여 oscillation 현상을 회피

$$\ \mu_{k+1} = \mu_{k} \dfrac{1}{1 + \text{decay}} $$

#### 2. momentum 방법 : 진행하던 방향으로 계속 진행하게하여 최적화를 빠르게 수행

$$\ v_{k+1} = \text{momentum} \cdot v_k - \mu_k g(w_k) $$
