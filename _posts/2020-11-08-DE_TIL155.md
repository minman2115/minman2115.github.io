---
layout: post
title: "EMR 운영중 트러블슈팅 사례 - jupyterhub notebook 차원에서 spark config 부여하기"
tags: [Data Engineering]
comments: true
---

.


Data_Engineering_TIL(20201108)

#### [문제상황]

주피터 노트북을 이용해 pyspark을 사용하려고 하는데 주피터 노트북에서 직접 spark configuration을 부여해서 사용하고 싶다.


#### [문제해결을 위해 알아야할 내용]

- Jupyter notebook에서 spark config 적용 방법

주피터노트북 가장상단 cell에서 아래와 같은 명령어를 실행한다. 


```python
%%configure -f
{
    "name": "my_spark_app_name",
    "conf": {
        "spark.executor.cores": 5,
        "spark.executor.memory": "19g",
        "spark.yarn.executor.memoryOverhead": "2g",
        "spark.driver.memory": "19g",
        "spark.executor.instances": 8,
        "spark.default.parallelism": 80,
        "spark.sql.shuffle.partitions": 80
    }
}
```

위의 명령어 실행시 결과화면은 아래와 같을것이다.

`Current session configs: {'name': 'my_spark_app_name', 'conf': {'spark.executor.cores': 5, 'spark.executor.memory': '19g', 'spark.yarn.executor.memoryOverhead': '2g', 'spark.driver.memory': '19g', 'spark.executor.instances': 8, 'spark.default.parallelism': 80, 'spark.sql.shuffle.partitions': 80}, 'proxyUser': 'jovyan', 'kind': 'pyspark'}`


- spark-submit 시 conf 적용 우선순위


1순위 pyspark code


2순위 spark-submit property


3순위 spark-default.conf


- jupyter notebook에서는 아래와 같이 getorcreate()에서 create가 먹지 않는다 왜냐하면 jupyter에서 미리 생성하기 때문이다. 그래서 spark = sparksession... 이게 먹지 않는다. 모든 config는 jupyter에서 spark 셋팅하고 들어간다.


`spark = SparkSession.builder.appName("my_spark_app").getOrCreate()`



- jupyter 에서 spark = sparksession ... getorcreate가 달린 이유는 하나이다. jupyter에서 설정된 spark config 값들을 가져오라는 것이다. 아무리 spark = sparksession뒤에 config를 달아도 먹지 않는 이유다.


- Livy의 핵심 동작원리

notebook에서 spark 커널을 띄우면 Livy가 자동실행됨 --> LIvy <-- REST communication --> spark cluster endpoint
