---
layout: post
title: "신경망 작동원리 기초개념"
tags: [딥러닝]
comments: true
---

.

#### # 학습 시 참고한 URL : https://datascienceschool.net


### # 신경망 작동원리

- 신경망에서 가중치를 표기할때 주의해야할 점이 있다. $$\ w^{(l)}_{j,i} $$ 와 같이 표기해야 한다. l-1 번째 계층의 i번째 뉴런과 l번째 계층에서 j번째 뉴련을 연결하는 가중치라는 의미이다.


- 왜 이렇게 하느냐. 이렇게 뒤집어서 하게 되면 우리가 알고 있는 행렬의 원소기호 쓰는 방식으로 w를 묶어서 메트릭스를 만들 수 있다. 그리고 여기서 뒤쪽으로 넘어와서 y값 계산하는 과정을 메트릭스하고 벡터의 곱으로 표현할 수 있다. 아직까지는 활성화 함수를 통과한 상태는 아닌것이다.


- l−1 번째 계층의 출력과  l 번째 계층의 출력은 다음과 같은 관계가 있다. $$\ a^{(l)} = {W^{(l)}} z^{(l-1)} + b^{(l)} $$, $$\ z^{(l)} = h\left({W^{(l)}} z^{(l-1)} + b^{(l)}\right) $$, $$\ z^{(0)} = x $$, $$\ \hat{y} = z^{(L)} $$


- 그래서 앞단에서 출력한 z값과 그 중간을 연결하는 네트워크들(w) 곱한다음에 b값을 더해주면 신경망 내부에 있는 활성화 함수 값이 된다. 근데 얘는 출력은 아니다. 출력이 되려면 h 활성화 함수를 통과해야 한다.


- 다시정리하면 앞단에서 z가 나오게 되면 걔를 w와 곱하고 b를 더해서 활성화 함수값 구하고 그값을 활성화 함수를 통과시키고 나면 이 단의 출력이 된다. 앞단에서 뒷단까지 순차적으로 계층마다 이 과정을 반복하면 된다.


- 위와 같은 과정을 feedforward propagation(순방향 전파)라고 한다.

- 퍼셉트론에서는 w의 값을 잘 조절하면 classification을 잘 할수 있다는 것이 핵심이었다. 신경망에서도 마찬가지로 w와 b를 잘 찾으면 classification을 잘 할 수 있다.


- 그런데 신경망에서는 이 w와 b를 찾는데에도 성능을 높이기 위해 파이라는 기저함수로 쓰게되었다. 


- 과거에는 w값을 좋은것을 찾아서 고정을 시키고, 파이는 그리드서치를 통해 최적화를 시켰었으나 너무 번거로우니 그냥 w와 파이를 한방에 찾을 수 있는 방법이 없을까 수학자들이 고민하였다.


- 다시말해 하이퍼파라미터 튜닝, 기저함수 찾는 과정, 모델 fitting과정 이 세개를 한방에 처리하자는 것이다.


- 목적함수는 예를 들어서 사진을 넣었을때 개면 1, 개가 아니면 0으로 출력되도록 말이다.


- 그렇게 하려면 트레이닝용 데이터는 있어야 한다. 그래서 목적함수를 어떻게 잡을 것인가. 다음과 같은 오차함수 수식을 이용한다. $$\ \begin{eqnarray}  C(w,b) = \sum_{i=1}^N C_i(w,b) =  \sum_{i=1}^N \| y_i - z_i^{(L)}(w,b) \|^2 
\end{eqnarray} $$


- 이 때  N 은 트레이닝 데이터의 갯수이다. 로지스틱 활성 함수를 이용한 분류 문제를 풀 때는 정답  y 가 클래스  k 에 속하는 데이터에 대해  k 번째 값만 1이고 나머지는 0인 원핫인코딩(one-hot-encoding) 벡터이다.


- 예를들어서 이미지가 여러장 있으면 이 이미지를 하나씩 넣게 된다. 사진을 넣으면 y헷이 나오게 되면 이게 개사진이 맞는 정답이면 1이어야 하고 아니면 0으로 나와야 한다.


- 위의 식처럼 유클리디안 거리를 이용해서 모든 이미지에 대해 실제 정답과 y헷값이 가능하면 가장 최소화하는 w와 b값을 찾으면 된다. 여기서 말하는 w와 b는 전처리 부분에 들어가는 w와 실제퍼셉드론에 들어가는 b를 원샷에 찾겠다는 것이다.


- 우리가 알고 있듯이 중간에 활성화 함수들이 막 끼워져 있다. 그래서 상당히 찾는 과정이 복잡해진다. 결론적으로 그레디언트 백터를 찾아서 조금씩 더 좋은 값으로 전진하는 방법을 채택해야한다. 신경망에서도 이 방법을 쓰면 된다.


- 수식으로 표현하면 다음과 같다. $$\ \begin{eqnarray}
  w_{k+1}  &=& w_{k} - \mu \frac{\partial C}{\partial w} \\
  b_{k+1} &=& b_{k} - \mu \frac{\partial C}{\partial b}
\end{eqnarray} $$ 이고 여기서 뮤는 최적화 스텝사이즈를 말한다.

- 만약에 입력계층이 784개이고 은닉계층이 15개 출력계층이 10개인 경우 w와 b는 몇개를 찾아야 하나. w는 앞단에 11760개 + 뒷단에 150개를 찾으면 된다. b는 앞단에 15개 + 뒷단에 10개 이다. 우리가 찾아야할 파라미터의 수는 11935개가 되는 것이다.


- 이말은 약 12000차원에서 최적화를 실시한다는 의미이고 그레디언트 백터는 약 12000개를 찾아야 한다는 것이다. 또한 미분을 12000번하면 된다는 의미이다.

- 문제는 C를 구하려면 사진을 한장씩 집어넣으면서 y헷이 얼마나 나오는지 보고 걔와 y를 빼서 애러값을 구해서 더하고 이러는 과정을 사진갯수만큼 해줘야한다.

- 데이터수가 커지면 감당이 안된다.. 너무 계산양이 커지게 되므로 그레디언트 백터를 구할때 효율적으로 하기 위해서 back propagation(역전파)라는 방법을 수학자들이 생각했다.


- 역전파 방법은 위의 수치적 미분을 하는것 보다는 훨씬 계산양이 줄어들게 된다.


- 먼저 델타를 뒤에서 앞으로 전파한다. 델타는 c를 a로 미분한 것이며 다음과 같다. $$\ \delta_j^{(l)} = \dfrac{\partial C}{\partial a_j^{(l)}} $$


- 그런데 a라는 것은 노드마다 하나씩 존재하게 된다. a의 갯수는 즉 노드의 개수가 된다. 아까는 a가 아니라 네트워크 엣지 w를 구해야하는 것인데 그것에 비해서는 상당히 줄어든 개수기 때문에 일단 a를 먼저 구하겠다는 것이다.


- 사실상 그래서 델타는 노드 하나마다 붙어있게 된다. 


- 그리고 델타를 계산할 수 있는 수식을 수학자들이 찾았는데 그 수식은 다음과 같다.
$$\ \begin{eqnarray} \delta^{(l-1)}_j = h'(a^{(l-1)}_j) \sum_{i=1}^{N_{(l)}} w^{(l)}_{ij} \delta^{(l)}_i
\end{eqnarray} $$

위식에서 N(l)은 l번째 레이어의 노드의 갯수를 말한다.
또한 h프라임은 미분에서 만든 도함수를 의미한다. 활성화함수가 아니다.


- 델타값l-1을 구하는데 델타 l을 이용하게 된다. 이게 무슨말이냐면 뒷단에 있는 델타를 이용해 앞단에 있는 델타를 구한다는 것이다.


- 그래서 해당 단에서 모든 j에 대해 기호로 쓸 경우에는 다음과 같은 식을 쓴다. 다시말해 위의 식을 벡터와 행렬의 식으로 쓰면 다음과 같다. $$\ \delta^{(l-1)} = h'(a^{(l-1)}) \odot ({W^T}^{(l)} \delta^{(l)}) $$ 여기서 $$\ \odot $$ 기호는 Hadamard Product, Schur product, 혹은 element-wise product 라고 하는데 예를들어 다음과 같다.


- $$\ x \odot y = 
\left(\begin{array}{c} x_1 \\ x_2 \\ x_3 \end{array}\right) \odot
\left(\begin{array}{c} y_1 \\ y_2 \\ y_3 \end{array}\right) 
= \left(\begin{array}{c} x_1 y_1 \\ x_2 y_2 \\ x_3 y_3 \end{array}\right) $$


- 이런식으로 back propogation을 하면 되는데 시작하는 지점은 y와 y헷의 차이, 즉 잔차를 쓰면 된다. 잔차가 마지막 부분의 델타다. 수식으로는 $$\ \delta^{(L)}_j = y_j - z_j $$와 같다.


- 여기까지하면 델타를 구하게 되는 것이고 우리의 원래 목적은 w와 b에 대한 미분값을 구해야하는 것이므로 그것은 다음과 같이 해주면 된다.


- 오차값에서 가중치에 대한 미분은 다음과 같이 구한다. 앞단에 있는 z와 뒷단에 있는 델타를 곱하면 된다. $$\ \frac{\partial C}{\partial w^{(l)}_{ji}} = \delta^{(l)}_j z^{(l-1)}_i $$ 요고를 앞단으로 계속 전파해주면 된다. 


- 또한 바이어스에 대한 미분값은 다음과 같은데 공교롭게도 그냥 델타 자체다. $$\ \frac{\partial C}{\partial b^{(l)}_{j}} = \delta^{(l)}_j $$




- 이렇게해서 w값을 피팅할 수는 있는데 여전히 계산량은 많다. 왜냐하면 먼저 C에 대한 미분값을 찾아야 하는데 C라는게 이미지 한장한장 넣었을때 오차의 합이고 이걸 w로 미분한다는 것은 한장한장에 대한 오차의 미분의 합이라는 것이다.


- 이는 전체 오차를 구한것이 아니고 사진한장에 대한 오차를 구하는 것인데 이것을 이미지 갯수만큼 실시하고 델타를 모두 더하는게 전체 오차에 대한 델타가 되는 것이다.


- back propagation을 10만장의 이미지라면 10만번 100만장이면 100만번 해야하는데 꼭 이렇게 무식하게 반복을 해야하냐라는 것에서 나온 아이디어가 Stochastic Gradient Descent 방법이다. 


- 데이터의 특성이 10만개가 갖고 있는 특성이나 이중에 100개를 뽑았을때 데이터 특성이나 크게 다르지 않다는 것이다. 그렇기 때문에 굳이 10만개를 다 안써도 된다는 것이다.


- 다시말해 일부데이터만 이용해서 그레디언트 백터를 계산하는 것이다. 


- 데이터를 10만개 전부 다쓰게 되면 목적함수의 값이 반드시 줄어드는 형태로 나오지만 SGD는 줄어들기도하고 늘어나기도 하는 형태로 왔다갔다하게 된다. 그러나 특이한건 수렴속도는 두개가 비슷하다는 점이다.


- 따라서 계산량이 너무 많다보니까 줄여서 해보자는 방법이 현실적으로 많이 쓰인다.


- 그렇다면 또 문제가 되는 것이 전체 데이터중에 n개만 뽑아서 써야 하는데 어떤것을 빼서 써야하냐 주사위를 써서 랜덤 초이스를 해야하냐. 이 랜덤 초이스 자체도 연산이기 때문에 부담스럽다.

- 현실적으로는 그래서 데이터가 10만개 있으면 맨앞에 데이터 n개만써서 그레디언트를 업데이트 한다.


- 그 다음에는 n개 이후에 데이터를 쓰게 된데 새로운 데이터를 써보기 위해서. 그래서 또 그레디언트를 업데이트 해준다.


- 이렇게 데이터를 부분적으로 잘라서 그레디언트를 업데이트를 계속해주게 된다.

$$\ \dfrac{\partial C}{\partial w_k} = \sum_{i=1}^N \dfrac{\partial C_i}{\partial w_k} $$, $$\ w_{k+1} = w_k - \mu \dfrac{\partial C}{\partial w_k} $$


- 실제로 w는 미니배치사이즈 만큼 사용해서 업데이트해주고 미니배치를 데이터개수만큼 다 쓸 경우를 1 에포크라고 한다.

- 정리하면 신경망의 계수는 다음과 같이 찾으면 된다.(신경망 fitting하기)

맨첨에 w와 b값을 임의로 집어넣어넣는다. 그다음에 이미지 한장을 입력하게되면 임의로 집어넣은 w와 b값을 이용해서 feedforward propagation을 하게되고 a와 z값을 계산하게 된다. 최종출력계층의 z와 실제 y간의 오차를 계산해서 다시 back propagation을 해주게 된다. 그러면 델타가 나오게 되는데 델타와 z값을 곱해서 그레디언트 값을 계산을 한다. 그러면 이게 그레디언트 한번 계산된것이다. 이것을 이미지 개수만큼 반복해야 하지만 계산량이 워낙 많기 때문에 minibatch-size 만큼만 이미지를 뽑아서 iteration을 해주면 된다. 그래서 생긴 그레디언트들를 모두 평균낸다. 그 만큼 또 w와 b를 갱신해준다. 그 다음에 미니배치 사이즈만큼 또 이터레이션해주어 그레디언트 값을 업데이트해주고 그 그레디언트를 이용해서 w와 b를 반복한다.
