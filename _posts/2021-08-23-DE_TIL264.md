---
layout: post
title: "YARN 클러스터에서 Spark application 실행 내부구조"
tags: [Data Engineering]
comments: true
---

.

Data_Engineering_TIL(20210823)

[학습시 참고자료]

"[Spark] Spark 구조 및 실행 흐름" 블로그글

https://wooono.tistory.com/57?category=914839

"[Spark] yarn 구조 및 실행 순서" 블로그글

https://wooono.tistory.com/58?category=914839

"Real-world Python workloads on Spark: EMR clusters" 블로그글

https://becominghuman.ai/real-world-python-workloads-on-spark-emr-clusters-3c6bda1a1350


[학습내용]

### spark 구성요소

- spark application

1) spark에서 실행되는 사용자가 개발한 프로그램


2) 1개의 Driver 프로그램과 N개의 Executor로 구성

- Driver 프로그램

![1](https://user-images.githubusercontent.com/41605276/130446291-865da639-fa29-4263-afdf-a29152666a6c.png)


1) spark application에서 Main() 함수가 실행되는 프로세스


2) 주요역할

spark application을 실제 spark에서 실행하는 단위인 Task로 변환해서 Executor에 할당

연산들의 관계에 대해 논리적인 방향성 비순환 그래프(DAG)를 생성한다.

입력으로부터 RDD를 생성하고 Transformation을 사용해서 또다른 RDD를 만들게 되며 Action 연산을 통해 데이터를 어떻게 처리할건지 계획을 짠다.

Driver 프로그램이 실행될때, Driver는 논리적인 방향성 비순환 그래프(DAG)를 물리적인 실행계획(Physical plan)으로 변환한다.

드라이버 프로그램은 Map/Transformation을 사용한 여러 최적화를 통해, 물리적인 실행계획을 여러 단계(Stage)로 바꾼다.

각 Stage는 순서에 따라 여러개의 Task로 구성된다.


단위 Task들을 묶어서 클러스터로 전송한다.

Task들의 묶음은 Stage이며 Stage의 묶음은 Job이다.
  
3) Executor에 할당된 Task 들을 적절하게 스케쥴링

Executor들은 프로그램 시작시 Driver 프로그램에 등록된다.


Driver 프로그램은 항상 실행중인 Executor들을 감시한다.


spark이 연산하는 데이터가 만약에 HDFS에 저장되었다면 각 Task가 데이터가 저장된 노드에 기반해서 적절한 노느 위치에서 실행하도록 한다.

- SparkContext

1) Driver 프로그램에서 Job들을 Executor에 실행하기 위한 엔드포인트이다.


2) 클러스터 매니저와 연결된다.

- Executor

1) Application에서 Driver Program이 요청한 Task들의 연산을 실제로 수행하는 프로세스


2) Executor는 Spark application 실행 시 최초 한번 실행된다.


대개 애플리케이션이 끝날 때까지 계속 동작하지만, 익스큐터가 오류로 죽더라도 스파크 애플리케이션은 계속 실행된다.


3) Executor는 두가지 역할을 한다.

Application을 구성하는 Task들을 실행하여 Driver Program에 그 결과를 되돌려 준다.

그리고 각 Executor 안에 존재하는 Block Manager라는 서비스를 통해 spark application에서 cache 하는 RDD를 저장하기 위한 메모리 저장소를 제공한다.


4) RDD가 Executor 내부에 직접 캐시되므로 단위 작업들 또한 같이 실행되기에 용이하다.


- Cluster Manager

1) Cluster Manager는 여러 대의 서버로 구성된 클러스터 환경에서, 다수의 Application이 함께 구동될 수 있도록 Application(Driver와 Executor) 사이의 자원을 관리해주는 역할을 담당함

2) spark와 탈부착이 가능한 컴포넌트이며 Spark는 YARN, mesos, Standalone 등 다양한 외부 리소스 매니저들 위에서도 실행이 가능함


- Master Node

Worker를 관리하는 노드


- Worker node

Cluster에서 Application 코드를 실행할 수 있는 모든 노드


- Task

하나의 Executor에서 수행되는 최소 작업 단위


- Stage

Task의 집합


- Job

Stage의 집합


### Spark Deploy mode

Spark Cluster를 사용할때 Driver Program의 실행 위치가 어디에 있느냐에 따라 달라짐

** yarn 클러스터 기준

1) Client mode 

Driver Program이 YARN Cluster 외부에 위치

Driver는 spark-submit의 일부로 실행됨

Driver Program 출력을 직접 확인 가능

Driver Program과 Spark application은 모두 Client 프로세스라는 것에서 실행됨

따라서 Spark Application을 실행했던 콘솔을 닫아 버리거나 기타 다른 방법으로 Client 프로세스를 중지시키면, Spark Context도 함께 종료되면서 수행 중이던 모든 스파크 job이 중지됨

2) Cluster mode

Driver가 YARN Cluster 내부에 위치

Driver가 Cluster내의 작업 노드(Worker) 중 하나에서 실행됨

실행 후 개입하지 않는 방식

Spark application은 Cluster에서 독립적인 프로세스(Task)들의 집합으로 실행되고 이들은 Driver Program의 Spark Context를 통해 조정됨


### YARN 클러스터 구성요소

1) Resource Manager 

전체적인 자원 할당 관리

Resource Manager는 Client의 요청에 해당하는 Application Master를 실행

Resource Manager는 Node Manager를 통해 전체 클러스터의 Resource 를 알고 관리할 수 있다.

Resource Manager 은 클러스터 당 하나만 있다.

2) Application Manager 

Client가 요청한 작업을 driver program으로부터 권한을 위임받아 실행

어플리케이션에 필요한 자원 확인 후 Resource Manager에게 자원 요청

Node Manager에게 컨테이너를 만들라고 지시

할당된 컨테이너들은 Application Manager가 관리

3) Node Manager 

해당 노드의 자원 관리

Node Manager는 Application Manager의 명령에 따라 task 를 실행시킨다.


### YARN 클러스터에서 Spark Application deploy client 모드 실행 내부과정

![2](https://user-images.githubusercontent.com/41605276/130464330-786bcb4f-9db6-4d89-b7c4-608cec9a9818.png)

STEP 1) 사용자는 spark-submit 명령어를 사용하여 spark application을 실행


STEP 2) spark-submit은 드라이버 프로그램을 실행하고 사용자가 정의한 main() 메소드를 호출

SparkContext도 생성 되어 Cluster Manager와 연결 됨


STEP 3) Driver Program은 Cluster Manager에게 Spark application 실행을 위한 리소스를 요청한다.


STEP 4) Resource Manager는 요청 받은 작업을 실행하기 위해, 먼저 Message Interface라는 것을 통해 YARN 클러스터를 구축하고 슬레이브 노드중 하나에 Application Master를 실행


STEP 5) Application Manager는 Client 가 요청한 작업이 얼마만큼의 Resource 를 필요로 하는지 파악 한 후에, Resource Manager에게 "이 만큼의 Resource가 작업하는 데 들어가니 할당 좀 해주세요" 라고 요청한다.

Executor 실행은 Cluster Manager에서 하고, Task 할당은 Driver Program에서 진행


STEP 6) Cluster manager는 Application Master가 요청한 Executor를 할당


STEP 7) Application Manager는 각 노드의 Node manager에게 Container 를 만들라고 지시하고 Node Manager는 Container 를 만든다.

실질적으로 Container 를 만드는 건 Node Manager가 한다.

컨테이너는 task 가 실행되기 위한 공간이며, 많으면 많을수록 task 가 많이 실행 될 것이다.

생성된 Container 들은 이제 Application Master가 관리한다.


STEP 8) Driver Program를 통해 사용자 애플리케이션이 실행된다.

DAG Schedling을 통해 spark job을 Task 단위로 분할하여 Executor에게 보낸다.


STEP 9) Application Manager는 각 노드의 Node Manager에게 "너는 이런 task 를 실행하고, 너는 저런 task 를 실행해라" 라고 명령하고, Node Manager 은 그 명령에 따라 task 를 실행시킨다.


STEP 10) 작업이 완료되면 Application Manager는 결과를 Driver Program으로 보낸다.


STEP 11) Application Master는 Resource Manager 에게 "일 다 끝났어요!" 라고 말 하고 자신을 정지한다.


STEP 12) Resource Manager는 Application Master에게 할당한 Resource들을 모두 수거해간다.

### YARN 클러스터에서 Spark Application deploy cluster 모드 아키텍처

![3](https://user-images.githubusercontent.com/41605276/130464145-407a2cd8-4ecc-43be-bf69-a0bfe0b42c5d.png)

** 드라이버 프로그램은 반드시 마스터 노드에서 실행되지 않으며 YARN 클러스터 슬레이브 노드중에 하나에서 실행됨
