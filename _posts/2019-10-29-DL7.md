---
layout: post
title: "Deep Learning Optimization Methods"
tags: [딥러닝]
comments: true
---

.

Deep_Learning_Studynotes_(20190713)

study program : https://www.fastcampus.co.kr/data_camp_deeplearning

#### [Neural Network 기초개념 3 리마인딩]

URL : https://minman2115.github.io/DL5

- 렐루의 단점은 모든 입력에 대해서 output이 음수가 나오면 렐루함수를 통과하는 순간 0이 되어서 전부다 kill되는 데드렐루 현상이 발생해서 학습이 안될수도 있다. 이런 문제를 보완하기 위해 나온것이 위키렐루와 피렐루이다. 


- 위키렐루는 음수쪽에 기울기를 약간 주는 것이고 피렐루는 기울기까지 학습시키는 것이다. 일루라는 것도 있는데 값이 마이너스 무한대로 갔을때 출력도 마이너스 무한대로 표현함으로써 아웃라이어(노이즈)에 대해서도 대응할 수 있는 함수이다. 그리고 이것을 일반화 한것을 maxout이라고 한다.


- 데이터 전처리에 대해서도 언급했었다. 평균 0에 표준편차도 1로 데이터들을 변환해주는것이 보통이다. 이미지에 대해서는 이런 노멀라이징은 잘 안한다. 다만 평균을 맞춰주는 것을 보통으로 한다. 그렇다고 노멀라이징을 아예 안하는건 아니다. 평균을 구할때 어떤것을 기준으로 평균을 구하는게 중요한데 모든 트레이닝 데이터셋에 대해서 평균값을 구할건데 R,G,B 채널별로 구한다. R채널의 평균, G채널의 평균, B채널의 평균. 이미지가 100만장 있으면 100만장의 R채널들만 전부 모아서 거기에 있는 모든 픽셀을 더한다음 전체 픽셀로 나누어서 평균을 구하고, B채널, G채널도 마찬가지로 이런식으로 해준다. 


- 예를들어서 이미지넷으로 트레이닝 시켜서 사람들이 학습된 모델을 사람들이 공개를 한다. 그거를 다운받아서 나도 돌려보고 싶은데 돌릴때 테스트 데이터에 대해서 채널별로 트레이닝 했을때 평균을 맞춰주지 않고 돌리게되면 이상한 결과가 나올 수도 있다. 그래서 모델을 만든사람들이 가중치를 공개할때 내가 쓴 평균값이 뭐인지도 공개한다. 학습할때 사용한 이미지의 R채널의 평균값, G채널의 평균값, B채널의 평균값이 뭐인지 공개한다. 


- 그렇게 안하고 mnist에서 하듯이 0 ~ 1사이로 그냥 255로 나누어서 하는 케이스도 있다. 이런경우는 채널별로 평균 안구해도 되고 255로 그냥 나누어주면 된다.


- 그리고 가중치 초기화도 언급을 했었다. 가중치를 너무 크게하면 안되고, 결국에는 평균 0에 표준편차도 얼마를 할지를 보통 정하는 편인데 표준편차를 너무크게하면 Saturation 영역으로 빠지게 되고, 작게하면 전부 0이되버리기 때문에 적당히 작게해야 한다. 적당히 작게 한다는게 퍼셉트론의 입력으로 들어오는게 몇개인지 개수를 보고 정하는것이 좋다. 이런 아이디어로 나온것이 하비에르 초기화 방법이고, he 초기화 방법은 렐루를 쓸때는 음수 절반이 날라가기 때문에 나누어주는 것을 작게 나누어줘야 한다는 아이디어에서 나온것이다. 하비에르 초기화방법에는 들어오는 입력이 10개이기 때문에 루트10으로 나누어주는데 he 초기화 방법에서는 그렇게 하지말고 10개중에 절반은 음수이기 때문에 0으로 날라가니까 루트 10으로 나누지말고 루트 5로 나누어야 한다는 아이디어다. 


- 그리고 cyclic learning rate 처럼 learning rate를 키웠다 줄였다 하는 아이디어를 쓰는 경우도 있는데 learning rate를 순간적으로 훅 키우는 이유는 세들포인트에 빠지지 않기 위함이다.


- 또한 딥러닝에서 오버피팅에 대한 우려도 있기 때문에 이를 막기 위한 아이디어를 알아봤다. 정규화를 언급을 했었는데 L1은 어떤얘들이 먼저 0으로 바뀌는 것이다. 예를 들어서 가중치가 100개가 있는데 100중에 하나씩 하나씩 0으로 바뀌어 가면서 네트워크가 sparse해지게 된다. L2를 쓰게 되면 가중치가 0이 되는 얘들은 없지만 전체적인 가중치가 작아지게 된다.


- 그리고 dropout을 봤었다. 트레이닝할때 일정확률로 노드일부를 날리는 것이다. 그리고 테스트할때는 다시 노드전체로 테스트하게 된다. 대신에 트레이닝할때 랜덤하게 켜지고 꺼지고 하는것을 테스트할때는 그렇게 안할 것이기 때문에 그거에 대한 보상을 해줘야 하는데 가중치를 평균내서 보상을 해준다. 


- 배치놈도 공부했었다. 배치놈은 wx+b와 같이 가중치를 곱해서 바이어스까지 더한다음에 배치놈을 한번적용하고 그 다음에 활성화 함수를 쓰게 된다. 이때 배치놈을 한다는게 들어오는 배치단위로 평균, 표준편차를 구해서 평균 0, 표준편차 1로 맞춰주는 것이다. 대신에 너무 그렇게 다 하면 자유도가 없어지니까 감마랑 배타랑 스케일 시프트 팩터로 들어간다. 얘도 마찬가지로 트레이닝할때 배치를 어떻게 하느냐에 따라서 랜덤성이 들어가기 때문에 트레이닝할때 배치단위마다 매레이어마다 평균, 표준편차를 구한다. 그런다음에 이 평균과 표준편차들의 평균을 저장해놨다가 테스트 타임에 어떤 데이터가 들어오든 그 저장해놓은 평균과 표준편차를 사용해서 테스트 데이터를 노멀라이징 한다음에 테스트를 해야한다. 그래서 단점이 트레이닝할때 배치사이즈가 작으면 좋지 않다. 왜냐하면 배치로 뽑는 샘플이 전체 데이터를 잘 대변하고 있다고 가정하기 때문이다. 일반적으로 배치노멀라이제이션을 많이 한다.


#### [딥러닝 최적화방법 학습기록]

![1](https://user-images.githubusercontent.com/41605276/67731887-ffe9b980-fa3c-11e9-8831-de1c53451a44.png)

- 그레디언트 디센트는 산과 골짜기들이 어떻게 되어있는지 우리는 모르는 상황에서 어쨌든 눈을 가리고 제일 낮은곳으로 가야한다. 지금 서있는 곳의 경사를 보고 경사가 내려가는 방향으로 계속 가다보면 언젠가는 제일낮은곳으로 갈 수 있겠다는 개념이다. 일반적인 그레디언트 디센트는 배치 그레디언트 디센트를 말한다. 


- 위의 그림에서 세트가 가중치라고 생각하면 된다. 이전 세타에다가 러닝레이트에다가 J가 로스값이라고 생각하면 되는데 이 J를 세타로 미분한다. 이게 그레디언트인데 이 그레디언트에 러닝레이트를 곱한값을 이전 세타에서 빼주면된다.


- 스토케스틱 그레디언트 디센트는 샘플하나를 뽑아서 그 하나가 전체를 대표할것이라 가정하는 방법이다. 그래서 그 특정샘플 하나를 뽑아서 그거에 대해서 로스를 게산하고 미분한 다음에 업데이트 하는 것이다.


- 스토케스틱 그레디언트 디센트 방법은 너무 극단적으로 소수의 샘플링만하기 때문에 나온 방법이 미니배치 그레디언트 디센트 방법이다. N개의 샘플을 가져와서 그것의 로스를 계산하고 미분을 하는 방법이다. 


- 그런데 그레디언트 디센트 방법의 근본적인 문제가 있다. local minima나 세들포인트 같은 그레디언트가 0에 근접한 지역에 도착하면 더이상 학습이 안되는 문제가 있다. 또한 최적점을 찾아가는 모먼트의 효율성이 떨어지는 편이다. 우리는 최적점으로 다이렉트 화살표로 가고 싶은데 그레디언트 디센트는 아래 그림처럼 지그제그를 그리면서 천천히 찾아간다. 그리고 최적점으로 갈수록 더욱더 느리게 수렴하게 되는 문제도 있다.

![2](https://user-images.githubusercontent.com/41605276/67731895-0710c780-fa3d-11e9-94b1-a39a78f88e5d.png)

- 그래서 우리는 아래 그림과 같이 최적화 방법에 대해 알아볼 것이다. 그래 그림은 카카오의 하용호님이 만든 자료로 최적화 방법들에 대한 개념을 잘 도식화 하였다.

![3](https://user-images.githubusercontent.com/41605276/67731904-0bd57b80-fa3d-11e9-998b-1dbe65bb6f07.png)

그레디언트는 백터니까 방향과 크기가 있다. 그래서 위의 그림에서 위쪽 방향 즉, 파란색 화살표들은 방향을 잘 조절해보겠다는 최적화 방법이고, 아래에 빨간색 화살표들은 크기(러닝레이트)를 상황에 따라서 컨트롤을 해보겠다는 방법이다.

![4](https://user-images.githubusercontent.com/41605276/67731912-109a2f80-fa3d-11e9-94aa-b02cd2369550.png)

- 그래서 모멘텀 방법은 이전의 그레디언트 방향에 감마라는 어떤값을 곱하는 것이다. 우리가 모멘텀이라는 방법을 쓰기위해 코딩을 한다면 감마를 사용자가 정해줘야 한다. 보통 1에 가까운 값이 디폴트로 들어가 있다. 결론적으로 이전의 움직였던 방향에다가 백터의 합을한 그 방향으로 움직이겠다라는 것이다. 좌측 그렘에 그레디언트 디센트는 최적점을 찾아가는 방향이 비교적 심한 지그제그 형태로 움직이면서 가는데 모멘텀을 적용하면 지그제그 형태가 조금더 직선에 가까운 형태로 상쇄되는 양상이다. 즉 진폭은 작아지고 최적점으로 다가가는 방향은 좀더 다이렉트해지게 된다. 그래서 더 빨리 최적점으로 수렴하게 하겠다는 의도가 담긴 방법이다. 모멘텀 방법은 그레디어트 디센트와 비교했을때 단점도 있다. 관성을 가지고 최적점에 다가가기 때문에 옵티멀 포인트를 지나쳐버리는 경우도 있다. 

![5](https://user-images.githubusercontent.com/41605276/67731921-15f77a00-fa3d-11e9-9c10-6407aeb511bf.png)

- 그 다음에 NAG라는 것도 있다. 이 방법은 모멘텀 방법을 반영한 것이다. 모멘텀 방법은 J()안에 세타만 있었는데 세타에서 무언가를 뺐다. 그게 뭐냐면 감마Vt-1이다. 그림을 보면 모멘텀방법에서는 그레디언트가 빨간색 선이고, 이전에 이동했던 방향이 초록색이라면 그 둘의 합인 방향 파란색 화살표 방향으로 움직이는 반면에 네스트로프 방법은 일단 이전에 움직였던 방향을 한번 더간다.그 다음에 그자리에서 그레디언트를 게산해서 거기서 그레디언트 방향으로 가는 방법이다. 


- 이렇게 하면 뭐가 좋아질까? 결론적으로 파란색 라인의 기울기가 모멘텀 방법보다 작아지게 되어서 최적점에 다가갈때 너무 다이렉트로 가지않게해서 최적점을 지나쳐버리는 여지를 조금 더 줄여준다.


- 위의 두가지 방법이 그레디언트의 방향을 컨트롤하는 최적화 방법이다.

![6](https://user-images.githubusercontent.com/41605276/67731933-1db71e80-fa3d-11e9-9afc-12fe1b416e93.png)

- 세타t+1을 세타t에서 뭔가를 빼준것이다. 그레디언트 디센트의 러닝레이트 자리에 무언가 루트가 씌워진게 분모에 들어가있다. 그 루트씌워진거 안에 Gt가 붙어있는 그레디언트를 Adaptive 그레디언트라는 것이다. 이 아다그라드 방법의 컨셉은 그레디언트의 크기의 제곱을 그레디언트 이전에 움직였던 그레디언트의 크기의 제곱을 모든방향에 대해서 따로따로 계속 누적하는 것이다. 그레디언트의 크기를 다 더해서 제곱한 다음에 그거를 루트로 나누는 방법이라고 할 수 있다.


- 그러면 이 방법을 통해 무엇을 하겠다라는 거냐면 내가 움직였던 방향으로 계속가면 점점 다가가는 보폭을 줄여주겠다(러닝레이트를 점점 줄이겠다)는 의도다. 그런데 이게 element-wise product이기 때문에 모든 방향(x축,y축...)에 대해 따로따로 계산한다. 그래서 특정방향이 최적점으로 많이 다가가면 그 특정방향의 보폭을 줄여주고, 아닌 방향은 천천히 가는 방법이다. 


- 이 아다그라드는 뭐가 문제냐면 계속 누적해서 더하기 때문에 무조건 학습을 진행하면 진행할수록 이 루트안에 있는 Gt가 커질수밖에 없다. 그래서 언젠가는 러닝레이트가 너무작아져서 학습이 멈추게되는 현상이 발생할수도 있다. 그래서 실전에서는 잘 안쓰는 방법이다.


- 그래서 이런 단점을 극복하고자 나온방법이 RMSprop이다.

Use exponentially decaying average of squared gradient

$$\ G_{t} = \gamma G_{t-1} + (1-\gamma)(\nabla_\theta j(\theta_t))^{2} $$


$$\ \theta_{t+1} = \theta_{t} - \frac{\eta}{\sqrt{G_{t}+\epsilon}} \centerdot \nabla_\theta j(\theta_t) $$


- (1-감마)를 추가로 앞에 붙여줘서 특정방향으로 계속갔다가 그 특정방향이 아닌 다른 방향으로 계속가지 않았으면 거기에 (1-감마)가 계속곱해져서 나누어주는 텀을 작게 만들어주는 방법이다. 그래서 특정방향으로 계속가다가 오랜만에 다른 방향으로 가면 그 방향으로 가면 스텝이 커질 수 있게 해주는 방법이다. 실전에서 굉장히 많이쓰는 방법이다. 일반적으로는 regression할때 더 많이 쓴다.

![7](https://user-images.githubusercontent.com/41605276/67731939-24de2c80-fa3d-11e9-9503-d4d258c286d2.png)

- 아담이라는 방법은 방향은 모멘텀 방향으로가고 그때 러닝레이트는 RMSprop으로 하겠다는 방법이다. 즉 방향은 모멘텀, 크기는 RMSprop을 합친방법이다. 굉장히 유명한 방법이고, 잘 모르면 최적화방법으로 아담을 쓰는 것이 가장 무난하다.


#### 천체적인 트레이닝 프로세스

1) 데이터 준비 및 전처리


2) 뉴럴네트워크의 아키텍처 선정(예를 들어서 레이어는 얼마나할지, 뉴런수는 얼마나할지, 드랍아웃 방법을 쓸건지 쓸거면 얼마나 가중치를 부여해서 줄건지 등등)


3) 내가 코딩을 다 한다음에 이 네트워크가 제대로 돌아가는지 확인하기 위해서 로스를 체크해본다. 어떤 정규화 방법을 체택했다면 한번 빼보고 드랍아웃을 채택했다면 드랍아웃을 0으로 한번해보는 등 정규화나 드랍아웃 코드는 그대로 두는데 적용하는 값을 0으로 하는 것이다. 그런다음에 트레이닝을 아주약간 해보고 로스를 출력해본다. 그러면 로스가 어떻게 나와야 되면 클래스의 수가 N개라고 할때 로그 N으로 나눈다. 그 -로그N 분에 1이 나오게 된다.

위에서 언급한 내용이 아래 두문장과 같다.

Initial loss must be about –log(1/n) w/o regularization loss 
 
 w/ regularization loss, loss must increase

만약에 우리가 가정한 -log(1/n)이 안나오고 엄청 크거나 작게 나오면 뭔가 내가 코딩을 잘못한거라고 할 수 있다.


4) 내가 만든 네트워크가 주어진 데이터를 오버피팅 할 수 있는지 확인해야 한다. 내가 데이터가 100만개 있어도 100만개를 다쓰지말고 배치사이즈의 3 ~ 4배정도만 집어넣고 게속학습을 시켜본다. 예를들어서 100만개의 데이터가 있으면 64개의 데이터만 샘플링한 다음에 배치사이즈 16으로해서 배치 3 ~ 4로해서 계속학습을 시킨다. 그래서 얘가 64개의 데이터에 대해서 100프로 맞출 수 있는지 확인해본다. 오버피팅해서 암기하는 식으로 해도 이 네트워크가 주어진 데이터를 풀 수 있는지를 확인해본다. 


5) 이런 검증을 해본다음에 하이퍼 파라미터 튜닝을 해본다. 그래서 전체 데이터를 사용해서 학습을 할텐데 네트워크에 들어가는 하이퍼파리미터를 제외하고 러닝레이트, 정규화 지수등을 조절해본다. 그런다음에 에포크를 많이주지 말고 약간의 에포크로 학습을 진행해본다. 그 결과로 하이퍼파라미어 튜닝을 해본다. 그리드서치나 랜덤서치등을 이용해서 해본다.

그러면 하이퍼파라미터 튜닝을 할때 어떻게 대응해야하냐. 문제가 발생했을때 어디서 어떤것을 고쳐야 하는가. 결론적으로 가장 큰 힌트를 주는 지표가 로스커브이다. 

![8](https://user-images.githubusercontent.com/41605276/67731951-2a3b7700-fa3d-11e9-9a08-0a6bd82f5212.png)

- 위의 그림에서 가장 좌측에 있는 그림은 학습이 아예 안되고 있는 상황이다. 그레디언트가 웨이트에 적용이 안되는 케이스이다. 우측에 두개 그림은 비슷한 상황이다. 이런경우들에는 트레인셋은 로스가 0에 가까워지는데 벨리데이션 테스트는 겝이 생겨버렸다. 이런 경우는 거의 오버피팅이라고 할 수 있다. 모델이 데이터의 수에 비해 너무 크거나 혹은 데이터가 너무 적은 경우다. 그래서 이럴때는 역시 데이터를 늘리는 것을 가장 큰 해결방안으로 생각해야 한다. 차선책으로 정규화를 적용하는 방안을 생각해봐야 한다. 데이터를 늘리지 않고 정규화를 걸어버리는 방법도 사실 바람직한 방법은 아니다. 그래서 데이터를 어떻게든 늘리는 방법을 강구해야 한다.

![9](https://user-images.githubusercontent.com/41605276/67731953-2f002b00-fa3d-11e9-8694-2642174743ae.png)

- 가장 좌측에 있는 그림은 어떤 상황이냐면 학습이 더디게 진행되는 것이라고 할 수 있다. 따라서 러닝레이틀 좀더 크게 잡을 필요가 있다는 말이다. 아니면 시간을 좀 더 길게 잡고 트레이닝을 한다던지 해야한다. 가운데 그림은 학습 처음할때 슬로우 스타트가 발생한 경우다. 인내가 없는 사람들이 학습을 했다면 이거 무슨 문제가 아니야 라는 의심을 할수도 있다. 이런경우에는 가중치 초기화를 너무 작게 잡거나, 잘못 부여한 경우일수도 있는데 인내심이 있다면 그냥 기다려도 상관없기는 하다. 가장 오른쪽 그림은 학습이 안되고 있는 상황이고 오히려 로스가 커지고 있다. 이 경우는 그레디언트의 부호를 거꾸로 적용한 경우이다.

![10](https://user-images.githubusercontent.com/41605276/67731962-332c4880-fa3d-11e9-8906-957604688bee.png)

- 여기서 위에 두개의 그림은 어떻게 보면 크리티컬한 문제는 아닐수도 있는데 이런 경우는 한 에포크 돌고 데이터를 셔플링하지 않은 경우에 저런현상이 발생할 수 있다. 좌측하단의 그림은 컴퓨터가 표현할 수 있는 숫자의 범위를 넘어버려서 학습이 중단되버린 상황이다. 이런 상황에서는 입실론 같은 숫자들을 활용해볼 필요가 있다. 우측하단의 그림은 벨리데이션 세트가 너무 작으면 발생할 수 있는 상황이다. 그래서 벨리데이션 세트의 수도 너무 아끼면 안된다.

![11](https://user-images.githubusercontent.com/41605276/67731968-37f0fc80-fa3d-11e9-8477-6f80942328b7.png)

- 좌측 그림은 무엇을 나타내냐면 저 색갈 다섯개의 라인이 모두 같은 성능의 네트워크다 한치의 수정이 없는 네트워크를 다섯번 테스트를 해본것인데 결과는 각각 다 다르게 나왔다. 마지막 레이어에 활성화함수를 이중으로 쓰게되면 이런현상이 발생한다. 과거에 텐서플로우버전에서 소프트맥스와 크로스 엔트로피를 동시에 수행해주는 API를 사람들이 일반적으로 많이 썼다. 원래는 소프트맥스 집어넣고 그 다음에 크로스엔트로피를 집어넣어줘야 하는데 이 API를 사용함으로써 마지막 레이어에는 활성화함수를 아예 안쓰고 그 동시에 수행해주는 API를 넣게된다. 그런데 코딩을 하는 과정에서 실수로 소프트맥스를 넣고, 소프트맥스와 크로스엔트로피를 동시에 수행하는 api를 또 넣어버리는 실수들이 많이 발생하게 되었는데 이런 경우 위의 그림과 같은 현상이 발생할 수 있다.
