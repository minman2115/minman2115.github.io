---
layout: post
title: "Random forest 기초개념"
tags: [Classification]
comments: true
---

.

#### 그림, 실습코드 등 학습자료 출처 : https://datascienceschool.net

#### 1. Random forest

![1](https://user-images.githubusercontent.com/41605276/57063677-fcc87780-6cfe-11e9-9bbc-d946d9adb260.jpg)

- 다수결방법이나 배깅방법 보다도 더 많이 쓰이는 방법이 랜덤포레스트이다. 랜덤포레스트는 배깅방법인데 의사결정나무를 개별모형을 사용하는 모형결합방법이다.


- 랜덤포레스트는 Random Subspaces를 응용한 방법이다. 노드 첫단계에서 전체차원에서 Random Subspaces를 하여 문제를 풀고, 노드 분리시 또다시 전체차원에서 Random Subspaces를 하여 문제를 푸는 이런 방식이다. 이렇게 노드마다 랜덤하게 제약조건이 달라지게 되는 것이다. 이렇게 하면 개별 모형들 사이의 상관관계가 줄어들기 때문에 모형 성능의 변동이 감소하는 효과가 있다.


- 예를들어 축구팀이 있는데 1번선수부터 30번 선수가 있다면 기존의 의사결정나무 방법에서는 가장 잘하는 7번선수를 바로 뽑을 수 있는데, 랜덤포레스트는 1번 선수부터 10번 선수중에 골라야하는 그런 상황과 비슷한것이다. 전체 선수단 안에서 고르라고 하게 되면 어떠한 감독이 와도 처음에는 다 7번을 고를것이다. 그래서 선수단을 subspacing해서 고르라고하면 모델들이 서로 독립적이게 되는 것이다.


- decision tree는 탐욕알고리즘이 들어가 있다. 어떤 선택을 할때 그 순간에 있어서만 최적의 조건을 선택하는 것을 탐욕알고리즘이라고 한다. 그런데 랜덤포레스트 방법을 쓰게 되면 탐욕알고리즘에서는 낼 수 없는 성능을 도출 할수도 있다. 그리디한 선택을 안하다 보면 우연히 더 좋은 성능을 낼 수도 있기 때문이다.

#### 2. Extremely Randomized Trees

![2](https://user-images.githubusercontent.com/41605276/57063689-03ef8580-6cff-11e9-8c4e-db4f038fb2e5.jpg)

- 이러한 방법을 극단적으로 적용한 것이 Extremely Randomized Trees 모형으로 이 경우에는 각 노드에서 랜덤하게 독립 변수를 선택한다. 그냥 랜덤포레스트는 Random Subspaces하는 것까지는 랜덤으로 하는데 그 특정 피쳐 안에서는 decision tree가 역할을 하는데 Extremely Randomized Trees는 Random Subspaces하고 또 그 범위 안에서도 주사위를 던져서 랜덤으로 피쳐를 하나 뽑는다. 그리고 쓰레시홀드만 decision tree가 역할을 해주는 그런 원리이다. range를 지정해서 하는 랜덤포레스트 보다는 성능이 떨어질지는 모르나 독립성은 더욱 강렬해진다. 


- 익스트림 랜덤포레스트의 장점 중 하나는 피쳐들의 출전기회가 동등해진다. 왜냐하면 피쳐 하나 고르는것까지 주사위로 결정하기 때문이다.


#### 3. Feature importance


- 랜덤포레스트의 장점 중 하나는 각 피쳐의 feature importance를 계산할 수 있다는 점이다. 사용된 모든 노드에 대해 어떤 피쳐를 사용하였고 그 노드에서 얻은 information gain을 구할 수 있으므로 각각의 피쳐들이 얻어낸 information gain의 평균을 비교하면 어떤 독립 변수가 중요한지를 비교할 수 있다.


- 랜덤포레스트는 회귀분석도되고 분류도된다. 그리고 피쳐가 카테고리든 실수값이든 상관없다. 또한 모델이 어떤 종류의 복잡도를 보여도 다 풀어낸다. 멤버수만 높이면 거의 다 푼다. 또한 정규화도 크게 신경쓸 필요가 없다. 왜냐하면 멤버가 많이 있으면 자동으로 되기 때문이다. 단점은 계산량이 많은 편이다.
