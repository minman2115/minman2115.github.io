---
layout: post
title: "데이터 탐색과 전처리를 위한 주요 파이썬 모듈"
tags: [데이터전처리]
comments: true
---

Data_Preprocessing_Studynotes_(20190522)

study program : https://www.fastcampus.co.kr/data_camp_ppc

#### [학습기록]

#### 1. 피쳐타입에 따른 적절한 모델선정 가이드라인

모든 데이터에 맞는다고 보장하는 자료는 아니지만 통상적으로 아래 그림과 같은 가이드라인을 적용하는 것이 바람직하다.

![1](https://user-images.githubusercontent.com/41605276/58229108-bd280500-7d6b-11e9-9d38-cd253696686c.jpg)

- 회귀모형은 혼합형 변수를 사용할 경우 부적합하다


- 의사결정나무가 데이터유형에 별 영향을 받지 않는 이유는 모든 데이터를 이진화하기 때문이다.


- 나이브 베이즈 모델은 변수유형에 매우 민감하다. 반면에 신경망은 둔감하다.


- 회귀모델과 knn은 변수 스케일에 영향을 많이 받기 때문에 혼합형 모델에 적합하지 않는다.


- 나이브 베이즈 모형도 가능하면 모든 변수가 동일한 확률분포를 가정하는 것이 좋다.


- 아래의 그림에서 시간복잡도가 곧 피쳐수, 클래스 복잡도를 의미한다.

![2](https://user-images.githubusercontent.com/41605276/58229117-c74a0380-7d6b-11e9-8216-27c9ca6f51ae.jpg)

#### 2. 혼합형 피처들에 적절하지 않는 '회귀모델'


- 혼합형 피쳐들의 경우에는 대부분의 경우 피쳐간의 스케일차이가 크게 발생한다. 그래서 피쳐의 스케일에 따라 가중치 w값이 크게 달라지며 이에 따라 예측 안정성이 크게 떨어진다. 다시말해서 가중치 w의 범위가 너무 커진다.


- 다항회귀 모델은 변수 간 연산결과를 사용하므로 혼합형 피처에 대해서 더더욱 부적절하다고 할 수 있다. 다만 정수형 피쳐와 연속형 피쳐는 같이 사용해도 괜찮다.


#### 3. 혼합형 피처들에 적절하지 않는 '나이브베이즈 모델'


- 예를들어서 베르누이 분포는 연속형 값을 가지는 확률분포 추정에 아예 사용할 수 없으며, 가우시안 분포는 이산형 값을 가지는 확률분포 추정에 적합하지 않은 분포다.


- 또한 나이브베이즈는 조건부 확률을 추정할때 하나의 확률분포만 가정한다. 따라서 피쳐가 혼합되어 있는 경우에는 나이브 베이즈가 우수한 성능을 보이기 어렵다.


#### 4. 혼합형 피처들에 적절하지 않는 'k-NN'


- 단일 유사도 척도(거리척도)를 사용해서 이웃을 정의하기 때문에 스케일차이가 서로 큰 혼합형 변수에 적절하지 않다. 


#### 5. list VS ndarray

- list는 서로 다른 데이터 타입의 요소를 담을 수 있지만 반면에 ndarray는 서로다른 데이터타입의 요소를 담을수는 없다.


- list보다 ndarray가 연산시 속도가 훨씬 빠르다.


- 그냥 리스트랑 정수 비교 연산은 불가하지만 np.array는 정수랑 비교연산이 가능하다.

#### 6. array 사본생성 및 재구조화

- array 슬라이스는 array data의 copy된 형태가 아니라 view를 반환함

ex)


```python
x = np.array([0,1,2,3,4,5,6,7,8,9])
print("x : ", x, '\n')

x_sub = x[:2]
# 배열사본 생성
print('x_sub : ', x_sub, '\n')

x_sub[0] = 20
print('x_sub : ', x_sub, '\n')

print("x : ", x)
# 사본(x_sub)의 0번째 요소를 20으로 바꾸면 원본(x)도 바뀐다.
```

    x :  [0 1 2 3 4 5 6 7 8 9] 
    
    x_sub :  [0 1] 
    
    x_sub :  [20  1] 
    
    x :  [20  1  2  3  4  5  6  7  8  9]
    

- 그래서 사용자가 copy된 형태를 쓸 수 있도록 나온것이 copy() 메서드이다.


```python
x = np.array([0,1,2,3,4,5,6,7,8,9])
print("x : ", x, '\n')

x_copy = x.copy()
print('x_copy : ', x_copy, '\n')

x_copy[0] = 20
print('x_copy : ', x_copy, '\n')

print("x : ", x)
```

    x :  [0 1 2 3 4 5 6 7 8 9] 
    
    x_copy :  [0 1 2 3 4 5 6 7 8 9] 
    
    x_copy :  [20  1  2  3  4  5  6  7  8  9] 
    
    x :  [0 1 2 3 4 5 6 7 8 9]
    

- 배열의 재구조화 (.reshape)는 주로 이미지 데이터를 가공할때 주로 쓴다.

#### 7. Universal function

- numpy 배열의 값에 반복된 연산을 빠르게 수행하는 것을 주목적으로 하는 함수다.


- 빠른 element-wise 연산(브로드캐스팅 같은 연산)을 가능하게 한다.


- 루프 대신에 universal function을 쓰면 약 400배 정도 더 빠른 연산을 할 수 있다.


- 배열산술연산

ex)


```python
x = np.arange(4)
print(x)

y = np.linspace(1,10,4)
print(y)

print(x + 5)
print(x + y)
```

    [0 1 2 3]
    [ 1.  4.  7. 10.]
    [5 6 7 8]
    [ 1.  5.  9. 13.]
    

- 위의 배열산술연산이 이루어지는 방식과 유사하게 절댓값 및 지수로그 연산도 가능하다.

#### 8. Bool logic

머신러닝에서는 특정조건을 만족하는 행이나 열을 가져올 수 있다.

bool logic 예시)


```python
M = np.array([1,2,3,4,5,6])

M[M > 3]
```




    array([4, 5, 6])



#### 9. 결합 인덱싱

ex)


```python
x = np.array([[0,1,2,3],
              [4,5,6,7],
              [8,9,10,11]])

print(x[2,[2,0,1]],'\n')

print(x[1:,[2,0,1]],'\n')
```

    [10  8  9] 
    
    [[ 6  4  5]
     [10  8  9]]
    

#### 10. np.argsort

- Numpy 정렬 알고리즘의 가장 유용한 기능 중 하나는 axis 인수 를 사용해 다차원 배열의 특정 행이나 열에 따라 정렬할 수 있다.


- argsort는 주로 순위 계산할때 많이 쓴다. 또는 heapq, nlargest 함수도 쓸 수 있다.


- 예를 들어서 이상치인지 아닌지, 어떤 특정한 특징인지

```python
x = np.array([3,1,2])

np.argsort(x)
```

array([1, 2, 0], dtype=int64)

#### 11. loc와 iloc

- loc 인덱서 : '명시적인 인덱스'를 참조하는 인덱싱과 슬라이싱을 가능하게 함


- iloc 인덱서 : '암묵적인 인덱스'를 참조하는 인덱시오가 슬라이싱을 가능하게 함


- 아래 코드에서 data[1]은 'b'를 나타내는 것인가 아니면 'a'를 나타내는 것인가. 정답은 'a'이다. 명시적인 인덱스를 우선적용하기 때문이다. 이런 혼동을 막고자 나온 개념이 loc와 iloc이다.


```python
data = pd.Series(['a','b','c'], index = [1,3,5])
print('data : ', '\n',data , '\n')

print(data.iloc[1], '\n')

print(data.iloc[1:3], '\n')

print(data.loc[3], '\n')

print(data.loc[3:5], '\n')
```

    data :  
     1    a
    3    b
    5    c
    dtype: object 
    
    b 
    
    3    b
    5    c
    dtype: object 
    
    b 
    
    3    b
    5    c
    dtype: object 
    
    

 #### 12. 집계함수(dataframe.describe())

기초통계량 활용방안

통상적으로 이를이용해서 데이터의 치우침을 많이 확인한다.

100개가 있으면 75개까지는 1이다.

- 전부 양수이고 표준편차가 평균보다 크다면 최소한 일반적인 정규분포가 아니다. 이는 일부 데이터 치우침이 있거나 각각의 데이터 스케일 차이가 엄청나게 난다는 것이다.

=> 결론적으로 스케일링이 필요한 경우다.

#### 13. Groupby

보통 조건부 통계량을 구할때 쓸 수 있다.(ex) 성별에 따른 평균키)

- ex) 성별에 따른 키의 평균을 구한다고 할때

성별 = 조건(분할기준칼럼)

적용기준 칼럼 = 키

평균 = 집계함수, 통계량

#### 14.  기타 참고사항 
pd.DataFrame(,engine='python')은 한글 인코딩 관련 이슈를 해결할때 쓴다.
