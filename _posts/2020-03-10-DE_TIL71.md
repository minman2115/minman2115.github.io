---
layout: post
title: "타계정간 대규모 s3 데이터 마이그레이션 방안"
tags: [Data Engineering]
comments: true
---

.


#### 1. 목적

AS-IS 계정에 있는 S3의 모든 버킷과 데이터를 같은 리전의 TO-BE계정으로 데이터 마이그레이션

(S3 to S3 Migration)

#### 2. 전제조건


- S3 총 데이터 규모가 40TB가 넘음


- AS-IS 계정은 현재 서비스 중이기 때문에 AS-IS 계정의 네트워크나 config 설정을 건드는 것을 최소화해야함


- 1차 베이스라인 데이터 백업 후 디데이까지 일배치로 AS-IS 계정의 s3 데이터와 TO-BE 계정의 s3 데이터 간 sync를 맞추는 작업 필요

#### 3. 가능한 방안

- [3안] S3 Sync 기능을 이용한 마이그레이션 방안 채택

![123123](https://user-images.githubusercontent.com/41605276/76311265-e40ff180-6313-11ea-9dd6-5d677bb227e3.png)

#### 4. [3안] S3 Sync 기능 테스트

STEP 1) AS-IS 계정의 source 버킷에 대하여 TO-BE가 접근할 수 있도록 버킷권한 설정

- AS-IS 계정의 source 버킷에서 아래와 같이 버킷권한 설정

![22](https://user-images.githubusercontent.com/41605276/76311599-abbce300-6314-11ea-8030-31f2abf3b99c.png)


```python
{
    "Version": "2012-10-17",
    "Id": "Policy1583757151705",
    "Statement": [
        {
            "Sid": "Stmt1583757150787",
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::161461013751:root"
            },
            "Action": [
                "s3:GetBucketLocation",
                "s3:GetObject",
                "s3:ListBucket",
            ],
            "Resource": [
                "arn:aws:s3:::[버킷이름]",
                "arn:aws:s3:::[버킷이름]/*"
            ]
        }
    ]
}
```

STEP 2) TO-BE 계정에서도 AS-IS 계정의 특정 버킷에 접근한다는 것을 사용자 계정 inline 정책을 만들어서 부여

![33](https://user-images.githubusercontent.com/41605276/76311952-60ef9b00-6315-11ea-9384-572cc18c552f.png)

json에서 아래와 같이 작성 후 정책 생성 및 연결


```python
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "s3:ListBucket",
                "s3:GetObject"
            ],
            "Resource": [
                "arn:aws:s3:::*",
                "arn:aws:s3:::*/*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "s3:ListBucket",
                "s3:PutObject",
                "s3:PutObjectAcl"
            ],
            "Resource": [
                "arn:aws:s3:::*",
                "arn:aws:s3:::*/*"
            ]
        }
    ]
}
```

** STEP 1 ~ 2) 참고자료 : https://aws.amazon.com/ko/premiumsupport/knowledge-center/copy-s3-objects-account/

STEP 3) TO-BE 계정에서 EC2(amazon linux2) 생성 후 task 부여환경 구성

step 3-1) ec2 생성 및 ssh 접속

step 3-2) 파이썬 3.7 설치


```python
sudo yum list | grep python3
sudo yum install python37 python37-pip
```

step 3-3) os 파이썬 기본버전 변경 (2.7 -> 3.7)


```python
sudo alternatives --install /usr/bin/python python /usr/bin/python2.7 1
sudo alternatives --install /usr/bin/python python /usr/bin/python3.7 2
```

step 3-4) 주피터 설치


```python
sudo pip3 install jupyter
```

step 3-5) 주피터 설정파일 생성


```python
jupyter notebook --generate-config
```

step 3-6) 설정파일 내 설정 변경


```python
sudo vi /home/ec2-user/.jupyter/jupyter_notebook_config.py
```

step 3-6-1) 외부 접속 허용


```python
##  Takes precedence over allow_origin_pat.
c.NotebookApp.allow_origin = '*'
```

step 3-6-2) 작업 경로 설정


```python
## The directory to use for notebooks and kernels.
c.NotebookApp.notebook_dir = '/home/ec2-user'
```

step 3-6-3) 시작시 브라우저 실행 안함설정


```python
## Whether to open in a browser after starting.
c.NotebookApp.open_browser = False
```

step 3-6-4) 접속 암호 설정

암호 설정을 위해 아래와 같이 암호 생성

리눅스 콘솔에서 python 실행

아래와 같이 입력


```python
Python 3.6.1 |Continuum Analytics, Inc.| (default, May 11 2017, 13:25:24) [MSC v.1900 64 bit (AMD64)] on win32
Type "help", "copyright", "credits" or "license" for more information.
>>> from notebook.auth import passwd
>>> passwd()
Enter password: 1234
Verify password: 1234
'sha1:**********************'
```

step 3-6-5) 다시 설정파일로 들어가서 비밀번호 설정부분 변경


```python
#  The string should be of the form type:salt:hashed-password.
c.NotebookApp.password = 'sha1:***********************'
```

step 3-6-6) 접속포트 설정

- 포트설정과 동시에 ec2 보안그룹에서도 8800 포트를 열어준다.


```python
## The port the notebook server will listen on.
c.NotebookApp.port = 8800
```

step 3-7) 리눅스 콘솔에서 aws configure 설정

step 3-8) 시스템 타임존 변경

tzselect 명령어를 사용하여 타임존을 서울 시간으로 설정

(이 방법은 로컬에만 적용된다는 것을 주의한다)

$ date

Fri Dec  1 05:48:03 UTC 2017

$ sudo echo "TZ='Asia/Seoul'; export TZ" >> .profile

$ . .profile

$ date

Fri Dec  1 14:48:36 KST 2017

step 3-9) 아래와 같이 리눅스 콘솔에서 주피터 실행

jupyter notebook --ip=0.0.0.0 --port=8800

아래와 같이 브라우저에서 IP주소:8800으로 접속

![JYPY](https://user-images.githubusercontent.com/41605276/76313004-78c81e80-6317-11ea-9628-fe8a84e9748e.png)

STEP 4) jupyter에서 노트북 생성 후 아래와 같은 코드를 작성하여 코드 실행


```python
import subprocess
from datetime import datetime

timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')+'\n'
logfilename = timestamp[0:4]+timestamp[5:7]+timestamp[8:10]

source_s3 = "[소스버킷이름]"
destination_s3 = "[목적지버킷이름]"

sync_command = f"aws s3 sync s3://{source_s3}/ s3://{destination_s3}/ --delete"


logfile = open("{}.txt".format(logfilename), 'wb')
logfile.write(timestamp.encode())

try :
    log_record = subprocess.check_output(sync_command, stderr=subprocess.STDOUT, shell=True)
    print("job success")
    logfile.write(log_record)
except subprocess.CalledProcessError as e:
    print("job fail")
    logfile.write(e.output)
    
logfile.close()
```

로그파일 저장된 내용 예시

![LOG](https://user-images.githubusercontent.com/41605276/76313061-939a9300-6317-11ea-82ad-b11b39b332dd.png)
