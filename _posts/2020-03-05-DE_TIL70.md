---
layout: post
title: "AWS to AWS Data migration 테크노트"
tags: [Data Engineering]
comments: true
---

.

#### 1. 마이그레이션 방안

![1](https://user-images.githubusercontent.com/41605276/76141146-e882a300-60a4-11ea-9380-d2c967ec1852.png)

#### 2. Redshift 및 HBase 데이터 검증방안

1) 데이터 로우 갯수를 카운트해서 확인

2) 일부데이터를 샘플링하여 AS-IS와 TO-BE간 일치하는지 확인

** 참고사항 : HBase는 Mapreduce Rowcount라는 기능을 활용할 수 있음

#### 3. CDH의 HBase클러스터는 그냥 AMI 이미지를 떠서 옮기면 되는거 아니냐?

- 디스크만 옮긴다고해서 해결할 수 있는 문제가 아님


- HDFS라는 시스템을 생각해야 하는데 HDFS의 기본개념은 데이터를 블락단위로 쪼개고 3개이상 복제를 떠서 각 노드에 저장한다는 것인데 그렇게 하려면 네임노드라는 곳에서 각각의 노드정보를 알고 있어야 한다. 그런 정보는 Hadoop이 구동중일때는 항상 메모리에 갖고 있다가. 시스템을 내리게 되면 하드디스크에 저장하게된다.


- 어쨌든 네임노드는 데이터노드들의 정보와 거기에 뭐가 저장되어 있는지 알고 있는 곳인데 단순하게 디스크만 AMI로 떠서 마이그레이션을 한다고해서 버츄얼 머신의 시스템 정보들도 같이 마이그레이션을 하는게 아니기 때문에 AMI로 디스크만 떠서 옮겨봤자 소용이 없다는 말이다.


- 따라서 클라우드애라에서도 권고하는 것은 동일한 설정의 하둡시스템을 마이그레이션 할 플레이스에 먼저 띄우고 distcp 등의 기능을 이용해서 옮기라고 한다.


- 그렇게 되면 데이터만 특정 클러스터에서 다른 클러스터로 보내주게되고 네임노드에서 데이터를 받아서 그 클러스터 정보에 맞게 네임노드가 데이터노드에 데이터를 분산 저장한다는 것이다.


- HBase는 HDFS라는 로우한 시스템 위에서 작동하는 하이레벨 NoSQL 서비스일 뿐 결론은 HDFS라는 것이다.


- 그래서 이번 프로젝트의 핵심은 AS-IS의 네트워크 밴드위스를 얼마만큼 우리가 쓸 수 있냐에 따라 데이터 마이그레이션 속도가 달라진다는 것이다.


#### 4. 엔지니어로서 성장방향

엔지니어는 하나의 솔루션만 몰입해서 공부하면 안된다. 고객이 어떤 비지니스 환경이고 어떤 목적인지 정확하게 캐치해서 거기에 맞는 데이터 처리 툴들을 잘 조합해서 환경을 구성해야한다. 따라서 상황별로 어떤 툴들을 조합해서 데이터 플로우를 구성을 해야하기 때문에 어떤 상황에서는 어떤 툴이나 도구를 쓸 수 있고, 클라우드 밴더별로도 어떤 옵션이 있는지 큰 그림을 봐야한다.


#### 5. AI/ML CDH 클러스터(HBase, Kafka 등) 분석

- Cloudera Manager 서(7180포트) 내로 접속해서 클러스터 내 인프라 현황(네트워크 등), 애코 서비스 config 등 분석 확인


- Default에 가까운 클러스터 설정(디폴트 설정 이외에 특별한 설정 없음, 커버로우 등 보안설정 없음)으로 확인


- 마이그래이션 시 특별한 이슈가 없이 무난할 것으로 예상

#### 6. 분석했던 CDH 구성에서 문제점

1) 카프카와 주키퍼를 같은 호스트에 두고 사용하고 있는데 이는 좋은 방법은 아니다. 네트워크 부하가 서로 적은 편이 아니기 때문에 카프카와 주키퍼는 상태정보를 빠르게 빠르게 막 주고받는 구조인데 이 둘이 같은 호스트에 있다는 것은 네트워크 부하에 대한 부담이 훨씬 커진다는 말이다.

2) kafka 클러스터(노드 3대)의 config을 보면 num.partitions = 10이라고 되어있는데 설정이 지금 잘못들어가져 있는것이다. 카프카 작동에는 문제가 없으나 3(노드대수)의 배수로 파티션 숫자가 설정이 되야 노드에 고르게 부하가 가는데 파티션 숫자가 10이라는 것은 어떤 노드 하나에 불균형하게 부하가 더 간다는 것이다. 이는 운영상에서 저 노드 하나 때문에 연쇄적으로 클러스터가 문제가 될 수 있는 잠재소지가 될 수 있다. 하둡의 사상은 어떤 큰 데이터나 잡이 있으면 노드들이 고르게 동작해야 한다는 것이다. 불균형하면 안된다 노드 간에서 그래서 예를들어서 하둡의 HDFS 같은 경우도 데이터가 어느 특정노드에 더 많이 쌓이는 것을 고르게 쌓을 수 있도록 조절하는 옵션도 있다. 카프카는 하둡의 사상처럼 모든 노드가 균형있게 일을 해야한다는 기본적인 개념을 엔지니어는 알고 있어야 한다.